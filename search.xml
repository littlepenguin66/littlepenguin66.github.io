<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>PaddleDetection基础训练</title>
      <link href="/%E6%9D%82%E5%AD%A6/PaddleDetection%E5%9F%BA%E7%A1%80%E8%AE%AD%E7%BB%83/"/>
      <url>/%E6%9D%82%E5%AD%A6/PaddleDetection%E5%9F%BA%E7%A1%80%E8%AE%AD%E7%BB%83/</url>
      
        <content type="html"><![CDATA[<h1>PaddleDetection 简介</h1><p>PaddleDetection 是百度框架 PaddlePaddle 下的一个开源目标检测框架，集成了许多开箱即用的模型，是一个端到端开发套件，在提供丰富的模型组件和测试基准的同时，注重端到端的产业落地应用，通过打造产业级特色模型|工具、建设产业应用范例等手段，帮助开发者实现数据准备、模型选型、模型训练、模型部署的全流程打通，快速进行落地应用。</p><h1>安装</h1><h2 id="环境要求">环境要求</h2><ul><li>PaddlePaddle 2.3.2</li><li>OS 64 位操作系统</li><li>Python 3(3.5.1+/3.6/3.7/3.8/3.9/3.10)，64 位版本</li><li>pip/pip3(9.0.1+)，64 位版本</li><li>CUDA &gt;= 10.2</li><li>cuDNN &gt;= 7.6</li></ul><p>PaddleDetection 依赖 PaddlePaddle 版本关系：</p><table><thead><tr><th style="text-align:center">PaddleDetection 版本</th><th style="text-align:center">PaddlePaddle 版本</th><th style="text-align:center">备注</th></tr></thead><tbody><tr><td style="text-align:center">develop</td><td style="text-align:center">&gt;=2.3.2</td><td style="text-align:center">默认使用动态图模式</td></tr><tr><td style="text-align:center">release/2.6</td><td style="text-align:center">&gt;=2.3.2</td><td style="text-align:center">默认使用动态图模式</td></tr><tr><td style="text-align:center">release/2.5</td><td style="text-align:center">&gt;= 2.2.2</td><td style="text-align:center">默认使用动态图模式</td></tr><tr><td style="text-align:center">release/2.4</td><td style="text-align:center">&gt;= 2.2.2</td><td style="text-align:center">默认使用动态图模式</td></tr><tr><td style="text-align:center">release/2.3</td><td style="text-align:center">&gt;= 2.2.0rc</td><td style="text-align:center">默认使用动态图模式</td></tr><tr><td style="text-align:center">release/2.2</td><td style="text-align:center">&gt;= 2.1.2</td><td style="text-align:center">默认使用动态图模式</td></tr><tr><td style="text-align:center">release/2.1</td><td style="text-align:center">&gt;= 2.1.0</td><td style="text-align:center">默认使用动态图模式</td></tr><tr><td style="text-align:center">release/2.0</td><td style="text-align:center">&gt;= 2.0.1</td><td style="text-align:center">默认使用动态图模式</td></tr><tr><td style="text-align:center">release/2.0-rc</td><td style="text-align:center">&gt;= 2.0.1</td><td style="text-align:center">–</td></tr><tr><td style="text-align:center">release/0.5</td><td style="text-align:center">&gt;= 1.8.4</td><td style="text-align:center">大部分模型&gt;=1.8.4 即可运行，Cascade R-CNN 系列模型与 SOLOv2 依赖 2.0.0.rc 版本</td></tr><tr><td style="text-align:center">release/0.4</td><td style="text-align:center">&gt;= 1.8.4</td><td style="text-align:center">PP-YOLO 依赖 1.8.4</td></tr><tr><td style="text-align:center">release/0.3</td><td style="text-align:center">&gt;=1.7</td><td style="text-align:center">–</td></tr></tbody></table><h2 id="安装说明">安装说明</h2><h3 id="1-安装-PaddlePaddle">1. 安装 PaddlePaddle</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># CUDA10.2</span><br><span class="line">python -m pip install paddlepaddle-gpu==2.3.2 -i https://mirror.baidu.com/pypi/simple</span><br><span class="line"></span><br><span class="line"># CPU</span><br><span class="line">python -m pip install paddlepaddle==2.3.2 -i https://mirror.baidu.com/pypi/simple</span><br></pre></td></tr></table></figure><ul><li>更多 CUDA 版本或环境快速安装，请参考<a href="https://www.paddlepaddle.org.cn/install/quick">PaddlePaddle 快速安装文档</a></li><li>更多安装方式例如 conda 或源码编译安装方法，请参考<a href="https://www.paddlepaddle.org.cn/documentation/docs/zh/install/index_cn.html">PaddlePaddle 安装文档</a></li></ul><p>请确保您的 PaddlePaddle 安装成功并且版本不低于需求版本。使用以下命令进行验证。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 在您的Python解释器中确认PaddlePaddle安装成功</span><br><span class="line">&gt;&gt;&gt; import paddle</span><br><span class="line">&gt;&gt;&gt; paddle.utils.run_check()</span><br><span class="line"></span><br><span class="line"># 确认PaddlePaddle版本</span><br><span class="line">python -c &quot;import paddle; print(paddle.__version__)&quot;</span><br></pre></td></tr></table></figure><p><strong>注意</strong></p><ol><li>如果您希望在多卡环境下使用 PaddleDetection，请首先安装 NCCL</li></ol><h3 id="2-安装-PaddleDetection">2. 安装 PaddleDetection</h3><p><strong>注意：</strong> pip 安装方式只支持 Python3</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 克隆PaddleDetection仓库</span><br><span class="line">cd &lt;path/to/clone/PaddleDetection&gt;</span><br><span class="line">git clone https://github.com/PaddlePaddle/PaddleDetection.git</span><br><span class="line"></span><br><span class="line"># 安装其他依赖</span><br><span class="line">cd PaddleDetection</span><br><span class="line">pip install -r requirements.txt</span><br><span class="line"></span><br><span class="line"># 编译安装paddledet</span><br><span class="line">python setup.py install</span><br></pre></td></tr></table></figure><p><strong>注意</strong></p><ol><li><p>如果 github 下载代码较慢，可尝试使用<a href="https://gitee.com/PaddlePaddle/PaddleDetection.git">gitee</a>或者<a href="https://doc.fastgit.org/zh-cn/guide.html">代理加速</a>。</p></li><li><p>若您使用的是 Windows 系统，由于原版 cocoapi 不支持 Windows，<code>pycocotools</code>依赖可能安装失败，可采用第三方实现版本，该版本仅支持 Python3</p><p><code>pip install git+https://github.com/philferriere/cocoapi.git#subdirectory=PythonAPI</code></p></li><li><p>若您使用的是 Python &lt;= 3.6 的版本，安装<code>pycocotools</code>可能会报错<code>distutils.errors.DistutilsError: Could not find suitable distribution for Requirement.parse('cython&gt;=0.27.3')</code>, 您可通过先安装<code>cython</code>如<code>pip install cython</code>解决该问题</p></li></ol><p>安装后确认测试通过：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python ppdet/modeling/tests/test_architectures.py</span><br></pre></td></tr></table></figure><p>测试通过后会提示如下信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">.......</span><br><span class="line">----------------------------------------------------------------------</span><br><span class="line">Ran 7 tests in 12.816s</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><h1>模型训练部分</h1><p>paddledetection 的模型训练主要用的是 tools/train.py 这个文件，但是在训练时需要预先配置基础模型 yml，如<code>ppyoloe_plus_crn_l_80e_coco.yml</code>其结构如下：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">_BASE_:</span></span><br><span class="line">  [</span><br><span class="line">    <span class="string">&quot;../datasets/coco_detection.yml&quot;</span>,</span><br><span class="line">    <span class="string">&quot;../runtime.yml&quot;</span>,</span><br><span class="line">    <span class="string">&quot;./_base_/optimizer_80e.yml&quot;</span>,</span><br><span class="line">    <span class="string">&quot;./_base_/ppyoloe_plus_crn.yml&quot;</span>,</span><br><span class="line">    <span class="string">&quot;./_base_/ppyoloe_plus_reader.yml&quot;</span>,</span><br><span class="line">  ]</span><br><span class="line"></span><br><span class="line"><span class="attr">log_iter:</span> <span class="number">100</span> <span class="comment">#多少个图片输出一次log</span></span><br><span class="line"><span class="attr">snapshot_epoch:</span> <span class="number">5</span> <span class="comment">#多少个epoch保存一次参数</span></span><br><span class="line"><span class="attr">weights:</span> <span class="string">output/ppyoloe_plus_crn_l_80e_coco/model_final</span> <span class="comment">#权重</span></span><br><span class="line"></span><br><span class="line"><span class="attr">pretrain_weights:</span> <span class="string">https://bj.bcebos.com/v1/paddledet/models/pretrained/ppyoloe_crn_l_obj365_pretrained.pdparams</span></span><br><span class="line"><span class="attr">depth_mult:</span> <span class="number">1.0</span></span><br><span class="line"><span class="attr">width_mult:</span> <span class="number">1.0</span></span><br></pre></td></tr></table></figure><p>正如文件内容所说，需要配置<em>BASE</em>中的五个文件，其中如果是 PaddleDetection 中自带的模型，<em>BASE</em>中就只要改 datasets 选项，且具体的优化器和训练配置就自己去文件中改，以<code>ppyoloe_plus_crn_l_80e_coco.yml</code>为例其 datasets 的 yml 文件如下所示：</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">metric:</span> <span class="string">COCO</span></span><br><span class="line"><span class="attr">num_classes:</span> <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="attr">TrainDataset:</span> <span class="type">!COCODataSet</span></span><br><span class="line">  <span class="attr">image_dir:</span> <span class="string">image</span></span><br><span class="line">  <span class="attr">anno_path:</span> <span class="string">train.json</span></span><br><span class="line">  <span class="attr">dataset_dir:</span> <span class="string">24dog/</span></span><br><span class="line">  <span class="attr">data_fields:</span> [<span class="string">&quot;image&quot;</span>, <span class="string">&quot;gt_bbox&quot;</span>, <span class="string">&quot;gt_class&quot;</span>, <span class="string">&quot;is_crowd&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="attr">EvalDataset:</span> <span class="type">!COCODataSet</span></span><br><span class="line">  <span class="attr">image_dir:</span> <span class="string">image</span></span><br><span class="line">  <span class="attr">anno_path:</span> <span class="string">val.json</span></span><br><span class="line">  <span class="attr">dataset_dir:</span> <span class="string">24dog/</span></span><br><span class="line"></span><br><span class="line"><span class="attr">TestDataset:</span> <span class="type">!ImageFolder</span></span><br><span class="line">  <span class="string">!</span> <span class="attr">anno_path:</span> <span class="string">val.json</span></span><br><span class="line">  <span class="attr">image_dir:</span> <span class="string">image</span></span><br><span class="line">  <span class="attr">dataset_dir:</span> <span class="string">24dog/</span></span><br></pre></td></tr></table></figure><p><code>dataset.yml</code>的需要指向个 json 文件，如上文则是<code>train.json</code>,<code>val.json</code>，但是把测试集与评估集设为同一个。<br><code>train.json</code>和<code>val.json</code>的格式如下所示</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;images&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;monkey0002.jpg&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;height&quot;</span><span class="punctuation">:</span> <span class="number">2160.0</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;width&quot;</span><span class="punctuation">:</span> <span class="number">3840.0</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">0</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;monkey0003.jpg&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;height&quot;</span><span class="punctuation">:</span> <span class="number">2160.0</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;width&quot;</span><span class="punctuation">:</span> <span class="number">3840.0</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;monkey0004.jpg&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;height&quot;</span><span class="punctuation">:</span> <span class="number">2160.0</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;width&quot;</span><span class="punctuation">:</span> <span class="number">3840.0</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">2</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p><code>ppyoloe_plus_reader.yml</code>文件则是对输入图像的转换</p><p><code>optimizer_80e.yml</code>文件时优化器部分，规定了模型训练的轮数和基础学习率</p><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">epoch:</span> <span class="number">80</span></span><br><span class="line"></span><br><span class="line"><span class="attr">LearningRate:</span></span><br><span class="line">  <span class="attr">base_lr:</span> <span class="number">0.001</span></span><br><span class="line">  <span class="attr">schedulers:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">CosineDecay</span></span><br><span class="line">      <span class="attr">max_epochs:</span> <span class="number">96</span></span><br><span class="line">    <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">LinearWarmup</span></span><br><span class="line">      <span class="attr">start_factor:</span> <span class="number">0</span><span class="string">.</span></span><br><span class="line">      <span class="attr">epochs:</span> <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="attr">OptimizerBuilder:</span></span><br><span class="line">  <span class="attr">optimizer:</span></span><br><span class="line">    <span class="attr">momentum:</span> <span class="number">0.9</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">Momentum</span></span><br><span class="line">  <span class="attr">regularizer:</span></span><br><span class="line">    <span class="attr">factor:</span> <span class="number">0.0005</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">L2</span></span><br></pre></td></tr></table></figure><p>配置完上文后只需要一个命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python tools/train.py -c config/ppyoloe/ppyoloe_plus_crn_l_80e_coco.yml</span><br><span class="line"><span class="comment"># config/ppyoloe/ppyoloe_plus_crn_l_80e_coco.yml == path to your base model yml</span></span><br></pre></td></tr></table></figure><p>模型就会开始训练，至于训练的轮数则取决于模型何时收敛，可以在命令中加上</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python tools/train.py -c config/ppyoloe/ppyoloe_plus_crn_l_80e_coco.yml &gt; file_path</span><br></pre></td></tr></table></figure><p>将命令行保存到日志中方面查看 loss 数据</p><p>训练完成后训练后参数会保存到<code>./output</code>文件夹下，里面包含<code>.pdema</code>,<code>.pdopt</code>,<code>.pdparams</code>，三个文件，其中会包含每次保存的和最终的<code>model_final</code>，可以使用以下命令进行模型评估</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">python tools\infer.py \</span><br><span class="line">    -c configs\picodet\ppyoloe_crn_s_400e_coco.yml \</span><br><span class="line">    --infer_img=24dog\image\monkey0137.jpg \</span><br><span class="line">    --output_dir=infer_output --draw_threshold=0.5 \</span><br><span class="line">    -o weights=output\model_final.pdparams \</span><br><span class="line">    --use_vdl=True</span><br></pre></td></tr></table></figure><p>如果模型效果好的话，就可以直接输出模型</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">python tools/export_model.py \</span><br><span class="line">    -c configs/picodet/ppyoloe_crn_s_400e_coco.yml \</span><br><span class="line">    -o weights=output/model_final \</span><br><span class="line">    TestReader.fuse_normalize=<span class="literal">true</span></span><br></pre></td></tr></table></figure><p>下面提供模型的预测文件，使用此文件时需要确定能够读取到 PaddleDetection 库中<code>deploy/python</code>下的文件</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Copyright (c) 2020 PaddlePaddle Authors. All Rights Reserved.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment"># you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment"># You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"># See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"># limitations under the License.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> codecs</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment">#sys.path.append(&#x27;PaddleDetection&#x27;)</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> reduce</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">from</span> paddle.inference <span class="keyword">import</span> Config</span><br><span class="line"><span class="keyword">from</span> paddle.inference <span class="keyword">import</span> create_predictor</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> preprocess <span class="keyword">import</span> preprocess, Resize, NormalizeImage, Permute, PadStride</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> argsparser, Timer, get_current_memory_mb</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PredictConfig</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;set config of preprocess, postprocess and visualize</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        model_dir (str): root path of model.yml</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, model_dir</span>):</span><br><span class="line">        <span class="comment"># parsing Yaml config for Preprocess</span></span><br><span class="line">        deploy_file = os.path.join(model_dir, <span class="string">&#x27;infer_cfg.yml&#x27;</span>)</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(deploy_file) <span class="keyword">as</span> f:</span><br><span class="line">            yml_conf = yaml.safe_load(f)</span><br><span class="line">        self.arch = yml_conf[<span class="string">&#x27;arch&#x27;</span>]</span><br><span class="line">        self.preprocess_infos = yml_conf[<span class="string">&#x27;Preprocess&#x27;</span>]</span><br><span class="line">        self.min_subgraph_size = yml_conf[<span class="string">&#x27;min_subgraph_size&#x27;</span>]</span><br><span class="line">        self.labels = yml_conf[<span class="string">&#x27;label_list&#x27;</span>]</span><br><span class="line">        self.mask = <span class="literal">False</span></span><br><span class="line">        self.use_dynamic_shape = yml_conf[<span class="string">&#x27;use_dynamic_shape&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;mask&#x27;</span> <span class="keyword">in</span> yml_conf:</span><br><span class="line">            self.mask = yml_conf[<span class="string">&#x27;mask&#x27;</span>]</span><br><span class="line">        self.tracker = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;tracker&#x27;</span> <span class="keyword">in</span> yml_conf:</span><br><span class="line">            self.tracker = yml_conf[<span class="string">&#x27;tracker&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;NMS&#x27;</span> <span class="keyword">in</span> yml_conf:</span><br><span class="line">            self.nms = yml_conf[<span class="string">&#x27;NMS&#x27;</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;fpn_stride&#x27;</span> <span class="keyword">in</span> yml_conf:</span><br><span class="line">            self.fpn_stride = yml_conf[<span class="string">&#x27;fpn_stride&#x27;</span>]</span><br><span class="line">        self.print_config()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">print_config</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;%s: %s&#x27;</span> % (<span class="string">&#x27;Model Arch&#x27;</span>, self.arch))</span><br><span class="line">        <span class="keyword">for</span> op_info <span class="keyword">in</span> self.preprocess_infos:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;--%s: %s&#x27;</span> % (<span class="string">&#x27;transform op&#x27;</span>, op_info[<span class="string">&#x27;type&#x27;</span>]))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_test_images</span>(<span class="params">infer_file</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(infer_file, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        dirs = f.readlines()</span><br><span class="line">    images = []</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">dir</span> <span class="keyword">in</span> dirs:</span><br><span class="line">        images.append(<span class="built_in">eval</span>(<span class="built_in">repr</span>(<span class="built_in">dir</span>.replace(<span class="string">&#x27;\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>))).replace(<span class="string">&#x27;\\&#x27;</span>, <span class="string">&#x27;/&#x27;</span>))</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(images) &gt; <span class="number">0</span>, <span class="string">&quot;no image found in &#123;&#125;&quot;</span>.<span class="built_in">format</span>(infer_file)</span><br><span class="line">    <span class="keyword">return</span> images</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_predictor</span>(<span class="params">model_dir</span>):</span><br><span class="line">    config = Config(</span><br><span class="line">        os.path.join(model_dir, <span class="string">&#x27;model.pdmodel&#x27;</span>),</span><br><span class="line">        os.path.join(model_dir, <span class="string">&#x27;model.pdiparams&#x27;</span>))</span><br><span class="line">    <span class="comment"># initial GPU memory(M), device ID</span></span><br><span class="line">    config.enable_use_gpu(<span class="number">2000</span>, <span class="number">0</span>)</span><br><span class="line">    <span class="comment"># optimize graph and fuse op</span></span><br><span class="line">    config.switch_ir_optim(<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># disable print log when predict</span></span><br><span class="line">    config.disable_glog_info()</span><br><span class="line">    <span class="comment"># enable shared memory</span></span><br><span class="line">    config.enable_memory_optim()</span><br><span class="line">    <span class="comment"># disable feed, fetch OP, needed by zero_copy_run</span></span><br><span class="line">    config.switch_use_feed_fetch_ops(<span class="literal">False</span>)</span><br><span class="line">    predictor = create_predictor(config)</span><br><span class="line">    <span class="keyword">return</span> predictor, config</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_inputs</span>(<span class="params">imgs, im_info</span>):</span><br><span class="line">    inputs = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    im_shape = []</span><br><span class="line">    scale_factor = []</span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> im_info:</span><br><span class="line">        im_shape.append(np.array((e[<span class="string">&#x27;im_shape&#x27;</span>],)).astype(<span class="string">&#x27;float32&#x27;</span>))</span><br><span class="line">        scale_factor.append(np.array((e[<span class="string">&#x27;scale_factor&#x27;</span>],)).astype(<span class="string">&#x27;float32&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    origin_scale_factor = np.concatenate(scale_factor, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    imgs_shape = [[e.shape[<span class="number">1</span>], e.shape[<span class="number">2</span>]] <span class="keyword">for</span> e <span class="keyword">in</span> imgs]</span><br><span class="line">    max_shape_h = <span class="built_in">max</span>([e[<span class="number">0</span>] <span class="keyword">for</span> e <span class="keyword">in</span> imgs_shape])</span><br><span class="line">    max_shape_w = <span class="built_in">max</span>([e[<span class="number">1</span>] <span class="keyword">for</span> e <span class="keyword">in</span> imgs_shape])</span><br><span class="line">    padding_imgs = []</span><br><span class="line">    padding_imgs_shape = []</span><br><span class="line">    padding_imgs_scale = []</span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> imgs:</span><br><span class="line">        im_c, im_h, im_w = img.shape[:]</span><br><span class="line">        padding_im = np.zeros(</span><br><span class="line">            (im_c, max_shape_h, max_shape_w), dtype=np.float32)</span><br><span class="line">        padding_im[:, :im_h, :im_w] = np.array(img, dtype=np.float32)</span><br><span class="line">        padding_imgs.append(padding_im)</span><br><span class="line">        padding_imgs_shape.append(</span><br><span class="line">            np.array([max_shape_h, max_shape_w]).astype(<span class="string">&#x27;float32&#x27;</span>))</span><br><span class="line">        rescale = [<span class="built_in">float</span>(max_shape_h) / <span class="built_in">float</span>(im_h), <span class="built_in">float</span>(max_shape_w) / <span class="built_in">float</span>(im_w)]</span><br><span class="line">        padding_imgs_scale.append(np.array(rescale).astype(<span class="string">&#x27;float32&#x27;</span>))</span><br><span class="line">    inputs[<span class="string">&#x27;image&#x27;</span>] = np.stack(padding_imgs, axis=<span class="number">0</span>)</span><br><span class="line">    inputs[<span class="string">&#x27;im_shape&#x27;</span>] = np.stack(padding_imgs_shape, axis=<span class="number">0</span>)</span><br><span class="line">    inputs[<span class="string">&#x27;scale_factor&#x27;</span>] = origin_scale_factor</span><br><span class="line">    <span class="keyword">return</span> inputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Detector</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 pred_config,</span></span><br><span class="line"><span class="params">                 model_dir,</span></span><br><span class="line"><span class="params">                 device=<span class="string">&#x27;CPU&#x27;</span>,</span></span><br><span class="line"><span class="params">                 run_mode=<span class="string">&#x27;paddle&#x27;</span>,</span></span><br><span class="line"><span class="params">                 batch_size=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 trt_min_shape=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 trt_max_shape=<span class="number">1280</span>,</span></span><br><span class="line"><span class="params">                 trt_opt_shape=<span class="number">640</span>,</span></span><br><span class="line"><span class="params">                 trt_calib_mode=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                 cpu_threads=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                 enable_mkldnn=<span class="literal">False</span></span>):</span><br><span class="line">        self.pred_config = pred_config</span><br><span class="line">        self.predictor, self.config = load_predictor(model_dir)</span><br><span class="line">        self.det_times = Timer()</span><br><span class="line">        self.cpu_mem, self.gpu_mem, self.gpu_util = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">        self.preprocess_ops = self.get_ops()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_ops</span>(<span class="params">self</span>):</span><br><span class="line">        preprocess_ops = []</span><br><span class="line">        <span class="keyword">for</span> op_info <span class="keyword">in</span> self.pred_config.preprocess_infos:</span><br><span class="line">            new_op_info = op_info.copy()</span><br><span class="line">            op_type = new_op_info.pop(<span class="string">&#x27;type&#x27;</span>)</span><br><span class="line">            preprocess_ops.append(<span class="built_in">eval</span>(op_type)(**new_op_info))</span><br><span class="line">        <span class="keyword">return</span> preprocess_ops</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        <span class="comment"># preprocess</span></span><br><span class="line">        input_names = self.predictor.get_input_names()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(input_names)):</span><br><span class="line">            input_tensor = self.predictor.get_input_handle(input_names[i])</span><br><span class="line">            input_tensor.copy_from_cpu(inputs[input_names[i]])</span><br><span class="line"></span><br><span class="line">        np_boxes, np_boxes_num = [], []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># model_prediction</span></span><br><span class="line">        self.predictor.run()</span><br><span class="line">        np_boxes.clear()</span><br><span class="line">        np_boxes_num.clear()</span><br><span class="line">        output_names = self.predictor.get_output_names()</span><br><span class="line">        num_outs = <span class="built_in">int</span>(<span class="built_in">len</span>(output_names) / <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> out_idx <span class="keyword">in</span> <span class="built_in">range</span>(num_outs):</span><br><span class="line">            np_boxes.append(</span><br><span class="line">                self.predictor.get_output_handle(output_names[out_idx])</span><br><span class="line">                .copy_to_cpu())</span><br><span class="line">            np_boxes_num.append(</span><br><span class="line">                self.predictor.get_output_handle(output_names[</span><br><span class="line">                                                     out_idx + num_outs]).copy_to_cpu())</span><br><span class="line"></span><br><span class="line">        np_boxes, np_boxes_num = np.array(np_boxes[<span class="number">0</span>]), np.array(np_boxes_num[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">dict</span>(boxes=np_boxes, boxes_num=np_boxes_num)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict_image</span>(<span class="params">detector, image_list, result_path, threshold</span>):</span><br><span class="line">    c_results = &#123;<span class="string">&quot;result&quot;</span>: []&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(image_list)):</span><br><span class="line">        <span class="comment"># 检测模型图像预处理</span></span><br><span class="line">        input_im_lst = []</span><br><span class="line">        input_im_info_lst = []</span><br><span class="line"></span><br><span class="line">        im_path = image_list[index]</span><br><span class="line">        im, im_info = preprocess(im_path, detector.preprocess_ops)</span><br><span class="line"></span><br><span class="line">        input_im_lst.append(im)</span><br><span class="line">        input_im_info_lst.append(im_info)</span><br><span class="line">        inputs = create_inputs(input_im_lst, input_im_info_lst)</span><br><span class="line"></span><br><span class="line">        image_id = os.path.basename(im_path).split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 检测模型预测结果</span></span><br><span class="line">        det_results = detector.predict(inputs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 检测模型写结果</span></span><br><span class="line">        im_bboxes_num = det_results[<span class="string">&#x27;boxes_num&#x27;</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> im_bboxes_num &gt; <span class="number">0</span>:</span><br><span class="line">            bbox_results = det_results[<span class="string">&#x27;boxes&#x27;</span>][<span class="number">0</span>:im_bboxes_num, <span class="number">2</span>:]</span><br><span class="line">            id_results = det_results[<span class="string">&#x27;boxes&#x27;</span>][<span class="number">0</span>:im_bboxes_num, <span class="number">0</span>]</span><br><span class="line">            score_results = det_results[<span class="string">&#x27;boxes&#x27;</span>][<span class="number">0</span>:im_bboxes_num, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(im_bboxes_num):</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">float</span>(score_results[idx]) &gt;= threshold:</span><br><span class="line">                    c_results[<span class="string">&quot;result&quot;</span>].append(&#123;<span class="string">&quot;image_id&quot;</span>: image_id,</span><br><span class="line">                                                <span class="string">&quot;type&quot;</span>: <span class="built_in">int</span>(id_results[idx]) + <span class="number">1</span>,</span><br><span class="line">                                                <span class="string">&quot;x&quot;</span>: <span class="built_in">float</span>(bbox_results[idx][<span class="number">0</span>]),</span><br><span class="line">                                                <span class="string">&quot;y&quot;</span>: <span class="built_in">float</span>(bbox_results[idx][<span class="number">1</span>]),</span><br><span class="line">                                                <span class="string">&quot;width&quot;</span>: <span class="built_in">float</span>(bbox_results[idx][<span class="number">2</span>]) - <span class="built_in">float</span>(bbox_results[idx][<span class="number">0</span>]),</span><br><span class="line">                                                <span class="string">&quot;height&quot;</span>: <span class="built_in">float</span>(bbox_results[idx][<span class="number">3</span>]) - <span class="built_in">float</span>(bbox_results[idx][<span class="number">1</span>]),</span><br><span class="line">                                                <span class="string">&quot;segmentation&quot;</span>: []&#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 写文件</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(result_path, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> ft:</span><br><span class="line">        json.dump(c_results, ft)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>(<span class="params">infer_txt, result_path, det_model_path, threshold</span>):</span><br><span class="line">    pred_config = PredictConfig(det_model_path)</span><br><span class="line">    detector = Detector(pred_config, det_model_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># predict from image</span></span><br><span class="line">    img_list = get_test_images(infer_txt)</span><br><span class="line">    predict_image(detector, img_list, result_path, threshold)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    det_model_path = <span class="string">&quot;model/base&quot;</span> <span class="comment">#export model path</span></span><br><span class="line"></span><br><span class="line">    threshold = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">    paddle.enable_static()</span><br><span class="line">    infer_txt = sys.argv[<span class="number">1</span>]</span><br><span class="line">    result_path = sys.argv[<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    main(infer_txt, result_path, det_model_path, threshold)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;total time:&#x27;</span>, time.time() - start_time)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>预测文件的使用方法为</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">python predict.py data.txt result.json</span><br><span class="line"><span class="comment">#data中应当包含需要预测的文件路径，result.json则是预测结果的输出</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 杂学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>LLaMA-Factory使用</title>
      <link href="/%E6%9D%82%E5%AD%A6/LLaMA-Factory%E4%BD%BF%E7%94%A8/"/>
      <url>/%E6%9D%82%E5%AD%A6/LLaMA-Factory%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="LLaMA-Factory-使用"><a href="#LLaMA-Factory-使用" class="headerlink" title="LLaMA-Factory 使用"></a>LLaMA-Factory 使用</h1><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/llamafactory.png" alt="llamafactory"></p><h2 id="安装-LLaMA-Factory"><a href="#安装-LLaMA-Factory" class="headerlink" title="安装 LLaMA-Factory"></a>安装 LLaMA-Factory</h2><p>首先先去 github 上 clone LLaMA-Factory 项目到本地</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/hiyouga/LLaMA-Factory.git</span><br><span class="line"><span class="built_in">cd</span> LLaMA-Factory</span><br><span class="line">pip install -e .[torch,metrics]</span><br><span class="line"><span class="comment">#.[]中可以填写&#123;torch, metrics, deepspeed, bitsandbytes, vllm, galore, badam, gptq, awq, aqlm, qwen, modelscope, quality&#125;</span></span><br><span class="line"><span class="comment"># 按需填写，比较推荐直接把vllm和modelscope下载了.</span></span><br></pre></td></tr></table></figure><p>因为我是单卡(多卡的话就不能用 webui)，所以直接运行的是 webui 的部分，比较直观也比较好调参数，具体开启代码在<code>LLaMA-Factory/src/llmtuner/webui</code>里，<code>LLaMA-Factory/src/llmtuner/webui/interface.py</code>中</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">run_web_ui</span>() -&gt; <span class="literal">None</span>:</span><br><span class="line">    create_ui().queue().launch() <span class="comment">#.launch()中可以添加server_port=port指定gradio开启的窗口</span></span><br></pre></td></tr></table></figure><p>输入命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=0 GRADIO_SHARE=1 llamafactory-cli webui</span><br></pre></td></tr></table></figure><p>或者直接新建一个脚本</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> src.llmtuner.webui.interface <span class="keyword">import</span> run_web_demo, run_web_ui</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="string">&quot;0&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    run_web_ui()</span><br></pre></td></tr></table></figure><p>用来开启 webui</p><h2 id="配置-LLaMA-Factory"><a href="#配置-LLaMA-Factory" class="headerlink" title="配置 LLaMA-Factory"></a>配置 LLaMA-Factory</h2><p>为了方便下载模型直接加了这个脚本，具体可以去 modelscope 里找</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 模型下载</span></span><br><span class="line"><span class="keyword">from</span> modelscope <span class="keyword">import</span> snapshot_download</span><br><span class="line"></span><br><span class="line">model_dir = snapshot_download(<span class="string">&quot;ZhipuAI/chatglm3-6b&quot;</span>, revision = <span class="string">&quot;v1.0.0&quot;</span>, cache_dir=<span class="string">&#x27;models&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">model_id = &#123;&#x27;baicai003/Phi-3-mini-128k-instruct-Chinese&#x27;,</span></span><br><span class="line"><span class="string">            &#x27;LLM-Research/Phi-3-mini-4k-instruct&#x27;,</span></span><br><span class="line"><span class="string">            &#x27;ChineseAlpacaGroup/llama-3-chinese-8b-instruct&#x27;,</span></span><br><span class="line"><span class="string">            &quot;ZhipuAI/chatglm3-6b&quot;, revision = &quot;v1.0.0&quot;&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># &quot;ZhipuAI/chatglm3-6b&quot;, revision = &quot;v1.0.0&quot;</span></span><br></pre></td></tr></table></figure><p>运行 webui 后打开 gradio 界面如下<br><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/llamawebui.png" alt="webui"></p><h2 id="训练模型"><a href="#训练模型" class="headerlink" title="训练模型"></a>训练模型</h2><ul><li>模型路径就是 models 的下载位置，按照上面的脚本会直接下载在 models 文件夹下</li><li>数据集的话我都是以以下格式然后还需要到<code>LLaMA-Factory/data/dataset_info.json</code>中根据格式填写。<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;&quot;</span><span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;&quot;</span><span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;&quot;</span><span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>dataset_info.json 添加，以我使用的 geo_signal 为例<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;geo_signal&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line"><span class="attr">&quot;file_name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;geo_signal.json&quot;</span><span class="punctuation">,</span></span><br><span class="line"><span class="attr">&quot;file_sha1&quot;</span><span class="punctuation">:</span> <span class="string">&quot;32633118B240079DA7C8D2C244978311AB4AE0E0&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>SHA1 可以通过以下命令获得<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Get-FileHash -p <span class="string">&quot;file_path&quot;</span> -Algorithm SHA1</span><br></pre></td></tr></table></figure></li><li>然后就可以在数据集里找到刚刚添加的数据集，接下来就是训练部分，默认使用 lora</li></ul><p><strong>一般以 loss 降低到 0.5 为目标，训练阶段就是微调，然后学习率就按默认，我训练次数比较小时会跳到 5e-4，如果数据集够大，训练轮数一般 3 次以内就够了，目标就是让 loss 降到 0.5 左右，如果显存够用可以把 batch_size 调高，此时 lr 也应该相对应加大一点点，理论上现在就可以直接预览命令然后开始训练了。</strong><br>如果不使用 webui 也可以按照 webui 中给出的<code>预览命令</code>进行修改</p><h2 id="使用模型进行预测"><a href="#使用模型进行预测" class="headerlink" title="使用模型进行预测"></a>使用模型进行预测</h2><p>训练完成后可以去 Chat 中，选择适配器，名字就是输出目录里的名字，加载模型后就可以聊天，然后要是效果好就可以直接导出</p><h2 id="多卡训练"><a href="#多卡训练" class="headerlink" title="多卡训练"></a>多卡训练</h2><p>多卡训练的我没用过，具体可以参考<a href="https://github.com/hiyouga/LLaMA-Factory/blob/main/examples/README_zh.md">LLaMA-Factory 的 README 文件</a></p>]]></content>
      
      
      <categories>
          
          <category> 杂学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CUDA的安装</title>
      <link href="/%E6%9D%82%E5%AD%A6/cuda%E7%9A%84%E5%AE%89%E8%A3%85/"/>
      <url>/%E6%9D%82%E5%AD%A6/cuda%E7%9A%84%E5%AE%89%E8%A3%85/</url>
      
        <content type="html"><![CDATA[<h1 id="Ubuntu-20-04-安装-CUDA-Toolkit-的三种方式"><a href="#Ubuntu-20-04-安装-CUDA-Toolkit-的三种方式" class="headerlink" title="Ubuntu 20.04 安装 CUDA Toolkit 的三种方式"></a>Ubuntu 20.04 安装 CUDA Toolkit 的三种方式</h1><p>在安装 CUDA Toolkit 之前，首先需要更新 Ubuntu 软件源和升级到最新版本的软件包。由于国内从 Ubuntu 官方软件源下载速度较慢，建议使用国内 Ubuntu 镜像源，例如阿里 Ubuntu 软件源或清华大学 Ubuntu 软件源。具体配置方式是修改配置文件 <code>/etc/apt/sources.list</code>，将其中的 <code>archive.ubuntu.com</code> 替换为 <code>mirrors.alibaba.com</code> 或 <code>mirrors.tuna.tsinghua.edu.cn</code>。也可以在图形界面应用 “Software &amp; Update” 中，修改 Ubuntu Software 标签页中的 Download from 后的软件源地址。<br>配置软件源后，使用以下命令进行软件源的更新和软件包的升级。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt upgrade</span><br></pre></td></tr></table></figure><p>下面介绍在 Ubuntu 20.04 长期支持版本中，安装 CUDA Tools 的三种方式：</p><h3 id="方式一：采用-Ubuntu-软件源中的-CUDA-Tools-软件包"><a href="#方式一：采用-Ubuntu-软件源中的-CUDA-Tools-软件包" class="headerlink" title="方式一：采用 Ubuntu 软件源中的 CUDA Tools 软件包"></a>方式一：采用 Ubuntu 软件源中的 CUDA Tools 软件包</h3><p>这种方式安装简单，但安装的 CUDA Toolkit 版本往往不是最新版本。查询目前可安装的 CUDA Toolkit 版本的命令如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt search nvidia-cuda-toolkit</span><br></pre></td></tr></table></figure><p>具体安装命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install nvidia-cuda-toolkit</span><br></pre></td></tr></table></figure><h3 id="方式二：先采用图形界面安装-CUDA-驱动，再安装从-NVIDIA-官网下载的-CUDA-Toolkit-安装包"><a href="#方式二：先采用图形界面安装-CUDA-驱动，再安装从-NVIDIA-官网下载的-CUDA-Toolkit-安装包" class="headerlink" title="方式二：先采用图形界面安装 CUDA 驱动，再安装从 NVIDIA 官网下载的 CUDA Toolkit 安装包"></a>方式二：先采用图形界面安装 CUDA 驱动，再安装从 NVIDIA 官网下载的 CUDA Toolkit 安装包</h3><h4 id="1）图形界面安装-CUDA-驱动"><a href="#1）图形界面安装-CUDA-驱动" class="headerlink" title="1）图形界面安装 CUDA 驱动"></a>1）图形界面安装 CUDA 驱动</h4><p>在所有应用中，选择 “Software &amp; Update” 应用，在标签页 “Additional Drivers” 中选择 “nvidia-driver-450-server”<br>选择后，单击 “Apply Changes” 按钮，这样就更新并切换到所选驱动。<br>使用快捷键 <code>Ctrl + Alt + T</code> 打开 Terminal，运行 <code>nvidia-smi</code> 命令以验证切换到 CUDA 驱动是否成功。我尝试过 <code>nvidia-driver-460</code> 这个版本，但没有成功，因此使用稍低的版本 <code>nvidia-driver-450-server</code>。</p><h4 id="2）下载并安装-CUDA-Toolkit"><a href="#2）下载并安装-CUDA-Toolkit" class="headerlink" title="2）下载并安装 CUDA Toolkit"></a>2）下载并安装 CUDA Toolkit</h4><p>本机安装的 CUDA Toolkit 版本为 11.0.3，与上一步安装的 CUDA 驱动 450 兼容（可以参考下载文件名的尾缀）。具体下载命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/11.0.3/local_installers/cuda_11.0.3_450.51.06_linux.run</span><br></pre></td></tr></table></figure><p>安装命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo sh cuda_11.0.3_450.51.06_linux.run</span><br></pre></td></tr></table></figure><p>需要注意，在安装时，选择不安装 CUDA 驱动。安装记录如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">===========</span><br><span class="line">= Summary =</span><br><span class="line">===========</span><br><span class="line">Driver:   Not Selected</span><br><span class="line">Toolkit:  Installed <span class="keyword">in</span> /usr/local/cuda-11.0/</span><br><span class="line">Samples:  Installed <span class="keyword">in</span> /home/klchang/, but missing recommended libraries</span><br><span class="line">Please make sure that</span><br><span class="line"> -   PATH includes /usr/local/cuda-11.0/bin</span><br><span class="line"> -   LD_LIBRARY_PATH includes /usr/local/cuda-11.0/lib64, or, add /usr/local/cuda-11.0/lib64 to /etc/ld.so.conf and run ldconfig as root</span><br><span class="line">To uninstall the CUDA Toolkit, run cuda-uninstaller <span class="keyword">in</span> /usr/local/cuda-11.0/bin</span><br><span class="line">***WARNING: Incomplete installation! This installation did not install the CUDA Driver. A driver of version at least .00 is required <span class="keyword">for</span> CUDA 11.0 functionality to work.</span><br><span class="line">To install the driver using this installer, run the following <span class="built_in">command</span>, replacing &lt;CudaInstaller&gt; with the name of this run file:</span><br><span class="line">    sudo &lt;CudaInstaller&gt;.run --silent --driver</span><br><span class="line">Logfile is /var/log/cuda-installer.log</span><br></pre></td></tr></table></figure><p>安装结束后，需要添加环境变量到 <code>~/.bashrc</code> 文件的末尾，具体添加内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="variable">$LD_LIBRARY_PATH</span>:/usr/local/cuda/lib64</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:/usr/local/cuda/bin</span><br><span class="line"><span class="built_in">export</span> CUDA_HOME=<span class="variable">$CUDA_HOME</span>:/usr/local/cuda</span><br></pre></td></tr></table></figure><p>保存后退出编辑器。在 Terminal 中，激活环境变量的命令为：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure><p>测试 CUDA Toolkit。通过编译自带 Samples 并执行，以验证是否安装成功。具体命令如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/cuda/samples/1_Utilities/deviceQuery</span><br><span class="line">sudo make</span><br><span class="line">./deviceQuery</span><br></pre></td></tr></table></figure><p>如果安装成功，则输出类似于如下信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">./deviceQuery Starting...</span><br><span class="line"></span><br><span class="line"> CUDA Device Query (Runtime API) version (CUDART static linking)</span><br><span class="line"></span><br><span class="line">Detected 1 CUDA Capable device(s)</span><br><span class="line"></span><br><span class="line">Device 0: <span class="string">&quot;GeForce RTX 2070 with Max-Q Design&quot;</span></span><br><span class="line">  CUDA Driver Version / Runtime Version          11.0 / 11.0</span><br><span class="line">  CUDA Capability Major/Minor version number:    7.5</span><br><span class="line">  Total amount of global memory:                 7982 MBytes (8370061312 bytes)</span><br><span class="line">  (36) Multiprocessors, ( 64) CUDA Cores/MP:     2304 CUDA Cores</span><br><span class="line">  GPU Max Clock rate:                            1125 MHz (1.12 GHz)</span><br><span class="line">  Memory Clock rate:                             5501 Mhz</span><br><span class="line">  Memory Bus Width:                              256-bit</span><br><span class="line">  L2 Cache Size:                                 4194304 bytes</span><br><span class="line">  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)</span><br><span class="line">  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers</span><br><span class="line">  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers</span><br><span class="line">  Total amount of constant memory:               65536 bytes</span><br><span class="line">  Total amount of shared memory per block:       49152 bytes</span><br><span class="line">  Total number of registers available per block: 65536</span><br><span class="line">  Warp size:                                     32</span><br><span class="line">  Maximum number of threads per multiprocessor:  1024</span><br><span class="line">  Maximum number of threads per block:           1024</span><br><span class="line">  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)</span><br><span class="line">  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)</span><br><span class="line">  Maximum memory pitch:                          2147483647 bytes</span><br><span class="line">  Texture alignment:                             512 bytes</span><br><span class="line">  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)</span><br><span class="line">  Run time <span class="built_in">limit</span> on kernels:                     Yes</span><br><span class="line">  Integrated GPU sharing Host Memory:            No</span><br><span class="line">  Support host page-locked memory mapping:       Yes</span><br><span class="line">  Alignment requirement <span class="keyword">for</span> Surfaces:            Yes</span><br><span class="line">  Device has ECC support:                        Disabled</span><br><span class="line">  Device supports Unified Addressing (UVA):      Yes</span><br><span class="line">  Device supports Managed Memory:                Yes</span><br><span class="line">  Device supports Compute Preemption:            Yes</span><br><span class="line">  Supports Cooperative Kernel Launch:            Yes</span><br><span class="line">  Supports MultiDevice Co-op Kernel Launch:      Yes</span><br><span class="line">  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0</span><br><span class="line">  Compute Mode:</span><br><span class="line">     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;</span><br><span class="line"></span><br><span class="line">deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 11.0, CUDA Runtime Version = 11.0, NumDevs = 1</span><br><span class="line">Result = PASS</span><br></pre></td></tr></table></figure><h4 id="3）下载并安装-cuDNN"><a href="#3）下载并安装-cuDNN" class="headerlink" title="3）下载并安装 cuDNN"></a>3）下载并安装 cuDNN</h4><p>从 NVIDIA 官方网址  <a href="https://developer.nvidia.com/rdp/cudnn-download">https://developer.nvidia.com/rdp/cudnn-download</a> 下载 cudnn-11.0-linux-x64-v8.0.5.39.tgz 。</p><p>解压压缩包，并把相应的文件，复制到指定目录即可。如下所示：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar zxvf cudnn-11.0-linux-x64-v8.0.5.39.tgz </span><br><span class="line">sudo <span class="built_in">cp</span> cuda/include/cudnn* /usr/local/cuda/include</span><br><span class="line">sudo <span class="built_in">cp</span> cuda/lib64/libcudnn* /usr/local/cuda/lib64</span><br><span class="line">sudo <span class="built_in">chmod</span> a+r /usr/local/cuda/include/cudnn* /usr/local/cuda/lib64/libcudnn*</span><br></pre></td></tr></table></figure></p><h3 id="方式三：CUDA-驱动和-CUDA-Toolkit-都采用命令行方式安装"><a href="#方式三：CUDA-驱动和-CUDA-Toolkit-都采用命令行方式安装" class="headerlink" title="方式三：CUDA 驱动和 CUDA Toolkit 都采用命令行方式安装"></a>方式三：CUDA 驱动和 CUDA Toolkit 都采用命令行方式安装</h3><p>首先，需要卸载原有的 NVIDIA 驱动并禁用自带的驱动 nouveau；然后，重启电脑，使用 lsmod | grep nouveau 命令检查禁用自带驱动是否成功；如果禁用成功，则安装从 NVIDIA 官方地址下载的<a href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA Toolkit</a>。其步骤则与方式二相同，差别在于这次需要安装 CUDA 驱动 。更多内容，参见 <a href="https://beyondstateoftheart.medium.com/install-cuda-toolkit-install-nvidia-driver-ubuntu20-04-1634685ed68a">How to Install CUDA ToolKit 11.0, and Nvidia Display Driver on Ubuntu 20.04</a>。</p><h2 id="3-2-安装-cuDNN"><a href="#3-2-安装-cuDNN" class="headerlink" title="3.2 安装 cuDNN"></a>3.2 安装 cuDNN</h2><p>访问 cuDNN 的存档页面 <a href="https://developer.nvidia.com/rdp/cudnn-archive">cuDNN Archive | NVIDIA Developer</a>，注册一个账户，并选择与您的 CUDA Toolkit 版本相匹配的 cuDNN 包。例如，如果您的 CUDA Toolkit 版本是 11.5，那么您应该选择 “Download cuDNN v8.3.0 (November 3rd, 2021), for CUDA 11.5；cuDNN Library for Linux (x86_64)”。<br>下载的文件是一个 <code>.tgz</code> 文件，您可以将其保存到 Windows 的默认下载路径中。由于 WSL2 可以完全访问您的主机文件系统，您可以在 Ubuntu 命令行中导航到保存该包的文件夹，并执行以下安装命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf cudnn-版本号.tgz</span><br><span class="line">sudo <span class="built_in">cp</span> -P cuda/lib64/libcudnn* /usr/local/cuda-11.5（根据您的版本修改路径）/lib64/</span><br><span class="line">sudo <span class="built_in">cp</span> cuda/include/cudnn.h /usr/local/cuda-11.5（根据您的版本修改路径）/include/</span><br></pre></td></tr></table></figure><br>为了更改文件的读取权限，执行以下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">chmod</span> a+r /usr/local/cuda-11.5（根据您的版本修改路径）/include/cudnn.h</span><br><span class="line">sudo <span class="built_in">chmod</span> a+r /usr/local/cuda-11.5（根据您的版本修改路径）/lib64/libcudnn*</span><br></pre></td></tr></table></figure><br>最后，为了检验 CUDA 是否能够正常运行，您可以尝试编译并运行 CUDA 自带的测试文件。找到测试项目 <code>BlackScholes</code>：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/local/cuda/samples/4_Finance/BlackScholes</span><br></pre></td></tr></table></figure><br>进行编译：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo make</span><br></pre></td></tr></table></figure><br>在当前目录查看编译结果并运行：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./BlackScholes</span><br></pre></td></tr></table></figure><br>如果运行后输出类似以下结果，那么代表 CUDA 运行正常：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[./BlackScholes] - Starting...</span><br><span class="line">GPU Device 0: &quot;Turing&quot; with compute capability 7.5</span><br></pre></td></tr></table></figure><br>请确保在实际执行命令时，将 <code>版本号</code>、<code>cuda-11.5</code> 等占位符替换为实际的版本号和路径。</p>]]></content>
      
      
      <categories>
          
          <category> 杂学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>准备环境</title>
      <link href="/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E5%87%86%E5%A4%87%E7%8E%AF%E5%A2%83/"/>
      <url>/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E5%87%86%E5%A4%87%E7%8E%AF%E5%A2%83/</url>
      
        <content type="html"><![CDATA[<h1 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h1><p>在我们开始编程之前，在你的机器上设置好一切是非常重要的。在本书中，我们将使用 Ubuntu 18.04 和 Python 3.7.6。如果你是 Windows 用户，可以通过多种方式安装 Ubuntu。例如，在虚拟机上安装由 Oracle 公司提供的免费软件 Virtual Box。与 Windows 一起作为双启动系统。我更喜欢双启动，因为它是原生的。如果你不是 Ubuntu 用户，在使用本书中的某些 bash 脚本时可能会遇到问题。为了避免这种情况，你可以在虚拟机中安装 Ubuntu，或者在 Windows 上安装 Linux shell。</p><p>用 Anaconda 在任何机器上安装 Python 都很简单。我特别喜欢 <strong>Miniconda</strong>，它是 conda 的最小安装程序。它适用于 Linux、OSX 和 Windows。由于 Python 2 支持已于 2019 年底结束，我们将使用 Python 3 发行版。需要注意的是，miniconda 并不像普通 Anaconda 附带所有软件包。因此，我们随时安装新软件包。安装 miniconda 非常简单。</p><p>首先要做的是将 <strong>Miniconda3</strong> 下载到系统中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ~/Downloads</span><br><span class="line">wget https://repo.anaconda.com/miniconda/...</span><br></pre></td></tr></table></figure><p>其中 wget 命令后的 URL 是 miniconda3 网页的 URL。对于 64 位 Linux 系统，编写本书时的 URL 是</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><p>下载 miniconda3 后，可以运行以下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh Miniconda3-latest-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><p>接下来，请阅读并按照屏幕上的说明操作。如果安装正确，你应该可以通过在终端输入 conda init 来启动 conda 环境。我们将创建一个在本书中一直使用的 conda 环境。要创建 conda 环境，可以输入：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n environment_name python=3.7.6</span><br></pre></td></tr></table></figure><p>此命令将创建名为 environment_name 的 conda 环境，可以使用：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate environment_name</span><br></pre></td></tr></table></figure><p>现在我们的环境已经搭建完毕。是时候安装一些我们会用到的软件包了。在 conda 环境中，安装软件包有两种不同的方式。 你可以从 conda 仓库或 PyPi 官方仓库安装软件包。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda/pip install package_name</span><br></pre></td></tr></table></figure><p>注意：某些软件包可能无法在 conda 软件仓库中找到。因此，在本书中，使用 pip 安装是最可取的方法。我已经创建了一个编写本书时使用的软件包列表，保存在 environment.yml 中。 你可以在我的 GitHub 仓库中的额外资料中找到它。你可以使用以下命令创建环境：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda env create -f environment.yml</span><br></pre></td></tr></table></figure><p>该命令将创建一个名为 ml 的环境。要激活该环境并开始使用，应运行：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate ml</span><br></pre></td></tr></table></figure><p>现在我们已经准备就绪，可以进行一些应用机器学习的工作了！在使用本书进行编码时，请始终记住要在 “ml “环境下进行。现在，让我们开始学习真正的第一章。</p>]]></content>
      
      
      <categories>
          
          <category> AAAMLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>可重复代码和模型方法</title>
      <link href="/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E5%8F%AF%E9%87%8D%E5%A4%8D%E4%BB%A3%E7%A0%81%E5%92%8C%E6%A8%A1%E5%9E%8B%E6%96%B9%E6%B3%95/"/>
      <url>/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E5%8F%AF%E9%87%8D%E5%A4%8D%E4%BB%A3%E7%A0%81%E5%92%8C%E6%A8%A1%E5%9E%8B%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="可重复代码和模型方法"><a href="#可重复代码和模型方法" class="headerlink" title="可重复代码和模型方法"></a>可重复代码和模型方法</h1><p>我们现在已经到了可以将模型/训练代码分发给他人使用的阶段。您可以用软盘分发或与他人共享代码，但这并不理想。是这样吗？也许很多年前，这是理想的做法，但现在不是了。 与他人共享代码和协作的首选方式是使用源代码管理系统。Git 是最流行的源代码管理系统之一。那么，假设你已经学会了 Git，并正确地格式化了代码，编写了适当的文档，还开源了你的项目。这就够了吗？不，还不够。因为你在自己的电脑上写的代码，在别人的电脑上可能会因为各种原因而无法运行。因此，如果您在发布代码时能复制自己的电脑，而其他人在安装您的软件或运行您的代码时也能复制您的电脑，那就再好不过了。为此，如今最流行的方法是使用 Docker 容器（Docker Containers）。要使用 Docker 容器，你需要安装 Docker。</p><p>让我们用下面的命令来安装 Docker。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install docker.io</span><br><span class="line">sudo systemctl start docker</span><br><span class="line">sudo systemctl enable docker</span><br><span class="line">sudo groupadd docker</span><br><span class="line">sudo usermod -aG docker $USER</span><br></pre></td></tr></table></figure><p>这些命令可以在 Ubuntu 18.04 上运行。Docker 最棒的地方在于它可以安装在任何机器上： Linux、Windows、OSX。因此，如果你一直在 Docker 容器中工作，哪台机器都没关系！</p><p>Docker 容器可以被视为小型虚拟机。你可以为你的代码创建一个容器，然后每个人都可以使用和访问它。让我们看看如何创建可用于训练模型的容器。我们将使用在自然语言处理一章中训练的 BERT 模型，并尝试将训练代码容器化。</p><p>首先，你需要一个包含 python 项目需求的文件。需求包含在名为 requirements.txt 的文件中。文件名是 thestandard。该文件包含项目中使用的所有 python 库。也就是可以通过 PyPI (pip) 下载的 python 库。用于 训练 BERT 模型以检测正/负情感，我们使用了 torch、transformers、tqdm、scikit-learn、pandas 和 numpy。 让我们把它们写入 requirements.txt 中。你可以只写名称，也可以包括版本。包含版本总是最好的，这也是你应该做的。包含版本后，可以确保其他人使用的版本与你的版本相同，而不是最新版本，因为最新版本可能会更改某些内容，如果是这样的话，模型的训练方式就不会与你的相同了。</p><p>下面的代码段显示了 requirements.txt。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># requirements.txt</span></span><br><span class="line">pandas==<span class="number">1.0</span><span class="number">.4</span></span><br><span class="line">scikit-learn==<span class="number">0.22</span><span class="number">.1</span></span><br><span class="line">torch==<span class="number">1.5</span><span class="number">.0</span></span><br><span class="line">transformers==<span class="number">2.11</span><span class="number">.0</span></span><br></pre></td></tr></table></figure><p>现在，我们将创建一个名为 Dockerfile 的 Docker 文件。没有扩展名。Dockerfile 有几个元素。让我们来看看。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Dockerfile</span></span><br><span class="line"><span class="comment"># First of all, we include where we are getting the image</span></span><br><span class="line"><span class="comment"># from. Image can be thought of as an operating system.</span></span><br><span class="line"><span class="comment"># You can do &quot;FROM ubuntu:18.04&quot;</span></span><br><span class="line"><span class="comment"># this will start from a clean ubuntu 18.04 image.</span></span><br><span class="line"><span class="comment"># All images are downloaded from dockerhub</span></span><br><span class="line"><span class="comment"># Here are we grabbing image from nvidia&#x27;s repo</span></span><br><span class="line"><span class="comment"># they created a docker image using ubuntu 18.04</span></span><br><span class="line"><span class="comment"># and installed cuda 10.1 and cudnn7 in it. Thus, we don&#x27;t have to</span></span><br><span class="line"><span class="comment"># install it. Makes our life easy.</span></span><br><span class="line"><span class="keyword">FROM</span> nvidia/cuda:<span class="number">10.1</span>-cudnn7-runtime-ubuntu18.<span class="number">04</span></span><br><span class="line"><span class="comment"># this is the same apt-get command that you are used to</span></span><br><span class="line"><span class="comment"># except the fact that, we have -y argument. Its because</span></span><br><span class="line"><span class="comment"># when we build this container, we cannot press Y when asked for</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apt-get update &amp;&amp; apt-get install -y \</span></span><br><span class="line"><span class="language-bash">git \</span></span><br><span class="line"><span class="language-bash">curl \</span></span><br><span class="line"><span class="language-bash">ca-certificates \</span></span><br><span class="line"><span class="language-bash">python3 \</span></span><br><span class="line"><span class="language-bash">python3-pip \</span></span><br><span class="line"><span class="language-bash">sudo \</span></span><br><span class="line"><span class="language-bash">&amp;&amp; <span class="built_in">rm</span> -rf /var/lib/apt/lists/*</span></span><br><span class="line"><span class="comment"># We add a new user called &quot;abhishek&quot;</span></span><br><span class="line"><span class="comment"># this can be anything. Anything you want it</span></span><br><span class="line"><span class="comment"># to be. Usually, we don&#x27;t use our own name,</span></span><br><span class="line"><span class="comment"># you can use &quot;user&quot; or &quot;ubuntu&quot;</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> useradd -m abhishek</span></span><br><span class="line"><span class="comment"># make our user own its own home directory</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">chown</span> -R abhishek:abhishek /home/abhishek/</span></span><br><span class="line"><span class="comment"># copy all files from this direrctory to a</span></span><br><span class="line"><span class="comment"># directory called app inside the home of abhishek</span></span><br><span class="line"><span class="comment"># and abhishek owns it.</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> --<span class="built_in">chown</span>=abhishek *.* /home/abhishek/app/</span></span><br><span class="line"><span class="comment"># change to user abhishek</span></span><br><span class="line"><span class="keyword">USER</span> abhishek</span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">mkdir</span> /home/abhishek/data/</span></span><br><span class="line"><span class="comment"># Now we install all the requirements</span></span><br><span class="line"><span class="comment"># after moving to the app directory</span></span><br><span class="line"><span class="comment"># PLEASE NOTE that ubuntu 18.04 image</span></span><br><span class="line"><span class="comment"># has python 3.6.9 and not python 3.7.6</span></span><br><span class="line"><span class="comment"># you can also install conda python here and use that</span></span><br><span class="line"><span class="comment"># however, to simplify it, I will be using python 3.6.9</span></span><br><span class="line"><span class="comment"># inside the docker container!!!!</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">cd</span> /home/abhishek/app/ &amp;&amp; pip3 install -r requirements.txt</span></span><br><span class="line"><span class="comment"># install mkl. its needed for transformers</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip3 install mkl</span></span><br><span class="line"><span class="comment"># when we log into the docker container,</span></span><br><span class="line"><span class="comment"># we will go inside this directory automatically</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /home/abhishek/app</span></span><br></pre></td></tr></table></figure><p>创建好 Docker 文件后，我们就需要构建它。构建 Docker 容器是一个非常简单的命令。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -f Dockerfile -t bert:train .</span><br></pre></td></tr></table></figure><p>该命令根据提供的 Dockerfile 构建一个容器。Docker 容器的名称是 bert:train。输出结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">❯ docker build -f Dockerfile -t bert:train .</span><br><span class="line">Sending build context to Docker daemon  19.97kB</span><br><span class="line">Step 1/7 : FROM nvidia/cuda:10.1-cudnn7-ubuntu18.04</span><br><span class="line">---&gt; 3b55548ae91f</span><br><span class="line">Step 2/7 : RUN apt-get update &amp;&amp; apt-get install -y   git  curl     ca-</span><br><span class="line">certificates     python3 python3-pip     sudo     &amp;&amp; rm -rf</span><br><span class="line">/var/lib/apt/lists/*</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">Removing intermediate container 8f6975dd08ba</span><br><span class="line">---&gt; d1802ac9f1b4</span><br><span class="line">Step 7/7 : WORKDIR /home/abhishek/app</span><br><span class="line">---&gt; Running in 257ff09502ed</span><br><span class="line">Removing intermediate container 257ff09502ed</span><br><span class="line">---&gt; e5f6eb4cddd7</span><br><span class="line">Successfully built e5f6eb4cddd7</span><br><span class="line">Successfully tagged bert:train</span><br></pre></td></tr></table></figure><p>请注意，我删除了输出中的许多行。现在，您可以使用以下命令登录容器。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -ti bert:train /bin/bash</span><br></pre></td></tr></table></figure><p>你需要记住，一旦退出 shell，你在 shell 中所做的一切都将丢失。你还可以在 Docker 容器中使用。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -ti bert:train python3 train.py</span><br></pre></td></tr></table></figure><p>输出情况：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">File &quot;train.py&quot;, line 2, in &lt;module&gt;</span><br><span class="line">import config</span><br><span class="line">File &quot;/home/abhishek/app/config.py&quot;, line 28, in &lt;module&gt;</span><br><span class="line">do_lower_case=True</span><br><span class="line">File &quot;/usr/local/lib/python3.6/dist-</span><br><span class="line">packages/transformers/tokenization_utils.py&quot;, line 393, in</span><br><span class="line">from_pretrained</span><br><span class="line">return cls._from_pretrained(*inputs, **kwargs)</span><br><span class="line">File &quot;/usr/local/lib/python3.6/dist-</span><br><span class="line">packages/transformers/tokenization_utils.py&quot;, line 496, in</span><br><span class="line">_from_pretrained</span><br><span class="line">list(cls.vocab_files_names.values()),</span><br><span class="line">OSError: Model name &#x27;../input/bert_base_uncased/&#x27; was not found in</span><br><span class="line">tokenizers model name list (bert-base-uncased, bert-large-uncased, bert-</span><br><span class="line">base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-</span><br><span class="line">multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-</span><br><span class="line">large-uncased-whole-word-masking, bert-large-cased-whole-word-masking,</span><br><span class="line">bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-</span><br><span class="line">whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-</span><br><span class="line">base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-</span><br><span class="line">finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased).</span><br><span class="line">We assumed &#x27;../input/bert_base_uncased/&#x27; was a path, a model identifier,</span><br><span class="line">or url to a directory containing vocabulary files named [&#x27;vocab.txt&#x27;] but</span><br><span class="line">couldn&#x27;t find such vocabulary files at this path or url.</span><br></pre></td></tr></table></figure><p>哎呀，出错了！</p><p>我为什么要把错误印在书上呢？</p><p>因为理解这个错误非常重要。这个错误说明代码无法找到目录”…/input/bert_base_cased”。为什么会出现这种情况呢？我们可以在没有 Docker 的情况下进行训练，我们可以看到目录和所有文件都存在。出现这种情况是因为 Docker 就像一个虚拟机！它有自己的文件系统，本地机器上的文件不会共享给 Docker 容器。如果你想使用本地机器上的路径并对其进行修改，你需要在运行 Docker 时将其挂载到 Docker 容器上。当我们查看这个文件夹的路径时，我们知道它位于名为 input 的文件夹的上一级。让我们稍微修改一下 config.py 文件！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># config.py</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> transformers</span><br><span class="line"><span class="comment"># fetch home directory</span></span><br><span class="line"><span class="comment"># in our docker container, it is</span></span><br><span class="line"><span class="comment"># /home/abhishek</span></span><br><span class="line">HOME_DIR = os.path.expanduser(<span class="string">&quot;~&quot;</span>)</span><br><span class="line"><span class="comment"># this is the maximum number of tokens in the sentence</span></span><br><span class="line">MAX_LEN = <span class="number">512</span></span><br><span class="line"><span class="comment"># batch sizes is low because model is huge!</span></span><br><span class="line">TRAIN_BATCH_SIZE = <span class="number">8</span></span><br><span class="line">VALID_BATCH_SIZE = <span class="number">4</span></span><br><span class="line"><span class="comment"># let&#x27;s train for a maximum of 10 epochs</span></span><br><span class="line">EPOCHS = <span class="number">10</span></span><br><span class="line"><span class="comment"># define path to BERT model files</span></span><br><span class="line"><span class="comment"># Now we assume that all the data is stored inside</span></span><br><span class="line"><span class="comment"># /home/abhishek/data</span></span><br><span class="line">BERT_PATH = os.path.join(HOME_DIR, <span class="string">&quot;data&quot;</span>, <span class="string">&quot;bert_base_uncased&quot;</span>)</span><br><span class="line"><span class="comment"># this is where you want to save the model</span></span><br><span class="line">MODEL_PATH = os.path.join(HOME_DIR, <span class="string">&quot;data&quot;</span>, <span class="string">&quot;model.bin&quot;</span>)</span><br><span class="line"><span class="comment"># training file</span></span><br><span class="line">TRAINING_FILE = os.path.join(HOME_DIR, <span class="string">&quot;data&quot;</span>, <span class="string">&quot;imdb.csv&quot;</span>)</span><br><span class="line">TOKENIZER = transformers.BertTokenizer.from_pretrained(BERT_PATH,do_lower_case=<span class="literal">True</span> )</span><br></pre></td></tr></table></figure><p>现在，代码假定所有内容都在主目录下名为 data 的文件夹中。</p><p>请注意，如果 Python 脚本有任何改动，都意味着需要重建 Docker 容器！因此，我们重建容器，然后重新运行 Docker 命令，但这次要有所改变。不过，如果我们没有英伟达 ™（NVIDIA®）Docker 运行时，这也是行不通的。别担心，这只是一个 Docker 容器。你只需要做一次。要安装英伟达 ™（NVIDIA®）Docker 运行时，可以在 Ubuntu 18.04 中运行以下命令。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">distribution=$(. /etc/os-release;echo $ID$VERSION_ID)</span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key</span><br><span class="line">add -</span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-</span><br><span class="line">docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list</span><br><span class="line">sudo apt-get update &amp;&amp; sudo apt-get install -y nvidia-container-toolkit</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure><p>现在，我们可以再次构建我们的容器，并开始训练过程：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker run --gpus 1 -v</span><br><span class="line">/home/abhishek/workspace/approaching_almost/input/:/home/abhishek/data/ -</span><br><span class="line">ti bert:train python3 train.py</span><br></pre></td></tr></table></figure><p>其中，-gpus 1 表示我们在 docker 容器中使用 1 个 GPU，-v 表示挂载卷。 因此，我们要将本地目录 /home/abhishek/workspace/approaching_almost/input/ 挂载到 docker 容器中的 /home/abhishek/data/。这一步要花点时间，但完成后，本地文件夹中就会有 model.bin。</p><p>这样，只需做一些简单的改动，你的训练代码就已经 “dockerized “了。现在，你可以在（几乎）任何你想要的系统上使用这些代码进行训练。</p><p>下一部分是将我们训练好的模型 “提供 “给最终用户。假设您想从接收到的推文流中提取情感信息。要完成这项任务，您必须创建一个 API，用于输入句子，然后返回带有情感概率的输出。使用 Python 构建 API 的最常见方法是使用 <strong>Flask</strong>，它是一个微型网络服务框架。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># api.py</span></span><br><span class="line"><span class="keyword">import</span> config</span><br><span class="line"><span class="keyword">import</span> flask</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> BERTBaseUncased</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line">MODEL = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">DEVICE = <span class="string">&quot;cuda&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sentence_prediction</span>(<span class="params">sentence</span>):</span><br><span class="line">    tokenizer = config.TOKENIZER</span><br><span class="line">    max_len = config.MAX_LEN</span><br><span class="line"></span><br><span class="line">    review = <span class="built_in">str</span>(sentence)</span><br><span class="line">    review = <span class="string">&quot; &quot;</span>.join(review.split())</span><br><span class="line"></span><br><span class="line">    inputs = tokenizer.encode_plus(</span><br><span class="line">        review,</span><br><span class="line">        <span class="literal">None</span>,</span><br><span class="line">        add_special_tokens=<span class="literal">True</span>,</span><br><span class="line">        max_length=max_len</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">ids = inputs[<span class="string">&quot;input_ids&quot;</span>]</span><br><span class="line">mask = inputs[<span class="string">&quot;attention_mask&quot;</span>]</span><br><span class="line">token_type_ids = inputs[<span class="string">&quot;token_type_ids&quot;</span>]</span><br><span class="line"></span><br><span class="line">    padding_length = max_len - <span class="built_in">len</span>(ids)</span><br><span class="line">    ids = ids + ([<span class="number">0</span>] * padding_length)</span><br><span class="line">    mask = mask + ([<span class="number">0</span>] * padding_length)</span><br><span class="line">    token_type_ids = token_type_ids + ([<span class="number">0</span>] * padding_length)</span><br><span class="line"></span><br><span class="line">    ids = torch.tensor(ids, dtype=torch.long).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    mask = torch.tensor(mask, dtype=torch.long).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    token_type_ids = torch.tensor(token_type_ids,</span><br><span class="line">                                  dtype=torch.long).unsqueeze(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    ids = ids.to(DEVICE, dtype=torch.long)</span><br><span class="line">    token_type_ids = token_type_ids.to(DEVICE, dtype=torch.long)</span><br><span class="line">    mask = mask.to(DEVICE, dtype=torch.long)</span><br><span class="line"></span><br><span class="line">    outputs = MODEL(ids=ids, mask=mask, token_type_ids=token_type_ids)</span><br><span class="line">    outputs = torch.sigmoid(outputs).cpu().detach().numpy()</span><br><span class="line">    <span class="keyword">return</span> outputs[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&quot;/predict&quot;</span>, methods=[<span class="string">&quot;GET&quot;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>():</span><br><span class="line">    sentence = request.args.get(<span class="string">&quot;sentence&quot;</span>)</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    positive_prediction = sentence_prediction(sentence)</span><br><span class="line">    negative_prediction = <span class="number">1</span> - positive_prediction</span><br><span class="line">    response = &#123;&#125;</span><br><span class="line">    response[<span class="string">&quot;response&quot;</span>] = &#123;</span><br><span class="line">        <span class="string">&quot;positive&quot;</span>: <span class="built_in">str</span>(positive_prediction),</span><br><span class="line">        <span class="string">&quot;negative&quot;</span>: <span class="built_in">str</span>(negative_prediction),</span><br><span class="line">        <span class="string">&quot;sentence&quot;</span>: <span class="built_in">str</span>(sentence),</span><br><span class="line">        <span class="string">&quot;time_taken&quot;</span>: <span class="built_in">str</span>(time.time() - start_time),</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> flask.jsonify(response)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    MODEL = BERTBaseUncased()</span><br><span class="line">    MODEL.load_state_dict(torch.load(</span><br><span class="line">        config.MODEL_PATH, map_location=torch.device(DEVICE)</span><br><span class="line">    ))</span><br><span class="line">MODEL.to(DEVICE)</span><br><span class="line">MODEL.<span class="built_in">eval</span>()</span><br><span class="line">app.run(host=<span class="string">&quot;0.0.0.0&quot;</span>)</span><br></pre></td></tr></table></figure><p>然后运行 “python api.py “命令启动 API。API 将在端口 5000 的 localhost 上启动。cURL 请求及其响应示例如下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ curl</span><br><span class="line">$&#x27;http://192.168.86.48:5000/predict?sentence=this%20is%20the%20best%20boo</span><br><span class="line">k%20ever&#x27;</span><br><span class="line">&#123;&quot;response&quot;:&#123;&quot;negative&quot;:&quot;0.0032927393913269043&quot;,&quot;positive&quot;:&quot;0.99670726&quot;,&quot;</span><br><span class="line">sentence&quot;:&quot;this is the best book</span><br><span class="line">ever&quot;,&quot;time_taken&quot;:&quot;0.029126882553100586&quot;&#125;&#125;</span><br></pre></td></tr></table></figure><p>可以看到，我们得到的输入句子的正面情感概率很高。输入句子的正面情感概率很高。 您还可以访问 <a href="http://127.0.0.1:5000/predict?sentence=this%20book%20is%20too%20complicated%20for%20me。这将再次返回一个">http://127.0.0.1:5000/predict?sentence=this%20book%20is%20too%20complicated%20for%20me。这将再次返回一个</a> JSON 文件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">response: &#123;</span><br><span class="line">negative: <span class="string">&quot;0.8646619468927383&quot;</span>,</span><br><span class="line">positive: <span class="string">&quot;0.13533805&quot;</span>,</span><br><span class="line">sentence: <span class="string">&quot;this book is too complicated for me&quot;</span>,</span><br><span class="line">time_taken: <span class="string">&quot;0.03852701187133789&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在，我们创建了一个简单的应用程序接口，可以用来为少量用户提供服务。为什么是少量？因为这个 API 一次只服务一个请求。gunicorn 是 UNIX 上的 Python WSGI HTTP 服务器，让我们使用它的 CPU 来处理多个并行请求。Gunicorn 可以为 API 创建多个进程，因此我们可以同时为多个客户提供服务。您可以使用 “pip install gunicorn “安装 gunicorn。</p><p>为了将代码转换为与 gunicorn 兼容，我们需要移除 init main，并将其中的所有内容移至全局范围。此外，我们现在使用的是 CPU 而不是 GPU。修改后的代码如下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># api.py</span></span><br><span class="line"><span class="keyword">import</span> config</span><br><span class="line"><span class="keyword">import</span> flask</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> BERTBaseUncased</span><br><span class="line">app = Flask(__name__)</span><br><span class="line">DEVICE = <span class="string">&quot;cpu&quot;</span></span><br><span class="line">MODEL = BERTBaseUncased()</span><br><span class="line">MODEL.load_state_dict(torch.load(config.MODEL_PATH, map_location=torch.device(DEVICE)))</span><br><span class="line">MODEL.to(DEVICE)</span><br><span class="line">MODEL.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sentence_prediction</span>(<span class="params">sentence</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> outputs[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&quot;/predict&quot;</span>, methods=[<span class="string">&quot;GET&quot;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict</span>():</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> flask.jsonify(response)</span><br></pre></td></tr></table></figure><p>我们使用以下命令运行这个应用程序接口。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gunicorn api:app --bind 0.0.0.0:5000 --workers 4</span><br></pre></td></tr></table></figure><p>这意味着我们在提供的 IP 地址和端口上使用 4 个 Worker 运行我们的 flask 应用程序。由于有 4 个 Worker，我们现在可以同时处理 4 个请求。请注意，现在我们的终端使用的是 CPU，因此不需要 GPU 机器，可以在任何标准服务器/虚拟机上运行。不过，我们还有一个问题：我们已经在本地机器上完成了所有工作，因此必须将其坞化。看看下面这个未注释的 Dockerfile，它可以用来部署这个应用程序接口。请注意用于培训的旧 Dockerfile 和这个 Dockerfile 之间的区别。区别不大。</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># CPU Dockerfile</span></span><br><span class="line"><span class="keyword">FROM</span> ubuntu:<span class="number">18.04</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> apt-get update &amp;&amp; apt-get install -y \</span></span><br><span class="line"><span class="language-bash">git \</span></span><br><span class="line"><span class="language-bash">curl \</span></span><br><span class="line"><span class="language-bash">ca-certificates \</span></span><br><span class="line"><span class="language-bash">python3 \</span></span><br><span class="line"><span class="language-bash">python3-pip \</span></span><br><span class="line"><span class="language-bash">sudo \</span></span><br><span class="line"><span class="language-bash">&amp;&amp; <span class="built_in">rm</span> -rf /var/lib/apt/lists/*</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> useradd -m abhishek</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">chown</span> -R abhishek:abhishek /home/abhishek/</span></span><br><span class="line"><span class="keyword">COPY</span><span class="language-bash"> --<span class="built_in">chown</span>=abhishek *.* /home/abhishek/app/</span></span><br><span class="line"><span class="keyword">USER</span> abhishek</span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">mkdir</span> /home/abhishek/data/</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> <span class="built_in">cd</span> /home/abhishek/app/ &amp;&amp; pip3 install -r requirements.txt</span></span><br><span class="line"><span class="keyword">RUN</span><span class="language-bash"> pip3 install mkl</span></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="language-bash"> /home/abhishek/app</span></span><br></pre></td></tr></table></figure><p>让我们构建一个新的 Docker 容器。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -f Dockerfile -t bert:api</span><br></pre></td></tr></table></figure><p>当 Docker 容器构建完成后，我们就可以使用以下命令直接运行 API 了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 5000:5000 -v</span><br><span class="line">/home/abhishek/workspace/approaching_almost/input/:/home/abhishek/data/ -</span><br><span class="line">ti bert:api /home/abhishek/.local/bin/gunicorn api:app --bind</span><br><span class="line">0.0.0.0:5000 --workers 4</span><br></pre></td></tr></table></figure><p>请注意，我们将容器内的 5000 端口暴露给容器外的 5000 端口。如果使用 docker-compose，也可以很好地做到这一点。Dockercompose 是一个可以让你同时在不同或相同容器中运行不同服务的工具。你可以使用 “pip install docker-compose “安装 docker-compose，然后在构建容器后运行 “docker-compose up”。要使用 docker-compose，你需要一个 docker-compose.yml 文件。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker-compose.yml</span></span><br><span class="line"><span class="comment"># specify a version of the compose</span></span><br><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3.7&#x27;</span></span><br><span class="line"><span class="comment"># you can add multiple services</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="comment"># specify service name. we call our service: api</span></span><br><span class="line"><span class="attr">api:</span></span><br><span class="line"><span class="comment"># specify image name</span></span><br><span class="line"><span class="attr">image:</span> <span class="string">bert:api</span></span><br><span class="line"><span class="comment"># the command that you would like to run inside the container</span></span><br><span class="line"><span class="attr">command:</span> <span class="string">/home/abhishek/.local/bin/gunicorn</span> <span class="string">api:app</span> <span class="string">--bind</span></span><br><span class="line"><span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span><span class="string">:5000</span> <span class="string">--workers</span> <span class="number">4</span></span><br><span class="line"><span class="comment"># mount the volume</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line"><span class="bullet">-</span></span><br><span class="line"><span class="string">/home/abhishek/workspace/approaching_almost/input/:/home/abhishek/data/</span></span><br><span class="line"><span class="comment"># this ensures that our ports from container will be</span></span><br><span class="line"><span class="comment"># exposed as it is</span></span><br><span class="line"><span class="attr">network_mode:</span> <span class="string">host</span></span><br></pre></td></tr></table></figure><p>现在，您只需使用上述命令即可重新运行 API，其运行方式与之前相同。恭喜你，现在，你也已经成功地将预测 API 进行了 Docker 化，可以随时随地部署了。在本章中，我们学习了 Docker、使用 flask 构建 API、使用 gunicorn 和 Docker 服务 API 以及 docker-compose。关于 docker 的知识远不止这些，但这应该是一个开始。其他内容可以在学习过程中逐渐掌握。 我们还跳过了许多工具，如 kubernetes、bean-stalk、sagemaker、heroku 和许多其他工具，这些工具如今被人们用来在生产中部署模型。”我要写什么？点击修改图 X 中的 docker 容器”？在书中描述这些是不可行的，也是不可取的，所以我将使用不同的媒介来赞美本书的这一部分。请记住，一旦你对应用程序进行了 Docker 化，使用这些技术/平台进行部署就变得易如反掌了。请务必记住，要让你的代码和模型对他人可用，并做好文档记录，这样任何人都可以使用你开发的东西，而无需多次询问你。这不仅能节省您的时间，还能节省他人的时间。好的、开源的、可重复使用的代码在您的作品集中也非常重要。</p>]]></content>
      
      
      <categories>
          
          <category> AAAMLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图像分类和分割方法</title>
      <link href="/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E5%92%8C%E5%88%86%E5%89%B2%E6%96%B9%E6%B3%95/"/>
      <url>/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E5%92%8C%E5%88%86%E5%89%B2%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="图像分类和分割方法"><a href="#图像分类和分割方法" class="headerlink" title="图像分类和分割方法"></a>图像分类和分割方法</h1><p>说到图像，过去几年取得了很多成就。计算机视觉的进步相当快，感觉计算机视觉的许多问题现在都更容易解决了。随着预训练模型的出现和计算成本的降低，现在在家里就能轻松训练出接近最先进水平的模型，解决大多数与图像相关的问题。但是，图像问题有许多不同的类型。从两个或多个类别的标准图像分类，到像自动驾驶汽车这样具有挑战性的问题。我们不会在本书中讨论自动驾驶汽车，但我们显然会处理一些最常见的图像问题。</p><p>我们可以对图像采用哪些不同的方法？图像只不过是一个数字矩阵。计算机无法像人类一样看到图像。它只能看到数字，这就是图像。灰度图像是一个二维矩阵，数值范围从 0 到 255。0 代表黑色，255 代表白色，介于两者之间的是各种灰色。以前，在没有深度学习的时候（或者说深度学习还不流行的时候），人们习惯于查看像素。每个像素都是一个特征。你可以在 Python 中轻松做到这一点。只需使用 OpenCV 或 Python-PIL 读取灰度图像，转换为 numpy 数组，然后将矩阵平铺（扁平化）即可。如果处理的是 RGB 图像，则需要三个矩阵，而不是一个。但思路是一样的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 生成一个 256x256 的随机灰度图像，像素值在0到255之间随机分布</span></span><br><span class="line">random_image = np.random.randint(<span class="number">0</span>, <span class="number">256</span>, (<span class="number">256</span>, <span class="number">256</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个新的图像窗口，设置窗口大小为7x7英寸</span></span><br><span class="line">plt.figure(figsize=(<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示生成的随机图像</span></span><br><span class="line"><span class="comment"># 使用灰度颜色映射 (colormap)，范围从0到255</span></span><br><span class="line">plt.imshow(random_image, cmap=<span class="string">&#x27;gray&#x27;</span>, vmin=<span class="number">0</span>, vmax=<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示图像窗口</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>上面的代码使用 numpy 生成一个随机矩阵。该矩阵由 0 到 255（包含）的值组成，大小为 256x256（也称为像素）。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page186_image.png" alt=""></p><p align="center"><b>图 1：二维图像阵列（单通道）及其展平版本</b> </p><p>正如你所看到的，拼写后的版本只是一个大小为 M 的向量，其中 M = N <em> N，在本例中，这个向量的大小为 256 </em> 256 = 65536。</p><p>现在，如果我们继续对数据集中的所有图像进行处理，每个样本就会有 65536 个特征。我们可以在这些数据上快速建立<strong>决策树模型、随机森林模型或基于 SVM 的模型</strong>。这些模型将基于像素值，尝试将正样本与负样本区分开来（二元分类问题）。</p><p>你们一定都听说过猫与狗的问题，这是一个经典的问题。如果你们还记得，在评估指标一章的开头，我向你们介绍了一个气胸图像数据集。那么，让我们尝试建立一个模型来检测肺部的 X 光图像是否存在气胸。也就是说，这是一个（并不）简单的二元分类。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page186_image_1.png" alt=""></p><p align="center"><b>图 2：非气胸与气胸 X 光图像对比</b> </p><p>在图 2 中，您可以看到非气胸和气胸图像的对比。您一定已经注意到了，对于一个非专业人士（比如我）来说，要在这些图像中辨别出哪个是气胸是相当困难的。</p><p>最初的数据集是关于检测气胸的具体位置，但我们将问题修改为查找给定的 X 光图像是否存在气胸。别担心，我们将在本章介绍这个部分。数据集由 10675 张独特的图像组成，其中 2379 张有气胸（注意，这些数字是经过数据清理后得出的，因此与原始数据集不符）。正如数据科学家所说：这是一个典型的<strong>偏斜二元分类案例</strong>。因此，我们选择 AUC 作为评估指标，并采用分层 k 折交叉验证方案。</p><p>您可以将特征扁平化，然后尝试一些经典方法（如 SVM、RF）来进行分类，这完全没问题，但却无法让您达到最先进的水平。此外，图像大小为 1024x1024。在这个数据集上训练一个模型需要很长时间。不管怎样，让我们尝试在这些数据上建立一个简单的随机森林模型。由于图像是灰度的，我们不需要进行任何转换。我们将把图像大小调整为 256x256，使其更小，并使用之前讨论过的 AUC 作为衡量指标。</p><p>让我们看看它的表现如何。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> ensemble</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个函数来创建数据集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_dataset</span>(<span class="params">training_df, image_dir</span>):</span><br><span class="line">    <span class="comment"># 初始化空列表来存储图像数据和目标值</span></span><br><span class="line">    images = []</span><br><span class="line">    targets = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 迭代处理训练数据集中的每一行</span></span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> tqdm(</span><br><span class="line">        training_df.iterrows(),</span><br><span class="line">        total=<span class="built_in">len</span>(training_df),</span><br><span class="line">        desc=<span class="string">&quot;processing images&quot;</span></span><br><span class="line">    ):</span><br><span class="line">        <span class="comment"># 获取图像文件名</span></span><br><span class="line">        image_id = row[<span class="string">&quot;ImageId&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 构建完整的图像文件路径</span></span><br><span class="line">        image_path = os.path.join(image_dir, image_id)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打开图像文件并进行大小调整（resize）为 256x256 像素，使用双线性插值（BILINEAR）</span></span><br><span class="line">        image = Image.<span class="built_in">open</span>(image_path + <span class="string">&quot;.png&quot;</span>)</span><br><span class="line">        image = image.resize((<span class="number">256</span>, <span class="number">256</span>), resample=Image.BILINEAR)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将图像转换为NumPy数组</span></span><br><span class="line">        image = np.array(image)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将图像扁平化为一维数组，并将其添加到图像列表</span></span><br><span class="line">        image = image.ravel()</span><br><span class="line">        images.append(image)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将目标值（target）添加到目标列表</span></span><br><span class="line">        targets.append(<span class="built_in">int</span>(row[<span class="string">&quot;target&quot;</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将图像列表转换为NumPy数组</span></span><br><span class="line">    images = np.array(images)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 打印图像数组的形状</span></span><br><span class="line">    <span class="built_in">print</span>(images.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回图像数据和目标值</span></span><br><span class="line">    <span class="keyword">return</span> images, targets</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 定义CSV文件路径和图像文件目录路径</span></span><br><span class="line">    csv_path = <span class="string">&quot;/home/abhishek/workspace/siim_png/train.csv&quot;</span></span><br><span class="line">    image_path = <span class="string">&quot;/home/abhishek/workspace/siim_png/train_png/&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从CSV文件加载数据</span></span><br><span class="line">    df = pd.read_csv(csv_path)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加一个名为&#x27;kfold&#x27;的列，并初始化为-1</span></span><br><span class="line">    df[<span class="string">&quot;kfold&quot;</span>] = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 随机打乱数据</span></span><br><span class="line">    df = df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取目标值（target）</span></span><br><span class="line">    y = df.target.values</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用分层KFold交叉验证将数据集分成5折</span></span><br><span class="line">    kf = model_selection.StratifiedKFold(n_splits=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每个折（fold）</span></span><br><span class="line">    <span class="keyword">for</span> f, (t_, v_) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kf.split(X=df, y=y)):</span><br><span class="line">        df.loc[v_, <span class="string">&#x27;kfold&#x27;</span>] = f</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历每个折</span></span><br><span class="line">    <span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        <span class="comment"># 获取训练数据和测试数据</span></span><br><span class="line">        train_df = df[df.kfold != fold_].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">        test_df = df[df.kfold == fold_].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建训练数据集的图像数据和目标值</span></span><br><span class="line">        xtrain, ytrain = create_dataset(train_df, image_path)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建测试数据集的图像数据和目标值</span></span><br><span class="line">        xtest, ytest = create_dataset(test_df, image_path)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化一个随机森林分类器</span></span><br><span class="line">        clf = ensemble.RandomForestClassifier(n_jobs=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用训练数据拟合分类器</span></span><br><span class="line">        clf.fit(xtrain, ytrain)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用分类器对测试数据进行预测，并获取概率值</span></span><br><span class="line">        preds = clf.predict_proba(xtest)[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打印折数（fold）和AUC（ROC曲线下的面积）</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;FOLD: <span class="subst">&#123;fold_&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;AUC = <span class="subst">&#123;metrics.roc_auc_score(ytest, preds)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure><p>平均 AUC 值约为 0.72。这还不错，但我们希望能做得更好。你可以将这种方法用于图像，这也是它在以前最常用的方法。SVM 在图像数据集方面相当有名。深度学习已被证明是解决此类问题的最先进方法，因此我们下一步可以试试它。</p><p>关于深度学习的历史以及谁发明了什么，我就不多说了。让我们看看最著名的深度学习模型之一 AlexNet。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page189_image.png" alt=""></p><p align="center"><b>图 3：AlexNet 架构9 请注意，本图中的输入大小不是 224x224 而是 227x227</b> </p><p>如今，你可能会说这只是一个基本的<strong>深度卷积神经网络</strong>，但它却是许多新型深度网络（深度神经网络）的基础。我们看到，图 3 中的网络是一个具有五个卷积层、两个密集层和一个输出层的卷积神经网络。我们看到还有最大池化。这是什么意思？让我们来看看在进行深度学习时会遇到的一些术语。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page189_image_1.png" alt=""></p><p align="center"><b>图 4：图像大小为 8x8，滤波器大小为 3x3，步长为 2。</b> </p><p>图 4 引入了两个新术语：滤波器和步长。<strong>滤波器</strong>是由给定函数初始化的二维矩阵，由指定函数初始化。<strong>Kaiming 正态初始化</strong>，是卷积神经网络的最佳选择。这是因为大多数现代网络都使用 <strong>ReLU</strong>（整流线性单元）激活函数，需要适当的初始化来避免梯度消失问题（梯度趋近于零，网络权重不变）。该滤波器与图像进行卷积。卷积不过是滤波器与给定图像中当前重叠像素之间的元素相乘的总和。您可以在任何高中数学教科书中阅读更多关于卷积的内容。我们从图像的左上角开始对滤镜进行卷积，然后水平移动滤镜。如果移动 1 个像素，则步长为 1；如果移动 2 个像素，则步长为 2。</p><p>即使在自然语言处理中，例如在问题和回答系统中需要从大量文本语料中筛选答案时，步长也是一个非常有用的概念。当我们在水平方向上走到尽头时，就会以同样的步长垂直向下移动过滤器，从左侧开始。图 4 还显示了过滤器移出图像的情况。在这种情况下，无法计算卷积。因此，我们跳过它。如果不想跳过，则需要对图像进行<strong>填充（pad）</strong>。还必须注意的是，卷积会减小图像的大小。填充也是保持图像大小不变的一种方法。在图 4 中，一个 3x3 滤波器正在水平和垂直移动，每次移动都会分别跳过两列和两行（即像素）。由于它跳过了两个像素，所以步长 = 2。因此图像大小为 [(8-3) / 2] + 1 = 3.5。我们取 3.5 的下限，所以是 3x3。您可以在草稿纸上进行尝试。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page190_image.png" alt=""></p><p align="center"><b>图 5：通过填充，我们可以提供与输入图像大小相同的图像</b> </p><p>我们可以从图 5 中看到填充的效果。现在，我们有一个 3x3 的滤波器，它以 1 的步长移动。原始图像的大小为 6x6，我们添加了 1 的<strong>填充</strong>。在这种情况下，生成的图像将与输入图像大小相同，即 6x6。在处理深度神经网络时可能会遇到的另一个相关术语是<strong>膨胀（dilation）</strong>，如图 6 所示。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page191_image.png" alt=""></p><p align="center"><b>图 6：膨胀（dilation）的例子</b> </p><p>在膨胀过程中，我们将滤波器扩大 N-1，其中 N 是膨胀率的值，或简称为膨胀。在这种带膨胀的内核中，每次卷积都会跳过一些像素。这在分割任务中尤为有效。请注意，我们只讨论了二维卷积。 还有一维卷积和更高维度的卷积。它们都基于相同的基本概念。</p><p>接下来是<strong>最大池化（Max pooling）</strong>。最大值池只是一个返回最大值的滤波器。因此，我们提取的不是卷积，而是像素的最大值。同样，<strong>平均池化（average pooling）</strong>或<strong>均值池化（mean pooling）</strong>会返回像素的平均值。它们的使用方法与卷积核相同。池化比卷积更快，是一种对图像进行缩减采样的方法。最大池化可检测边缘，平均池化可平滑图像。</p><p>卷积神经网络和深度学习的概念太多了。我所讨论的是一些基础知识，可以帮助你入门。现在，我们已经为在 PyTorch 中构建第一个卷积神经网络做好了充分准备。PyTorch 提供了一种直观而简单的方法来实现深度神经网络，而且你不需要关心反向传播。我们用一个 python 类和一个前馈函数来定义网络，告诉 PyTorch 各层之间如何连接。在 PyTorch 中，图像符号是 BS、C、H、W，其中，BS 是批大小，C 是通道，H 是高度，W 是宽度。让我们看看 PyTorch 是如何实现 AlexNet 的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AlexNet</span>(nn.Module):</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line"><span class="built_in">super</span>(AlexNet, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(</span><br><span class="line">            in_channels=<span class="number">3</span>,</span><br><span class="line">out_channels=<span class="number">96</span>,</span><br><span class="line">kernel_size=<span class="number">11</span>,</span><br><span class="line">stride=<span class="number">4</span>,</span><br><span class="line">padding=<span class="number">0</span>)</span><br><span class="line">self.pool1 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line">self.conv2 = nn.Conv2d(</span><br><span class="line">in_channels=<span class="number">96</span>,</span><br><span class="line">out_channels=<span class="number">256</span>,</span><br><span class="line">kernel_size=<span class="number">5</span>,</span><br><span class="line">stride=<span class="number">1</span>,</span><br><span class="line">padding=<span class="number">2</span>)</span><br><span class="line">self.pool2 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line">self.conv3 = nn.Conv2d(</span><br><span class="line">in_channels=<span class="number">256</span>,</span><br><span class="line">out_channels=<span class="number">384</span>,</span><br><span class="line">kernel_size=<span class="number">3</span>,</span><br><span class="line">stride=<span class="number">1</span>,</span><br><span class="line">padding=<span class="number">1</span>)</span><br><span class="line">self.conv4 = nn.Conv2d(in_channels=<span class="number">384</span>,out_channels=<span class="number">384</span>,</span><br><span class="line">kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.conv5 = nn.Conv2d(in_channels=<span class="number">384</span>, out_channels=<span class="number">256</span>,</span><br><span class="line">kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">self.pool3 = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line">self.fc1 = nn.Linear(in_features=<span class="number">9216</span>, out_features=<span class="number">4096</span>)</span><br><span class="line">self.dropout1 = nn.Dropout(<span class="number">0.5</span>)</span><br><span class="line">self.fc2 = nn.Linear(in_features=<span class="number">4096</span>,</span><br><span class="line">                             out_features=<span class="number">4096</span>)</span><br><span class="line">self.dropout2 = nn.Dropout(<span class="number">0.5</span>)</span><br><span class="line">self.fc3 = nn.Linear(</span><br><span class="line">            in_features=<span class="number">4096</span>,</span><br><span class="line">            out_features=<span class="number">1000</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image</span>):</span><br><span class="line">        bs, c, h, w = image.size()</span><br><span class="line">        x = F.relu(self.conv1(image)) <span class="comment"># size: (bs, 96, 55, 55)</span></span><br><span class="line">        x = self.pool1(x) <span class="comment"># size: (bs, 96, 27, 27)</span></span><br><span class="line">        x = F.relu(self.conv2(x)) <span class="comment"># size: (bs, 256, 27, 27)</span></span><br><span class="line">        x = self.pool2(x) <span class="comment"># size: (bs, 256, 13, 13)</span></span><br><span class="line">        x = F.relu(self.conv3(x)) <span class="comment"># size: (bs, 384, 13, 13)</span></span><br><span class="line">        x = F.relu(self.conv4(x)) <span class="comment"># size: (bs, 384, 13, 13)</span></span><br><span class="line">        x = F.relu(self.conv5(x)) <span class="comment"># size: (bs, 256, 13, 13)</span></span><br><span class="line">        x = self.pool3(x) <span class="comment"># size: (bs, 256, 6, 6)</span></span><br><span class="line">        x = x.view(bs, -<span class="number">1</span>) <span class="comment"># size: (bs, 9216)</span></span><br><span class="line">        x = F.relu(self.fc1(x)) <span class="comment"># size: (bs, 4096)</span></span><br><span class="line">        x = self.dropout1(x) <span class="comment"># size: (bs, 4096)</span></span><br><span class="line"><span class="comment"># dropout does not change size</span></span><br><span class="line"><span class="comment"># dropout is used for regularization</span></span><br><span class="line"><span class="comment"># 0.3 dropout means that only 70% of the nodes</span></span><br><span class="line"><span class="comment"># of the current layer are used for the next layer</span></span><br><span class="line">x = F.relu(self.fc2(x)) <span class="comment"># size: (bs, 4096)</span></span><br><span class="line">x = self.dropout2(x) <span class="comment"># size: (bs, 4096)</span></span><br><span class="line">x = F.relu(self.fc3(x)) <span class="comment"># size: (bs, 1000)</span></span><br><span class="line"><span class="comment"># 1000 is number of classes in ImageNet Dataset</span></span><br><span class="line"><span class="comment"># softmax is an activation function that converts</span></span><br><span class="line"><span class="comment"># linear output to probabilities that add up to 1</span></span><br><span class="line">        <span class="comment"># for each sample in the batch</span></span><br><span class="line">x = torch.softmax(x, axis=<span class="number">1</span>) <span class="comment"># size: (bs, 1000)</span></span><br><span class="line"><span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>如果您有一幅 3x227x227 的图像，并应用了一个大小为 11x11 的卷积滤波器，这意味着您应用了一个大小为 11x11x3 的滤波器，并与一个大小为 227x227x3 的图像进行了卷积。输出通道的数量就是分别应用于图像的相同大小的不同卷积滤波器的数量。 因此，在第一个卷积层中，输入通道是 3，也就是原始输入，即 R、G、B 三通道。PyTorch 的 torchvision 提供了许多与 AlexNet 类似的不同模型，必须指出的是，AlexNet 的实现与 torchvision 的实现并不相同。Torchvision 的 AlexNet 实现是从另一篇论文中修改而来的 AlexNet： Krizhevsky, A. One weird trick for parallelizing convolutional neural networks. CoRR, abs/1404.5997, 2014.</p><p>你可以为自己的任务设计卷积神经网络，很多时候，从零做起是个不错的主意。让我们构建一个网络，用于区分图像有无气胸。首先，让我们准备一些文件。第一步是创建一个交叉检验数据集，即 train.csv，但增加一列 kfold。我们将创建五个文件夹。在本书中，我已经演示了如何针对不同的数据集创建折叠，因此我将跳过这一部分，留作练习。对于基于 PyTorch 的神经网络，我们需要创建一个数据集类。数据集类的目的是返回一个数据项或数据样本。这个数据样本应该包含训练或评估模型所需的所有内容。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> ImageFile</span><br><span class="line">ImageFile.LOAD_TRUNCATED_IMAGES = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个数据集类，用于处理图像分类任务</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ClassificationDataset</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, image_paths, targets, resize=<span class="literal">None</span>, augmentations=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 图像文件路径列表</span></span><br><span class="line">        self.image_paths = image_paths</span><br><span class="line">        <span class="comment"># 目标标签列表</span></span><br><span class="line">        self.targets = targets</span><br><span class="line">        <span class="comment"># 图像尺寸调整参数，可以为None</span></span><br><span class="line">        self.resize = resize</span><br><span class="line">        <span class="comment"># 数据增强函数，可以为None</span></span><br><span class="line">        self.augmentations = augmentations</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 返回数据集的大小，即图像数量</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.image_paths)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        <span class="comment"># 获取数据集中的一个样本</span></span><br><span class="line">        image = Image.<span class="built_in">open</span>(self.image_paths[item])</span><br><span class="line">        image = image.convert(<span class="string">&quot;RGB&quot;</span>)  <span class="comment"># 将图像转换为RGB格式</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取该样本的目标标签</span></span><br><span class="line">        targets = self.targets[item]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.resize <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 如果指定了尺寸调整参数，将图像进行尺寸调整</span></span><br><span class="line">            image = image.resize((self.resize[<span class="number">1</span>], self.resize[<span class="number">0</span>]),</span><br><span class="line">                                 resample=Image.BILINEAR)</span><br><span class="line">            image = np.array(image)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> self.augmentations <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                <span class="comment"># 如果指定了数据增强函数，应用数据增强</span></span><br><span class="line">                augmented = self.augmentations(image=image)</span><br><span class="line">                image = augmented[<span class="string">&quot;image&quot;</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将图像通道顺序调整为(C, H, W)的形式，并转换为float32类型</span></span><br><span class="line">            image = np.transpose(image, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)).astype(np.float32)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 返回样本，包括图像和对应的目标标签</span></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&quot;image&quot;</span>: torch.tensor(image, dtype=torch.<span class="built_in">float</span>),</span><br><span class="line">            <span class="string">&quot;targets&quot;</span>: torch.tensor(targets, dtype=torch.long),</span><br><span class="line">        &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>现在我们需要 engine.py。engine.py 包含训练和评估功能。让我们看看 engine.py 是如何编写的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用于训练模型的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">data_loader, model, optimizer, device</span>):</span><br><span class="line">    <span class="comment"># 将模型设置为训练模式</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> data_loader:</span><br><span class="line">        <span class="comment"># 从数据加载器中提取输入图像和目标标签</span></span><br><span class="line">        inputs = data[<span class="string">&quot;image&quot;</span>]</span><br><span class="line">        targets = data[<span class="string">&quot;targets&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将输入和目标移动到指定的设备（例如，GPU）</span></span><br><span class="line">        inputs = inputs.to(device, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">        targets = targets.to(device, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将优化器中的梯度归零</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 前向传播：计算模型预测</span></span><br><span class="line">        outputs = model(inputs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用带逻辑斯蒂函数的二元交叉熵损失计算损失</span></span><br><span class="line">        loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 反向传播：计算梯度并更新模型权重</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用于评估模型的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">data_loader, model, device</span>):</span><br><span class="line">    <span class="comment"># 将模型设置为评估模式（不进行梯度计算）</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化列表以存储真实目标和模型预测</span></span><br><span class="line">    final_targets = []</span><br><span class="line">    final_outputs = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_loader:</span><br><span class="line">            <span class="comment"># 从数据加载器中提取输入图像和目标标签</span></span><br><span class="line">            inputs = data[<span class="string">&quot;image&quot;</span>]</span><br><span class="line">            targets = data[<span class="string">&quot;targets&quot;</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将输入移动到指定的设备（例如，GPU）</span></span><br><span class="line">            inputs = inputs.to(device, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 获取模型预测</span></span><br><span class="line">            output = model(inputs)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将目标和输出转换为CPU和Python列表</span></span><br><span class="line">            targets = targets.detach().cpu().numpy().tolist()</span><br><span class="line">            output = output.detach().cpu().numpy().tolist()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 将列表扩展以包含批次数据</span></span><br><span class="line">            final_targets.extend(targets)</span><br><span class="line">            final_outputs.extend(output)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回最终的模型预测和真实目标</span></span><br><span class="line">    <span class="keyword">return</span> final_outputs, final_targets</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>有了 engine.py，就可以创建一个新文件：model.py。model.py 将包含我们的模型。把模型与训练分开是个好主意，因为这样我们就可以轻松地试验不同的模型和不同的架构。名为 pretrainedmodels 的 PyTorch 库中有很多不同的模型架构，如 AlexNet、ResNet、DenseNet 等。这些不同的模型架构是在名为 ImageNet 的大型图像数据集上训练出来的。在 ImageNet 上训练后，我们可以使用它们的权重，也可以不使用这些权重。如果我们不使用 ImageNet 权重进行训练，这意味着我们的网络将从头开始学习一切。这就是 model.py 的样子。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> pretrainedmodels</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个函数以获取模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_model</span>(<span class="params">pretrained</span>):</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        <span class="comment"># 使用预训练的 AlexNet 模型，加载在 ImageNet 数据集上训练的权重</span></span><br><span class="line">        model = pretrainedmodels.__dict__[<span class="string">&quot;alexnet&quot;</span>](pretrained=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 使用未经预训练的 AlexNet 模型</span></span><br><span class="line">        model = pretrainedmodels.__dict__[<span class="string">&quot;alexnet&quot;</span>](pretrained=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 修改模型的最后一层全连接层，以适应特定任务</span></span><br><span class="line">    model.last_linear = nn.Sequential(</span><br><span class="line">        nn.BatchNorm1d(<span class="number">4096</span>),  <span class="comment"># 批归一化层</span></span><br><span class="line">        nn.Dropout(p=<span class="number">0.25</span>),  <span class="comment"># 随机失活层，防止过拟合</span></span><br><span class="line">        nn.Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">2048</span>),  <span class="comment"># 连接层</span></span><br><span class="line">        nn.ReLU(),  <span class="comment"># ReLU 激活函数</span></span><br><span class="line">        nn.BatchNorm1d(<span class="number">2048</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>),  <span class="comment"># 批归一化层</span></span><br><span class="line">        nn.Dropout(p=<span class="number">0.5</span>),  <span class="comment"># 随机失活层</span></span><br><span class="line">        nn.Linear(in_features=<span class="number">2048</span>, out_features=<span class="number">1</span>)  <span class="comment"># 最终的二元分类层</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如果你打印了网络，会得到如下输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">AlexNet(</span><br><span class="line">(avgpool): AdaptiveAvgPool2d(output_size=(<span class="number">6</span>, <span class="number">6</span>))</span><br><span class="line">(_features): Sequential(</span><br><span class="line">        (<span class="number">0</span>): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">11</span>, <span class="number">11</span>), stride=(<span class="number">4</span>, <span class="number">4</span>), padding=(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">(<span class="number">1</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">(<span class="number">2</span>): MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">(<span class="number">3</span>): Conv2d(<span class="number">64</span>, <span class="number">192</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">(<span class="number">4</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">(<span class="number">5</span>): MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">(<span class="number">6</span>): Conv2d(<span class="number">192</span>, <span class="number">384</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">(<span class="number">7</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">(<span class="number">8</span>): Conv2d(<span class="number">384</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">(<span class="number">9</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">(<span class="number">10</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line">(<span class="number">11</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">(<span class="number">12</span>): MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, eil_mode=<span class="literal">False</span>))</span><br><span class="line">(dropout0): Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">(linear0): Linear(in_features=<span class="number">9216</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">(relu0): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">(dropout1): Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">(linear1): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">(relu1): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">(last_linear): Sequential(</span><br><span class="line">(<span class="number">0</span>): BatchNorm1d(<span class="number">4096</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>, rack_running_stats=<span class="literal">True</span>)</span><br><span class="line">(<span class="number">1</span>): Dropout(p=<span class="number">0.25</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">(<span class="number">2</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">2048</span>, bias=<span class="literal">True</span>)</span><br><span class="line">(<span class="number">3</span>): ReLU()</span><br><span class="line">(<span class="number">4</span>): BatchNorm1d(<span class="number">2048</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>, affine=<span class="literal">True</span>,</span><br><span class="line">track_running_stats=<span class="literal">True</span>)</span><br><span class="line">(<span class="number">5</span>): Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">(<span class="number">6</span>): Linear(in_features=<span class="number">2048</span>, out_features=<span class="number">1</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>现在，万事俱备，可以开始训练了。我们将使用 train.py 训练模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> albumentations</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> dataset</span><br><span class="line"><span class="keyword">import</span> engine</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> get_model</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 定义数据路径、设备、迭代次数</span></span><br><span class="line">    data_path = <span class="string">&quot;/home/abhishek/workspace/siim_png/&quot;</span></span><br><span class="line">    device = <span class="string">&quot;cuda&quot;</span>  <span class="comment"># 使用GPU加速</span></span><br><span class="line">    epochs = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从CSV文件读取数据</span></span><br><span class="line">    df = pd.read_csv(os.path.join(data_path, <span class="string">&quot;train.csv&quot;</span>))</span><br><span class="line">    images = df.ImageId.values.tolist()</span><br><span class="line">    images = [os.path.join(data_path, <span class="string">&quot;train_png&quot;</span>, i + <span class="string">&quot;.png&quot;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> images]</span><br><span class="line">    targets = df.target.values</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取预训练的模型</span></span><br><span class="line">    model = get_model(pretrained=<span class="literal">True</span>)</span><br><span class="line">    model.to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义均值和标准差，用于数据标准化</span></span><br><span class="line">    mean = (<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>)</span><br><span class="line">    std = (<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 数据增强，将图像标准化</span></span><br><span class="line">    aug = albumentations.Compose(</span><br><span class="line">        [</span><br><span class="line">            albumentations.Normalize(</span><br><span class="line">                mean, std, max_pixel_value=<span class="number">255.0</span>, always_apply=<span class="literal">True</span></span><br><span class="line">            )</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 划分训练集和验证集</span></span><br><span class="line">    train_images, valid_images, train_targets, valid_targets = train_test_split(</span><br><span class="line">        images, targets, stratify=targets, random_state=<span class="number">42</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建训练数据集和验证数据集</span></span><br><span class="line">    train_dataset = dataset.ClassificationDataset(</span><br><span class="line">        image_paths=train_images,</span><br><span class="line">        targets=train_targets,</span><br><span class="line">        resize=(<span class="number">227</span>, <span class="number">227</span>),</span><br><span class="line">        augmentations=aug,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建训练数据加载器</span></span><br><span class="line">    train_loader = torch.utils.data.DataLoader(</span><br><span class="line">        train_dataset, batch_size=<span class="number">16</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建验证数据集</span></span><br><span class="line">    valid_dataset = dataset.ClassificationDataset(</span><br><span class="line">        image_paths=valid_images,</span><br><span class="line">        targets=valid_targets,</span><br><span class="line">        resize=(<span class="number">227</span>, <span class="number">227</span>),</span><br><span class="line">        augmentations=aug,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建验证数据加载器</span></span><br><span class="line">    valid_loader = torch.utils.data.DataLoader(</span><br><span class="line">        valid_dataset, batch_size=<span class="number">16</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">4</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义优化器</span></span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">5e-4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练循环</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        <span class="comment"># 训练模型</span></span><br><span class="line">        engine.train(train_loader, model, optimizer, device=device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 评估模型性能</span></span><br><span class="line">        predictions, valid_targets = engine.evaluate(</span><br><span class="line">            valid_loader, model, device=device</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算ROC AUC分数并打印</span></span><br><span class="line">        roc_auc = metrics.roc_auc_score(valid_targets, predictions)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch=<span class="subst">&#123;epoch&#125;</span>, Valid ROC AUC=<span class="subst">&#123;roc_auc&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>让我们在没有预训练权重的情况下进行训练：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Epoch=<span class="number">0</span>, Valid ROC AUC=<span class="number">0.5737161981475328</span></span><br><span class="line">Epoch=<span class="number">1</span>, Valid ROC AUC=<span class="number">0.5362868001588292</span></span><br><span class="line">Epoch=<span class="number">2</span>, Valid ROC AUC=<span class="number">0.6163448214387008</span></span><br><span class="line">Epoch=<span class="number">3</span>, Valid ROC AUC=<span class="number">0.6119219143780944</span></span><br><span class="line">Epoch=<span class="number">4</span>, Valid ROC AUC=<span class="number">0.6229718888519726</span></span><br><span class="line">Epoch=<span class="number">5</span>, Valid ROC AUC=<span class="number">0.5983014999635341</span></span><br><span class="line">Epoch=<span class="number">6</span>, Valid ROC AUC=<span class="number">0.5523236874306134</span></span><br><span class="line">Epoch=<span class="number">7</span>, Valid ROC AUC=<span class="number">0.4717721611306046</span></span><br><span class="line">Epoch=<span class="number">8</span>, Valid ROC AUC=<span class="number">0.6473408263980617</span></span><br><span class="line">Epoch=<span class="number">9</span>, Valid ROC AUC=<span class="number">0.6639862888260415</span></span><br></pre></td></tr></table></figure><p>AUC 约为 0.66，甚至低于我们的随机森林模型。使用预训练权重会发生什么情况？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Epoch=<span class="number">0</span>, Valid ROC AUC=<span class="number">0.5730387429803165</span></span><br><span class="line">Epoch=<span class="number">1</span>, Valid ROC AUC=<span class="number">0.5319813942934937</span></span><br><span class="line">Epoch=<span class="number">2</span>, Valid ROC AUC=<span class="number">0.627111577514323</span></span><br><span class="line">Epoch=<span class="number">3</span>, Valid ROC AUC=<span class="number">0.6819736959393209</span></span><br><span class="line">Epoch=<span class="number">4</span>, Valid ROC AUC=<span class="number">0.5747117168950512</span></span><br><span class="line">Epoch=<span class="number">5</span>, Valid ROC AUC=<span class="number">0.5994619255609669</span></span><br><span class="line">Epoch=<span class="number">6</span>, Valid ROC AUC=<span class="number">0.5080889443530546</span></span><br><span class="line">Epoch=<span class="number">7</span>, Valid ROC AUC=<span class="number">0.6323792776512727</span></span><br><span class="line">Epoch=<span class="number">8</span>, Valid ROC AUC=<span class="number">0.6685753182661686</span></span><br><span class="line">Epoch=<span class="number">9</span>, Valid ROC AUC=<span class="number">0.6861802387300147</span></span><br></pre></td></tr></table></figure><p>现在的 AUC 好了很多。不过，它仍然较低。预训练模型的好处是可以轻松尝试多种不同的模型。让我们试试使用预训练权重的 <strong>resnet18</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> pretrainedmodels</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个函数以获取模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_model</span>(<span class="params">pretrained</span>):</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        <span class="comment"># 使用预训练的 ResNet-18 模型，加载在 ImageNet 数据集上训练的权重</span></span><br><span class="line">        model = pretrainedmodels.__dict__[<span class="string">&quot;resnet18&quot;</span>](pretrained=<span class="string">&#x27;imagenet&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 使用未经预训练的 ResNet-18 模型</span></span><br><span class="line">        model = pretrainedmodels.__dict__[<span class="string">&quot;resnet18&quot;</span>](pretrained=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 修改模型的最后一层全连接层，以适应特定任务</span></span><br><span class="line">    model.last_linear = nn.Sequential(</span><br><span class="line">        nn.BatchNorm1d(<span class="number">512</span>),  <span class="comment"># 批归一化层</span></span><br><span class="line">        nn.Dropout(p=<span class="number">0.25</span>),  <span class="comment"># 随机失活层，防止过拟合</span></span><br><span class="line">        nn.Linear(in_features=<span class="number">512</span>, out_features=<span class="number">2048</span>),  <span class="comment"># 连接层</span></span><br><span class="line">        nn.ReLU(),  <span class="comment"># ReLU 激活函数</span></span><br><span class="line">        nn.BatchNorm1d(<span class="number">2048</span>, eps=<span class="number">1e-05</span>, momentum=<span class="number">0.1</span>),  <span class="comment"># 批归一化层</span></span><br><span class="line">        nn.Dropout(p=<span class="number">0.5</span>),  <span class="comment"># 随机失活层</span></span><br><span class="line">        nn.Linear(in_features=<span class="number">2048</span>, out_features=<span class="number">1</span>)  <span class="comment"># 最终的二元分类层</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在尝试该模型时，我还将图像大小改为 512x512，并添加了一个学习率调度器，每 3 个 epochs 后将学习率乘以 0.5。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Epoch=<span class="number">0</span>, Valid ROC AUC=<span class="number">0.5988225569880796</span></span><br><span class="line">Epoch=<span class="number">1</span>, Valid ROC AUC=<span class="number">0.730349343208836</span></span><br><span class="line">Epoch=<span class="number">2</span>, Valid ROC AUC=<span class="number">0.5870943169939142</span></span><br><span class="line">Epoch=<span class="number">3</span>, Valid ROC AUC=<span class="number">0.5775864444138311</span></span><br><span class="line">Epoch=<span class="number">4</span>, Valid ROC AUC=<span class="number">0.7330502499939224</span></span><br><span class="line">Epoch=<span class="number">5</span>, Valid ROC AUC=<span class="number">0.7500336296524395</span></span><br><span class="line">Epoch=<span class="number">6</span>, Valid ROC AUC=<span class="number">0.7563722113724951</span></span><br><span class="line">Epoch=<span class="number">7</span>, Valid ROC AUC=<span class="number">0.7987463837994215</span></span><br><span class="line">Epoch=<span class="number">8</span>, Valid ROC AUC=<span class="number">0.798505708937384</span></span><br><span class="line">Epoch=<span class="number">9</span>, Valid ROC AUC=<span class="number">0.8025477500546988</span></span><br></pre></td></tr></table></figure><p>这个模型似乎表现最好。不过，您可以调整 AlexNet 中的不同参数和图像大小，以获得更好的分数。 使用增强技术将进一步提高得分。优化深度神经网络很难，但并非不可能。选择 Adam 优化器、使用低学习率、在验证损失达到高点时降低学习率、尝试一些增强技术、尝试对图像进行预处理（如在需要时进行裁剪，这也可视为预处理）、改变批次大小等。你可以做很多事情来优化深度神经网络。</p><p>与 AlexNet 相比，<strong>ResNet</strong> 的结构要复杂得多。ResNet 是残差神经网络（Residual Neural Network）的缩写，由 K. He、X. Zhang、S. Ren 和 J. Sun 在 2015 年发表的论文中提出。ResNet 由<strong>残差块</strong>（residual blocks）组成，通过跳过某些层，使知识能够不断在各层中进行传递。这些层之间的 连接被称为<strong>跳跃连接</strong>（skip-connections），因为我们跳过了一层或多层。跳跃连接通过将梯度传播到更多层来帮助解决梯度消失问题。这样，我们就可以训练非常大的卷积神经网络，而不会损失性能。通常情况下，如果我们使用的是大型神经网络，那么当训练到某一节点上时训练损失反而会增加，但这可以通过使用跳跃连接来避免。通过图 7 可以更好地理解这一点。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page205_image.png" alt=""></p><p align="center"><b>图 7：简单连接与残差连接的比较。参见跳跃连接。请注意，本图省略了最后一层。</b> </p><p>残差块非常容易理解。你从某一层获取输出，跳过一些层，然后将输出添加到网络中更远的一层。虚线表示输入形状需要调整，因为使用了最大池化，而最大池化的使用会改变输出的大小。</p><p>ResNet 有多种不同的版本： 有 18 层、34 层、50 层、101 层和 152 层，所有这些层都在 ImageNet 数据集上进行了权重预训练。如今，预训练模型（几乎）适用于所有情况，但请确保您从较小的模型开始，例如，从 resnet-18 开始，而不是 resnet-50。其他一些 ImageNet 预训练模型包括：</p><ul><li>Inception</li><li><p>DenseNet(different variations)</p></li><li><p>NASNet</p></li><li>PNASNet</li><li>VGG</li><li>Xception</li><li>ResNeXt</li><li>EfficientNet, etc.</li></ul><p>大部分预训练的最先进模型可以在 GitHub 上的 pytorch- pretrainedmodels 资源库中找到：<a href="https://github.com/Cadene/pretrained-models.pytorch。详细讨论这些模型不在本章（和本书）范围之内。既然我们只关注应用，那就让我们看看这样的预训练模型如何用于分割任务。">https://github.com/Cadene/pretrained-models.pytorch。详细讨论这些模型不在本章（和本书）范围之内。既然我们只关注应用，那就让我们看看这样的预训练模型如何用于分割任务。</a></p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page206_image.png" alt=""></p><p align="center"><b>图 8：U-Net架构</b> </p><p>分割（Segmentation）是计算机视觉中相当流行的一项任务。在分割任务中，我们试图从背景中移除/提取前景。 前景和背景可以有不同的定义。我们也可以说，这是一项像素分类任务，你的工作是给给定图像中的每个像素分配一个类别。事实上，我们正在处理的气胸数据集就是一项分割任务。在这项任务中，我们需要对给定的胸部放射图像进行气胸分割。用于分割任务的最常用模型是 U-Net。其结构如图 8 所示。</p><p>U-Net 包括两个部分：编码器和解码器。编码器与您目前所见过的任何 U-Net 都是一样的。解码器则有些不同。解码器由上卷积层组成。在上卷积（up-convolutions）（<strong>转置卷积</strong>transposed convolutions）中，我们使用滤波器，当应用到一个小图像时，会产生一个大图像。在 PyTorch 中，您可以使用 ConvTranspose2d 来完成这一操作。必须注意的是，上卷积与上采样并不相同。上采样是一个简单的过程，我们在图像上应用一个函数来调整它的大小。在上卷积中，我们要学习滤波器。我们将编码器的某些部分作为某些解码器的输入。这对 上卷积层非常重要。</p><p>让我们看看 U-Net 是如何实现的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个双卷积层</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">double_conv</span>(<span class="params">in_channels, out_channels</span>):</span><br><span class="line">    conv = nn.Sequential(</span><br><span class="line">        nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>),</span><br><span class="line">        nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        nn.Conv2d(out_channels, out_channels, kernel_size=<span class="number">3</span>),</span><br><span class="line">        nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> conv</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义函数用于裁剪输入张量</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">crop_tensor</span>(<span class="params">tensor, target_tensor</span>):</span><br><span class="line">    target_size = target_tensor.size()[<span class="number">2</span>]</span><br><span class="line">    tensor_size = tensor.size()[<span class="number">2</span>]</span><br><span class="line">    delta = tensor_size - target_size</span><br><span class="line">    delta = delta // <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> tensor[:, :, delta:tensor_size - delta, delta:tensor_size - delta]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义 U-Net 模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(UNet, self).__init()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义池化层，编码器和解码器的双卷积层</span></span><br><span class="line">        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.down_conv_1 = double_conv(<span class="number">1</span>, <span class="number">64</span>)</span><br><span class="line">        self.down_conv_2 = double_conv(<span class="number">64</span>, <span class="number">128</span>)</span><br><span class="line">        self.down_conv_3 = double_conv(<span class="number">128</span>, <span class="number">256</span>)</span><br><span class="line">        self.down_conv_4 = double_conv(<span class="number">256</span>, <span class="number">512</span>)</span><br><span class="line">        self.down_conv_5 = double_conv(<span class="number">512</span>, <span class="number">1024</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义上采样层和解码器的双卷积层</span></span><br><span class="line">        self.up_trans_1 = nn.ConvTranspose2d(in_channels=<span class="number">1024</span>, out_channels=<span class="number">512</span>, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.up_conv_1 = double_conv(<span class="number">1024</span>, <span class="number">512</span>)</span><br><span class="line">        self.up_trans_2 = nn.ConvTranspose2d(in_channels=<span class="number">512</span>, out_channels=<span class="number">256</span>, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.up_conv_2 = double_conv(<span class="number">512</span>, <span class="number">256</span>)</span><br><span class="line">        self.up_trans_3 = nn.ConvTranspose2d(in_channels=<span class="number">256</span>, out_channels=<span class="number">128</span>, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.up_conv_3 = double_conv(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.up_trans_4 = nn.ConvTranspose2d(in_channels=<span class="number">128</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line">        self.up_conv_4 = double_conv(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义输出层</span></span><br><span class="line">        self.out = nn.Conv2d(in_channels=<span class="number">64</span>, out_channels=<span class="number">2</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image</span>):</span><br><span class="line">        <span class="comment"># 编码器部分</span></span><br><span class="line">        x1 = self.down_conv_1(image)</span><br><span class="line">        x2 = self.max_pool_2x2(x1)</span><br><span class="line">        x3 = self.down_conv_2(x2)</span><br><span class="line">        x4 = self.max_pool_2x2(x3)</span><br><span class="line">        x5 = self.down_conv_3(x4)</span><br><span class="line">        x6 = self.max_pool_2x2(x5)</span><br><span class="line">        x7 = self.down_conv_4(x6)</span><br><span class="line">        x8 = self.max_pool_2x2(x7)</span><br><span class="line">        x9 = self.down_conv_5(x8)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解码器部分</span></span><br><span class="line">        x = self.up_trans_1(x9)</span><br><span class="line">        y = crop_tensor(x7, x)</span><br><span class="line">        x = self.up_conv_1(torch.cat([x, y], axis=<span class="number">1</span>))</span><br><span class="line">        x = self.up_trans_2(x)</span><br><span class="line">        y = crop_tensor(x5, x)</span><br><span class="line">        x = self.up_conv_2(torch.cat([x, y], axis=<span class="number">1</span>))</span><br><span class="line">        x = self.up_trans_3(x)</span><br><span class="line">        y = crop_tensor(x3, x)</span><br><span class="line">        x = self.up_conv_3(torch.cat([x, y], axis=<span class="number">1</span>))</span><br><span class="line">        x = self.up_trans_4(x)</span><br><span class="line">        y = crop_tensor(x1, x)</span><br><span class="line">        x = self.up_conv_4(torch.cat([x, y], axis=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 输出层</span></span><br><span class="line">        out = self.out(x)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    image = torch.rand((<span class="number">1</span>, <span class="number">1</span>, <span class="number">572</span>, <span class="number">572</span>))</span><br><span class="line">    model = UNet()</span><br><span class="line">    <span class="built_in">print</span>(model(image))</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>请注意，我上面展示的 U-Net 实现是 U-Net 论文的原始实现。互联网上有很多不同的实现方法。 有些人喜欢使用双线性采样代替转置卷积进行上采样，但这并不是论文的真正实现。不过，它的性能可能会更好。在上图所示的原始实现中，有一个单通道图像，输出中有两个通道：一个是前景，一个是背景。正如你所看到的，这可以很容易地为任意数量的类和任意数量的输入通道进行定制。在此实现中，输入图像的大小与输出图像的大小不同，因为我们使用的是无填充卷积（convolutions without padding）。</p><p>我们可以看到，U-Net 的编码器部分只是一个简单的卷积网络。 因此，我们可以用任何网络（如 ResNet）来替换它。 这种替换也可以通过预训练权重来完成。因此，我们可以使用基于 ResNet 的编码器，该编码器已在 ImageNet 和通用解码器上进行了预训练。我们可以使用多种不同的网络架构来代替 ResNet。Pavel Yakubovskiy 所著的《Segmentation Models Pytorch》就是许多此类变体的实现，其中编码器可以被预训练模型所取代。让我们应用基于 ResNet 的 U-Net 来解决气胸检测问题。</p><p>大多数类似的问题都有两个输入：原始图像和掩码（mask）。 如果有多个对象，就会有多个掩码。 在我们的气胸数据集中，我们得到的是 RLE。RLE 代表运行长度编码，是一种表示二进制掩码以节省空间的方法。深入研究 RLE 超出了本章的范围。因此，假设我们有一张输入图像和相应的掩码。让我们先设计一个数据集类，用于输出图像和掩码图像。请注意，我们创建的脚本几乎可以应用于任何分割问题。训练数据集是一个 CSV 文件，只包含图像 ID（也是文件名）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageFile</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> albumentations <span class="keyword">import</span> (Compose,</span><br><span class="line">                            OneOf,</span><br><span class="line">                            RandomBrightnessContrast,</span><br><span class="line">                            RandomGamma,</span><br><span class="line">                            ShiftScaleRotate, )</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置PIL图像加载截断的处理</span></span><br><span class="line">ImageFile.LOAD_TRUNCATED_IMAGES = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建SIIM数据集类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SIIMDataset</span>(torch.utils.data.Dataset):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, image_ids, transform=<span class="literal">True</span>, preprocessing_fn=<span class="literal">None</span></span>):</span><br><span class="line">        self.data = defaultdict(<span class="built_in">dict</span>)</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.preprocessing_fn = preprocessing_fn</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 定义数据增强</span></span><br><span class="line">        self.aug = Compose(</span><br><span class="line">            [ShiftScaleRotate(</span><br><span class="line">                shift_limit=<span class="number">0.0625</span>,</span><br><span class="line">                scale_limit=<span class="number">0.1</span>,</span><br><span class="line">                rotate_limit=<span class="number">10</span>, p=<span class="number">0.8</span></span><br><span class="line">            ),</span><br><span class="line">             OneOf(</span><br><span class="line">                 [</span><br><span class="line">                     RandomGamma(</span><br><span class="line">                         gamma_limit=(<span class="number">90</span>, <span class="number">110</span>)</span><br><span class="line">                     ),</span><br><span class="line">                     RandomBrightnessContrast(</span><br><span class="line">                         brightness_limit=<span class="number">0.1</span>,</span><br><span class="line">                         contrast_limit=<span class="number">0.1</span></span><br><span class="line">                     ),</span><br><span class="line">                 ],</span><br><span class="line">                 p=<span class="number">0.5</span>,</span><br><span class="line">             ),</span><br><span class="line">            ]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 构建数据字典，其中包含图像和掩码的路径信息</span></span><br><span class="line">        <span class="keyword">for</span> imgid <span class="keyword">in</span> image_ids:</span><br><span class="line">            files = glob.glob(os.path.join(TRAIN_PATH, imgid, <span class="string">&quot;*.png&quot;</span>))</span><br><span class="line">            self.data[counter] = &#123;</span><br><span class="line">                <span class="string">&quot;img_path&quot;</span>: os.path.join(</span><br><span class="line">                    TRAIN_PATH, imgid + <span class="string">&quot;.png&quot;</span></span><br><span class="line">                ),</span><br><span class="line">                <span class="string">&quot;mask_path&quot;</span>: os.path.join(</span><br><span class="line">                    TRAIN_PATH, imgid + <span class="string">&quot;_mask.png&quot;</span></span><br><span class="line">                ),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        img_path = self.data[item][<span class="string">&quot;img_path&quot;</span>]</span><br><span class="line">        mask_path = self.data[item][<span class="string">&quot;mask_path&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打开图像并将其转换为RGB模式</span></span><br><span class="line">        img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">        img = img.convert(<span class="string">&quot;RGB&quot;</span>)</span><br><span class="line">        img = np.array(img)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 打开掩码图像，并将其转换为浮点数</span></span><br><span class="line">        mask = Image.<span class="built_in">open</span>(mask_path)</span><br><span class="line">        mask = (mask &gt;= <span class="number">1</span>).astype(<span class="string">&quot;float32&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果需要进行数据增强</span></span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="literal">True</span>:</span><br><span class="line">            augmented = self.aug(image=img, mask=mask)</span><br><span class="line">            img = augmented[<span class="string">&quot;image&quot;</span>]</span><br><span class="line">            mask = augmented[<span class="string">&quot;mask&quot;</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 应用预处理函数（如果有）</span></span><br><span class="line">        img = self.preprocessing_fn(img)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 返回图像和掩码</span></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&quot;image&quot;</span>: transforms.ToTensor()(img),</span><br><span class="line">            <span class="string">&quot;mask&quot;</span>: transforms.ToTensor()(mask).<span class="built_in">float</span>(),</span><br><span class="line">        &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>有了数据集类之后，我们就可以创建一个训练函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> segmentation_models_pytorch <span class="keyword">as</span> smp</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> apex <span class="keyword">import</span> amp</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> lr_scheduler</span><br><span class="line"><span class="keyword">from</span> dataset <span class="keyword">import</span> SIIMDataset</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义训练数据集CSV文件路径</span></span><br><span class="line">TRAINING_CSV = <span class="string">&quot;../input/train_pneumothorax.csv&quot;</span></span><br><span class="line"><span class="comment"># 定义训练和测试的批量大小</span></span><br><span class="line">TRAINING_BATCH_SIZE = <span class="number">16</span></span><br><span class="line">TEST_BATCH_SIZE = <span class="number">4</span></span><br><span class="line"><span class="comment"># 定义训练的时期数</span></span><br><span class="line">EPOCHS = <span class="number">10</span></span><br><span class="line"><span class="comment"># 指定使用的编码器和权重</span></span><br><span class="line">ENCODER = <span class="string">&quot;resnet18&quot;</span></span><br><span class="line">ENCODER_WEIGHTS = <span class="string">&quot;imagenet&quot;</span></span><br><span class="line"><span class="comment"># 指定设备（GPU）</span></span><br><span class="line">DEVICE = <span class="string">&quot;cuda&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义训练函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">dataset, data_loader, model, criterion, optimizer</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    num_batches = <span class="built_in">int</span>(<span class="built_in">len</span>(dataset) / data_loader.batch_size)</span><br><span class="line">    tk0 = tqdm(data_loader, total=num_batches)</span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> tk0:</span><br><span class="line">        inputs = d[<span class="string">&quot;image&quot;</span>]</span><br><span class="line">        targets = d[<span class="string">&quot;mask&quot;</span>]</span><br><span class="line">        inputs = inputs.to(DEVICE, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">        targets = targets.to(DEVICE, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = model(inputs)</span><br><span class="line">        loss = criterion(outputs, targets)</span><br><span class="line">        <span class="keyword">with</span> amp.scale_loss(loss, optimizer) <span class="keyword">as</span> scaled_loss:</span><br><span class="line">            scaled_loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">    tk0.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义评估函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">dataset, data_loader, model</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    final_loss = <span class="number">0</span></span><br><span class="line">    num_batches = <span class="built_in">int</span>(<span class="built_in">len</span>(dataset) / data_loader.batch_size)</span><br><span class="line">    tk0 = tqdm(data_loader, total=num_batches)</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> tk0:</span><br><span class="line">            inputs = d[<span class="string">&quot;image&quot;</span>]</span><br><span class="line">            targets = d[<span class="string">&quot;mask&quot;</span>]</span><br><span class="line">            inputs = inputs to (DEVICE, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">            targets = targets.to(DEVICE, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">            output = model(inputs)</span><br><span class="line">            loss = criterion(output, targets)</span><br><span class="line">            final_loss += loss</span><br><span class="line">        tk0.close()</span><br><span class="line">        <span class="keyword">return</span> final_loss / num_batches</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    df = pd.read_csv(TRAINING_CSV)</span><br><span class="line">    df_train, df_valid = model_selection.train_test_split(</span><br><span class="line">        df, random_state=<span class="number">42</span>, test_size=<span class="number">0.1</span></span><br><span class="line">    )</span><br><span class="line">    training_images = df_train.image_id.values</span><br><span class="line">    validation_images = df_valid.image_id.values</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建 U-Net 模型</span></span><br><span class="line">    model = smp.Unet(</span><br><span class="line">        encoder_name=ENCODER,</span><br><span class="line">        encoder_weights=ENCODER_WEIGHTS,</span><br><span class="line">        classes=<span class="number">1</span>,</span><br><span class="line">        activation=<span class="literal">None</span>,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取数据预处理函数</span></span><br><span class="line">    prep_fn = smp.encoders.get_preprocessing_fn(</span><br><span class="line">        ENCODER,</span><br><span class="line">        ENCODER_WEIGHTS</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将模型放在设备上</span></span><br><span class="line">    model.to(DEVICE)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建训练数据集</span></span><br><span class="line">    train_dataset = SIIMDataset(</span><br><span class="line">        training_images,</span><br><span class="line">        transform=<span class="literal">True</span>,</span><br><span class="line">        preprocessing_fn=prep_fn,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建训练数据加载器</span></span><br><span class="line">    train_loader = torch.utils.data.DataLoader(</span><br><span class="line">        train_dataset,</span><br><span class="line">        batch_size=TRAINING_BATCH_SIZE,</span><br><span class="line">        shuffle=<span class="literal">True</span>,</span><br><span class="line">        num_workers=<span class="number">12</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建验证数据集</span></span><br><span class="line">    valid_dataset = SIIMDataset(</span><br><span class="line">        validation_images,</span><br><span class="line">        transform=<span class="literal">False</span>,</span><br><span class="line">        preprocessing_fn=prep_fn,</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建验证数据加载器</span></span><br><span class="line">    valid_loader = torch.utils.data.DataLoader(</span><br><span class="line">        valid_dataset,</span><br><span class="line">        batch_size=TEST_BATCH_SIZE,</span><br><span class="line">        shuffle=<span class="literal">True</span>,</span><br><span class="line">        num_workers=<span class="number">4</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义优化器</span></span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义学习率调度器</span></span><br><span class="line">    scheduler = lr_scheduler.ReduceLROnPlateau(</span><br><span class="line">        optimizer, mode=<span class="string">&quot;min&quot;</span>, patience=<span class="number">3</span>, verbose=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化 Apex 混合精度训练</span></span><br><span class="line">    model, optimizer = amp.initialize(</span><br><span class="line">        model, optimizer, opt_level=<span class="string">&quot;O1&quot;</span>, verbosity=<span class="number">0</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 如果有多个GPU，则使用 DataParallel 进行并行训练</span></span><br><span class="line">    <span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Let&#x27;s use <span class="subst">&#123;torch.cuda.device_count()&#125;</span> GPUs!&quot;</span>)</span><br><span class="line">        model = nn.DataParallel(model)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输出训练相关的信息</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Training batch size: <span class="subst">&#123;TRAINING_BATCH_SIZE&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Test batch size: <span class="subst">&#123;TEST_BATCH_SIZE&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epochs: <span class="subst">&#123;EPOCHS&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Image size: <span class="subst">&#123;IMAGE_SIZE&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Number of training images: <span class="subst">&#123;<span class="built_in">len</span>(train_dataset)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Number of validation images: <span class="subst">&#123;<span class="built_in">len</span>(valid_dataset)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Encoder: <span class="subst">&#123;ENCODER&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 循环训练多个时期</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Training Epoch: <span class="subst">&#123;epoch&#125;</span>&quot;</span>)</span><br><span class="line">        train(</span><br><span class="line">            train_dataset,</span><br><span class="line">            train_loader,</span><br><span class="line">            model,</span><br><span class="line">            criterion,</span><br><span class="line">            optimizer</span><br><span class="line">        )</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Validation Epoch: <span class="subst">&#123;epoch&#125;</span>&quot;</span>)</span><br><span class="line">        val_log = evaluate(</span><br><span class="line">            valid_dataset,</span><br><span class="line">            valid_loader,</span><br><span class="line">            model</span><br><span class="line">        )</span><br><span class="line">        scheduler.step(val_log[<span class="string">&quot;loss&quot;</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在分割问题中，你可以使用各种损失函数，例如二元交叉熵、focal 损失、dice 损失等。我把这个问题留给 读者根据评估指标来决定合适的损失。当训练这样一个模型时，您将建立预测气胸位置的模型，如图 9 所示。在上述代码中，我们使用英伟达 apex 进行了混合精度训练。请注意，从 PyTorch 1.6.0+ 版本开始，PyTorch 本身就提供了这一功能。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page219_image.png" alt=""></p><p align="center"><b>图 9：从训练有素的模型中检测到气胸的示例（可能不是正确预测）。</b> </p><p>我在一个名为 “Well That’s Fantastic Machine Learning (WTFML) “的 python 软件包中收录了一些常用函数。让我们看看它如何帮助我们为 FGVC 202013 植物病理学挑战赛中的植物图像建立多类分类模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> albumentations</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> wtfml.engine <span class="keyword">import</span> Engine</span><br><span class="line"><span class="keyword">from</span> wtfml.data_loaders.image <span class="keyword">import</span> ClassificationDataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义损失函数，实现密集交叉熵</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DenseCrossEntropy</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(DenseCrossEntropy, self).__init__()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, logits, labels</span>):</span><br><span class="line">        logits = logits.<span class="built_in">float</span>()</span><br><span class="line">        labels = labels.<span class="built_in">float</span>()</span><br><span class="line">        logprobs = F.log_softmax(logits, dim=-<span class="number">1</span>)</span><br><span class="line">        loss = -labels * logprobs</span><br><span class="line">        loss = loss.<span class="built_in">sum</span>(-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> loss.mean()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义神经网络模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init()</span><br><span class="line">        self.base_model = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">        in_features = self.base_model.fc.in_features</span><br><span class="line">        self.out = nn.Linear(in_features, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, image, targets=<span class="literal">None</span></span>):</span><br><span class="line">        batch_size, C, H, W = image.shape</span><br><span class="line">        x = self.base_model.conv1(image)</span><br><span class="line">        x = self.base_model.bn1(x)</span><br><span class="line">        x = self.base_model.relu(x)</span><br><span class="line">        x = self.base_model.maxpool(x)</span><br><span class="line">        x = self.base_model.layer1(x)</span><br><span class="line">        x = self.base_model.layer2(x)</span><br><span class="line">        x = self.base_model.layer3(x)</span><br><span class="line">        x = self.base_model.layer4(x)</span><br><span class="line">        x = F.adaptive_avg_pool2d(x, <span class="number">1</span>).reshape(batch_size, -<span class="number">1</span>)</span><br><span class="line">        x = self.out(x)</span><br><span class="line">        loss = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> targets <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            loss = DenseCrossEntropy()(x, targets.type_as(x))</span><br><span class="line">        <span class="keyword">return</span> x, loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 命令行参数解析器</span></span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--data_path&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, )</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--device&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,)</span><br><span class="line">    parser.add_argument(<span class="string">&quot;--epochs&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从CSV文件加载数据</span></span><br><span class="line">    df = pd.read_csv(os.path.join(args.data_path, <span class="string">&quot;train.csv&quot;</span>))</span><br><span class="line">    images = df.image_id.values.tolist()</span><br><span class="line">    images = [os.path.join(args.data_path, <span class="string">&quot;images&quot;</span>, i + <span class="string">&quot;.jpg&quot;</span>) <span class="keyword">for</span> i <span class="keyword">in</span> images]</span><br><span class="line">    targets = df[[<span class="string">&quot;healthy&quot;</span>, <span class="string">&quot;multiple_diseases&quot;</span>, <span class="string">&quot;rust&quot;</span>, <span class="string">&quot;scab&quot;</span>]].values</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建神经网络模型</span></span><br><span class="line">    model = Model()</span><br><span class="line">    model.to(args.device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义均值和标准差以及数据增强</span></span><br><span class="line">    mean = (<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>)</span><br><span class="line">    std = (<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>)</span><br><span class="line">    aug = albumentations.Compose(</span><br><span class="line">        [</span><br><span class="line">            albumentations.Normalize(</span><br><span class="line">                mean,</span><br><span class="line">                std,</span><br><span class="line">                max_pixel_value=<span class="number">255.0</span>,</span><br><span class="line">                always_apply=<span class="literal">True</span></span><br><span class="line">            )</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 分割训练集和验证集</span></span><br><span class="line">    (</span><br><span class="line">        train_images, valid_images,</span><br><span class="line">        train_targets, valid_targets</span><br><span class="line">    ) = train_test_split(images, targets)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建训练数据加载器</span></span><br><span class="line">    train_loader = ClassificationDataLoader(</span><br><span class="line">        image_paths=train_images,</span><br><span class="line">        targets=train_targets,</span><br><span class="line">        resize=(<span class="number">128</span>, <span class="number">128</span>),</span><br><span class="line">        augmentations=aug,</span><br><span class="line">    ).fetch(</span><br><span class="line">        batch_size=<span class="number">16</span>,</span><br><span class="line">        num_workers=<span class="number">4</span>,</span><br><span class="line">        drop_last=<span class="literal">False</span>,</span><br><span class="line">        shuffle=<span class="literal">True</span>,</span><br><span class="line">        tpu=<span class="literal">False</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建验证数据加载器</span></span><br><span class="line">    valid_loader = ClassificationDataLoader(</span><br><span class="line">        image_paths=valid_images,</span><br><span class="line">        targets=valid_targets,</span><br><span class="line">        resize=(<span class="number">128</span>, <span class="number">128</span>),</span><br><span class="line">        augmentations=aug,</span><br><span class="line">    ).fetch(</span><br><span class="line">        batch_size=<span class="number">16</span>,</span><br><span class="line">        num_workers=<span class="number">4</span>,</span><br><span class="line">        drop_last=<span class="literal">False</span>,</span><br><span class="line">        shuffle=<span class="literal">False</span>,</span><br><span class="line">        tpu=<span class="literal">False</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建优化器</span></span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">5e-4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建学习率调度器</span></span><br><span class="line">    scheduler = torch.optim.lr_scheduler.StepLR(</span><br><span class="line">        optimizer, step_size=<span class="number">15</span>, gamma=<span class="number">0.6</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 循环训练多个时期</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):</span><br><span class="line">        <span class="comment"># 训练模型</span></span><br><span class="line">        train_loss = Engine.train(</span><br><span class="line">            train_loader, model, optimizer, device=args.device</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 评估模型</span></span><br><span class="line">        valid_loss = Engine.evaluate(</span><br><span class="line">            valid_loader, model, device=args.device</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 打印损失信息</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;epoch&#125;</span>, Train Loss=<span class="subst">&#123;train_loss&#125;</span> Valid Loss=<span class="subst">&#123;valid_loss&#125;</span>&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>有了数据后，就可以运行脚本了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">python plant.py --data_path ../../plant_pathology --device cuda --</span><br><span class="line">epochs 2</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|█████████████| 86/86 [00:12&lt;00:00, 6.73it/s, loss=0.723]</span></span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|█████████████ 29/29 [00:04&lt;00:00, 6.62it/s, loss=0.433]</span></span><br><span class="line">0, Train Loss=0.7228777609592261 Valid Loss=0.4327834551704341</span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|█████████████| 86/86 [00:12&lt;00:00, 6.74it/s, loss=0.271]</span></span><br><span class="line"><span class="meta prompt_">100%</span><span class="language-bash">|█████████████ 29/29 [00:04&lt;00:00, 6.63it/s, loss=0.568]</span></span><br><span class="line">1, Train Loss=0.2708700496790021 Valid Loss=0.56841839541649</span><br></pre></td></tr></table></figure><p>正如你所看到的，这让我们构建模型变得简单，代码也易于阅读和理解。没有任何封装的 PyTorch 效果最好。图像中不仅仅有分类，还有很多其他的内容，如果我开始写所有的内容，就得再写一本书了， 接近（几乎）任何图像问题（作者在开玩笑）。</p>]]></content>
      
      
      <categories>
          
          <category> AAAMLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>文本分类或回归方法</title>
      <link href="/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E6%88%96%E5%9B%9E%E5%BD%92%E6%96%B9%E6%B3%95/"/>
      <url>/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E6%88%96%E5%9B%9E%E5%BD%92%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="文本分类或回归方法"><a href="#文本分类或回归方法" class="headerlink" title="文本分类或回归方法"></a>文本分类或回归方法</h1><p>文本问题是我的最爱。一般来说，这些问题也被称为<strong>自然语言处理（NLP）问题</strong>。NLP 问题与图像问题也有很大不同。你需要创建以前从未为表格问题创建过的数据管道。你需要了解商业案例，才能建立一个好的模型。顺便说一句，机器学习中的任何事情都是如此。建立模型会让你达到一定的水平，但要想改善和促进你所建立模型的业务，你必须了解它对业务的影响。</p><p>NLP 问题有很多种，其中最常见的是字符串分类。很多时候，我们会看到人们在处理表格数据或图像时表现出色，但在处理文本时，他们甚至不知道从何入手。文本数据与其他类型的数据集没有什么不同。对于计算机来说，一切都是数字。</p><p>假设我们从情感分类这一基本任务开始。我们将尝试对电影评论进行情感分类。因此，您有一个文本，并有与之相关的情感。你将如何处理这类问题？是应用深度神经网络？ 不，绝对错了。你要从最基本的开始。让我们先看看这些数据是什么样子的。</p><p>我们从<strong>IMDB 电影评论数据集</strong>开始，该数据集包含 25000 篇正面情感评论和 25000 篇负面情感评论。</p><p>我将在此讨论的概念几乎适用于任何文本分类数据集。</p><p>这个数据集非常容易理解。一篇评论对应一个目标变量。请注意，我写的是评论而不是句子。评论就是一堆句子。所以，到目前为止，你一定只看到了对单句的分类，但在这个问题中，我们将对多个句子进行分类。简单地说，这意味着不仅一个句子会对情感产生影响，而且情感得分是多个句子得分的组合。数据简介如图 1 所示。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page225_image.png" alt=""></p><p>如何着手解决这样的问题？一个简单的方法就是手工制作两份单词表。一个列表包含你能想象到的所有正面词汇，例如好、棒、好等；另一个列表包含所有负面词汇，例如坏、恶等。我们先不要举例说明坏词，否则这本书就只能供 18 岁以上的人阅读了。一旦你有了这些列表，你甚至不需要一个模型来进行预测。这些列表也被称为情感词典。你可以用一个简单的计数器来计算句子中正面和负面词语的数量。如果正面词语的数量较多，则表示该句子具有正面情感；如果负面词语的数量较多，则表示该句子具有负面情感。如果句子中没有这些词，则可以说该句子具有中性情感。这是最古老的方法之一，现在仍有人在使用。它也不需要太多代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">find_sentiment</span>(<span class="params">sentence, pos, neg</span>):</span><br><span class="line">sentence = sentence.split()</span><br><span class="line">    sentence = <span class="built_in">set</span>(sentence)</span><br><span class="line">num_common_pos = <span class="built_in">len</span>(sentence.intersection(pos))</span><br><span class="line">num_common_neg = <span class="built_in">len</span>(sentence.intersection(neg))</span><br><span class="line"><span class="keyword">if</span> num_common_pos &gt; num_common_neg:</span><br><span class="line"><span class="keyword">return</span> <span class="string">&quot;positive&quot;</span></span><br><span class="line"><span class="keyword">if</span> num_common_pos &lt; num_common_neg:</span><br><span class="line"><span class="keyword">return</span> <span class="string">&quot;negative&quot;</span></span><br><span class="line"><span class="keyword">return</span> <span class="string">&quot;neutral&quot;</span></span><br></pre></td></tr></table></figure><p>不过，这种方法考虑的因素并不多。正如你所看到的，我们的 split() 也并不完美。如果使用 split()，就会出现这样的句子：</p><p>“hi, how are you?”</p><p>经过分割后变为：</p><p>[“hi,”, “how”,”are”,”you?”]</p><p>这种方法并不理想，因为单词中包含了逗号和问号，它们并没有被分割。因此，如果没有在分割前对这些特殊字符进行预处理，不建议使用这种方法。将字符串拆分为单词列表称为标记化。最流行的标记化方法之一来自 <strong>NLTK（自然语言工具包）</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [X]: <span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line">In [X]: sentence = <span class="string">&quot;hi, how are you?&quot;</span></span><br><span class="line">In [X]: sentence.split()</span><br><span class="line">Out[X]: [<span class="string">&#x27;hi,&#x27;</span>, <span class="string">&#x27;how&#x27;</span>, <span class="string">&#x27;are&#x27;</span>, <span class="string">&#x27;you?&#x27;</span>]</span><br><span class="line">In [X]: word_tokenize(sentence)</span><br><span class="line">Out[X]: [<span class="string">&#x27;hi&#x27;</span>, <span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;how&#x27;</span>, <span class="string">&#x27;are&#x27;</span>, <span class="string">&#x27;you&#x27;</span>, <span class="string">&#x27;?&#x27;</span>]</span><br></pre></td></tr></table></figure><p>正如您所看到的，使用 NLTK 的单词标记化功能，同一个句子的拆分效果要好得多。使用单词列表进行对比的效果也会更好！这就是我们将应用于第一个情感检测模型的方法。</p><p>在处理 NLP 分类问题时，您应该经常尝试的基本模型之一是<strong>词袋模型（bag of words）</strong>。在词袋模型中，我们创建一个巨大的稀疏矩阵，存储语料库（语料库=所有文档=所有句子）中所有单词的计数。为此，我们将使用 scikit-learn 中的 CountVectorizer。让我们看看它是如何工作的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line">corpus = [</span><br><span class="line">    <span class="string">&quot;hello, how are you?&quot;</span>,</span><br><span class="line">    <span class="string">&quot;im getting bored at home. And you? What do you think?&quot;</span>,</span><br><span class="line">    <span class="string">&quot;did you know about counts&quot;</span>,</span><br><span class="line">    <span class="string">&quot;let&#x27;s see if this works!&quot;</span>,</span><br><span class="line">    <span class="string">&quot;YES!!!!&quot;</span></span><br><span class="line">]</span><br><span class="line">ctv = CountVectorizer()</span><br><span class="line">ctv.fit(corpus)</span><br><span class="line">corpus_transformed = ctv.transform(corpus)</span><br></pre></td></tr></table></figure><p>如果我们打印 corpus_transformed，就会得到类似下面的结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">0</span>, <span class="number">2</span>)      <span class="number">1</span></span><br><span class="line">(<span class="number">0</span>, <span class="number">9</span>)      <span class="number">1</span></span><br><span class="line">(<span class="number">0</span>, <span class="number">11</span>)     <span class="number">1</span></span><br><span class="line">(<span class="number">0</span>, <span class="number">22</span>)     <span class="number">1</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">1</span>)      <span class="number">1</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">3</span>)      <span class="number">1</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">4</span>)      <span class="number">1</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">7</span>)      <span class="number">1</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">8</span>)      <span class="number">1</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">10</span>)     <span class="number">1</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">13</span>)     <span class="number">1</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">17</span>)     <span class="number">1</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">19</span>)     <span class="number">1</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">22</span>)     <span class="number">2</span></span><br><span class="line">(<span class="number">2</span>, <span class="number">0</span>)      <span class="number">1</span></span><br><span class="line">(<span class="number">2</span>, <span class="number">5</span>)      <span class="number">1</span></span><br><span class="line">(<span class="number">2</span>, <span class="number">6</span>)      <span class="number">1</span></span><br><span class="line">(<span class="number">2</span>, <span class="number">14</span>)     <span class="number">1</span></span><br><span class="line">(<span class="number">2</span>, <span class="number">22</span>)     <span class="number">1</span></span><br><span class="line">(<span class="number">3</span>, <span class="number">12</span>)     <span class="number">1</span></span><br><span class="line">(<span class="number">3</span>, <span class="number">15</span>)     <span class="number">1</span></span><br><span class="line">(<span class="number">3</span>, <span class="number">16</span>)     <span class="number">1</span></span><br><span class="line">(<span class="number">3</span>, <span class="number">18</span>)     <span class="number">1</span></span><br><span class="line">(<span class="number">3</span>, <span class="number">20</span>)     <span class="number">1</span></span><br><span class="line">(<span class="number">4</span>, <span class="number">21</span>)     <span class="number">1</span></span><br></pre></td></tr></table></figure><p>在前面的章节中，我们已经见识过这种表示法。即稀疏表示法。因此，语料库现在是一个稀疏矩阵，其中第一个样本有 4 个元素，第二个样本有 10 个元素，以此类推，第三个样本有 5 个元素，以此类推。我们还可以看到，这些元素都有相关的计数。有些元素会出现两次，有些则只有一次。例如，在样本 2（第 1 行）中，我们看到第 22 列的数值是 2。这是为什么呢？第 22 列是什么？</p><p>CountVectorizer 的工作方式是首先对句子进行标记化处理，然后为每个标记赋值。因此，每个标记都由一个唯一索引表示。这些唯一索引就是我们看到的列。CountVectorizer 会存储这些信息。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(ctv.vocabulary_)</span><br><span class="line">&#123;<span class="string">&#x27;hello&#x27;</span>: <span class="number">9</span>, <span class="string">&#x27;how&#x27;</span>: <span class="number">11</span>, <span class="string">&#x27;are&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;you&#x27;</span>: <span class="number">22</span>, <span class="string">&#x27;im&#x27;</span>: <span class="number">13</span>, <span class="string">&#x27;getting&#x27;</span>: <span class="number">8</span>,</span><br><span class="line"><span class="string">&#x27;bored&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;at&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;home&#x27;</span>: <span class="number">10</span>, <span class="string">&#x27;and&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;what&#x27;</span>: <span class="number">19</span>, <span class="string">&#x27;do&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;think&#x27;</span>:</span><br><span class="line"><span class="number">17</span>, <span class="string">&#x27;did&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;know&#x27;</span>: <span class="number">14</span>, <span class="string">&#x27;about&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;counts&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;let&#x27;</span>: <span class="number">15</span>, <span class="string">&#x27;see&#x27;</span>: <span class="number">16</span>,</span><br><span class="line"><span class="string">&#x27;if&#x27;</span>: <span class="number">12</span>, <span class="string">&#x27;this&#x27;</span>: <span class="number">18</span>, <span class="string">&#x27;works&#x27;</span>: <span class="number">20</span>, <span class="string">&#x27;yes&#x27;</span>: <span class="number">21</span>&#125;</span><br></pre></td></tr></table></figure><p>我们看到，索引 22 属于 “you”，而在第二句中，我们使用了两次 “you”。我希望大家现在已经清楚什么是词袋了。但是我们还缺少一些特殊字符。有时，这些特殊字符也很有用。例如，”? “在大多数句子中表示疑问句。让我们把 scikit-learn 的 word_tokenize 整合到 CountVectorizer 中，看看会发生什么。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"></span><br><span class="line">corpus = [</span><br><span class="line">    <span class="string">&quot;hello, how are you?&quot;</span>,</span><br><span class="line">    <span class="string">&quot;im getting bored at home. And you? What do you think?&quot;</span>,</span><br><span class="line">    <span class="string">&quot;did you know about counts&quot;</span>,</span><br><span class="line">    <span class="string">&quot;let&#x27;s see if this works!&quot;</span>,</span><br><span class="line">    <span class="string">&quot;YES!!!!&quot;</span></span><br><span class="line">]</span><br><span class="line">ctv = CountVectorizer(tokenizer=word_tokenize, token_pattern=<span class="literal">None</span>)</span><br><span class="line">ctv.fit(corpus)</span><br><span class="line">corpus_transformed = ctv.transform(corpus)</span><br><span class="line"><span class="built_in">print</span>(ctv.vocabulary_)</span><br></pre></td></tr></table></figure><p>这样，我们的词袋就变成了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;hello&#x27;</span>: <span class="number">14</span>, <span class="string">&#x27;,&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;how&#x27;</span>: <span class="number">16</span>, <span class="string">&#x27;are&#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;you&#x27;</span>: <span class="number">27</span>, <span class="string">&#x27;?&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;im&#x27;</span>: <span class="number">18</span>,</span><br><span class="line"><span class="string">&#x27;getting&#x27;</span>: <span class="number">13</span>, <span class="string">&#x27;bored&#x27;</span>: <span class="number">9</span>, <span class="string">&#x27;at&#x27;</span>: <span class="number">8</span>, <span class="string">&#x27;home&#x27;</span>: <span class="number">15</span>, <span class="string">&#x27;.&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;and&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;what&#x27;</span>:</span><br><span class="line"><span class="number">24</span>, <span class="string">&#x27;do&#x27;</span>: <span class="number">12</span>, <span class="string">&#x27;think&#x27;</span>: <span class="number">22</span>, <span class="string">&#x27;did&#x27;</span>: <span class="number">11</span>, <span class="string">&#x27;know&#x27;</span>: <span class="number">19</span>, <span class="string">&#x27;about&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;counts&#x27;</span>:</span><br><span class="line"><span class="number">10</span>, <span class="string">&#x27;let&#x27;</span>: <span class="number">20</span>, <span class="string">&quot;&#x27;s&quot;</span>: <span class="number">1</span>, <span class="string">&#x27;see&#x27;</span>: <span class="number">21</span>, <span class="string">&#x27;if&#x27;</span>: <span class="number">17</span>, <span class="string">&#x27;this&#x27;</span>: <span class="number">23</span>, <span class="string">&#x27;works&#x27;</span>: <span class="number">25</span>,</span><br><span class="line"><span class="string">&#x27;!&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;yes&#x27;</span>: <span class="number">26</span>&#125;</span><br></pre></td></tr></table></figure><p>我们现在可以利用 IMDB 数据集中的所有句子创建一个稀疏矩阵，并建立一个模型。该数据集中正负样本的比例为 1:1，因此我们可以使用准确率作为衡量标准。我们将使用 StratifiedKFold 并创建一个脚本来训练 5 个折叠。你会问使用哪个模型？对于高维稀疏数据，哪个模型最快？逻辑回归。我们将首先使用逻辑回归来处理这个数据集，并创建第一个基准模型。</p><p>让我们看看如何做到这一点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/imdb.csv&quot;</span>)</span><br><span class="line">    df.sentiment = df.sentiment.apply(</span><br><span class="line">        <span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x == <span class="string">&quot;positive&quot;</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">&quot;kfold&quot;</span>] = -<span class="number">1</span></span><br><span class="line">    df = df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    y = df.sentiment.values</span><br><span class="line">    kf = model_selection.StratifiedKFold(n_splits=<span class="number">5</span>)</span><br><span class="line">    <span class="keyword">for</span> f, (t_, v_) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kf.split(X=df, y=y)):</span><br><span class="line">        df.loc[v_, <span class="string">&#x27;kfold&#x27;</span>] = f</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        train_df = df[df.kfold != fold_].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">        test_df = df[df.kfold == fold_].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">        count_vec = CountVectorizer(</span><br><span class="line">            tokenizer=word_tokenize,</span><br><span class="line">            token_pattern=<span class="literal">None</span></span><br><span class="line">        )</span><br><span class="line">        count_vec.fit(train_df.review)</span><br><span class="line">        xtrain = count_vec.transform(train_df.review)</span><br><span class="line">        xtest = count_vec.transform(test_df.review)</span><br><span class="line">        model = linear_model.LogisticRegression()</span><br><span class="line">        model.fit(xtrain, train_df.sentiment)</span><br><span class="line">        preds = model.predict(xtest)</span><br><span class="line">        accuracy = metrics.accuracy_score(test_df.sentiment, preds)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Fold: <span class="subst">&#123;fold_&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Accuracy = <span class="subst">&#123;accuracy&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure><p>这段代码的运行需要一定的时间，但可以得到以下输出结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Fold: <span class="number">0</span></span><br><span class="line">Accuracy = <span class="number">0.8903</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">1</span></span><br><span class="line">Accuracy = <span class="number">0.897</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">2</span></span><br><span class="line">Accuracy = <span class="number">0.891</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">3</span></span><br><span class="line">Accuracy = <span class="number">0.8914</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">4</span></span><br><span class="line">Accuracy = <span class="number">0.8931</span></span><br></pre></td></tr></table></figure><p>哇，准确率已经达到 89%，而我们所做的只是使用词袋和逻辑回归！这真是太棒了！不过，这个模型的训练花费了很多时间，让我们看看能否通过使用朴素贝叶斯分类器来缩短训练时间。朴素贝叶斯分类器在 NLP 任务中相当流行，因为稀疏矩阵非常庞大，而朴素贝叶斯是一个简单的模型。要使用这个模型，需要更改一个导入和模型的行。让我们看看这个模型的性能如何。我们将使用 scikit-learn 中的 MultinomialNB。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> naive_bayes</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = naive_bayes.MultinomialNB()</span><br><span class="line">model.fit(xtrain, train_df.sentiment)</span><br></pre></td></tr></table></figure><p>得到如下结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Fold: <span class="number">0</span></span><br><span class="line">Accuracy = <span class="number">0.8444</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">1</span></span><br><span class="line">Accuracy = <span class="number">0.8499</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">2</span></span><br><span class="line">Accuracy = <span class="number">0.8422</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">3</span></span><br><span class="line">Accuracy = <span class="number">0.8443</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">4</span></span><br><span class="line">Accuracy = <span class="number">0.8455</span></span><br></pre></td></tr></table></figure><p>我们看到这个分数很低。但朴素贝叶斯模型的速度非常快。</p><p>NLP 中的另一种方法是 TF-IDF，如今大多数人都倾向于忽略或不屑于了解这种方法。TF 是术语频率，IDF 是反向文档频率。从这些术语来看，这似乎有些困难，但通过 TF 和 IDF 的计算公式，事情就会变得很明显。</p><script type="math/tex; mode=display">TF(t) = \frac{Number\ of\ times\ a\ term\ t\ appears\ in\ a\ document}{Total\ number\ of\ terms\ in \ the\ document}</script><script type="math/tex; mode=display">IDF(t) = LOG\left(\frac{Total\ number\ of\ documents}{Number\ of\ documents with\ term\ t\ in\ it}\right)</script><p>术语 t 的 TF-IDF 定义为：</p><script type="math/tex; mode=display">TF-IDF(t) = TF(t) \times IDF(t)</script><p>与 scikit-learn 中的 CountVectorizer 类似，我们也有 TfidfVectorizer。让我们试着像使用 CountVectorizer 一样使用它。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"></span><br><span class="line">corpus = [</span><br><span class="line">    <span class="string">&quot;hello, how are you?&quot;</span>,</span><br><span class="line"><span class="string">&quot;im getting bored at home. And you? What do you think?&quot;</span>,</span><br><span class="line"><span class="string">&quot;did you know about counts&quot;</span>,</span><br><span class="line"><span class="string">&quot;let&#x27;s see if this works!&quot;</span>,</span><br><span class="line"><span class="string">&quot;YES!!!!&quot;</span></span><br><span class="line">]</span><br><span class="line">tfv = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=<span class="literal">None</span>)</span><br><span class="line">tfv.fit(corpus)</span><br><span class="line">corpus_transformed = tfv.transform(corpus)</span><br><span class="line"><span class="built_in">print</span>(corpus_transformed)</span><br></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">0</span>, <span class="number">27</span>)     <span class="number">0.2965698850220162</span></span><br><span class="line">(<span class="number">0</span>, <span class="number">16</span>)     <span class="number">0.4428321995085722</span></span><br><span class="line">(<span class="number">0</span>, <span class="number">14</span>)     <span class="number">0.4428321995085722</span></span><br><span class="line">(<span class="number">0</span>, <span class="number">7</span>)      <span class="number">0.4428321995085722</span></span><br><span class="line">(<span class="number">0</span>, <span class="number">4</span>)      <span class="number">0.35727423026525224</span></span><br><span class="line">(<span class="number">0</span>, <span class="number">2</span>)      <span class="number">0.4428321995085722</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">27</span>)     <span class="number">0.35299699146792735</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">24</span>)     <span class="number">0.2635440111190765</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">22</span>)     <span class="number">0.2635440111190765</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">18</span>)     <span class="number">0.2635440111190765</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">15</span>)     <span class="number">0.2635440111190765</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">13</span>)     <span class="number">0.2635440111190765</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">12</span>)     <span class="number">0.2635440111190765</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">9</span>)      <span class="number">0.2635440111190765</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">8</span>)      <span class="number">0.2635440111190765</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">6</span>)      <span class="number">0.2635440111190765</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">4</span>)      <span class="number">0.42525129752567803</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">3</span>)      <span class="number">0.2635440111190765</span></span><br><span class="line">(<span class="number">2</span>, <span class="number">27</span>)     <span class="number">0.31752680284846835</span></span><br><span class="line">(<span class="number">2</span>, <span class="number">19</span>)     <span class="number">0.4741246485558491</span></span><br><span class="line">(<span class="number">2</span>, <span class="number">11</span>)     <span class="number">0.4741246485558491</span></span><br><span class="line">(<span class="number">2</span>, <span class="number">10</span>)     <span class="number">0.4741246485558491</span></span><br><span class="line">(<span class="number">2</span>, <span class="number">5</span>)      <span class="number">0.4741246485558491</span></span><br><span class="line">(<span class="number">3</span>, <span class="number">25</span>)     <span class="number">0.38775666010579296</span></span><br><span class="line">(<span class="number">3</span>, <span class="number">23</span>)     <span class="number">0.38775666010579296</span></span><br><span class="line">(<span class="number">3</span>, <span class="number">21</span>)     <span class="number">0.38775666010579296</span></span><br><span class="line">(<span class="number">3</span>, <span class="number">20</span>)     <span class="number">0.38775666010579296</span></span><br><span class="line">(<span class="number">3</span>, <span class="number">17</span>)     <span class="number">0.38775666010579296</span></span><br><span class="line">(<span class="number">3</span>, <span class="number">1</span>)      <span class="number">0.38775666010579296</span></span><br><span class="line">(<span class="number">3</span>, <span class="number">0</span>)      <span class="number">0.3128396318588854</span></span><br><span class="line">(<span class="number">4</span>, <span class="number">26</span>)     <span class="number">0.2959842226518677</span></span><br><span class="line">(<span class="number">4</span>, <span class="number">0</span>)      <span class="number">0.9551928286692534</span></span><br></pre></td></tr></table></figure><p>可以看到，这次我们得到的不是整数值，而是浮点数。 用 TfidfVectorizer 代替 CountVectorizer 也是小菜一碟。Scikit-learn 还提供了 TfidfTransformer。如果你使用的是计数值，可以使用 TfidfTransformer 并获得与 TfidfVectorizer 相同的效果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    train_df = df[df.kfold != fold_].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    test_df = df[df.kfold == fold_].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    tfidf_vec = TfidfVectorizer(</span><br><span class="line">        tokenizer=word_tokenize,</span><br><span class="line">        token_pattern=<span class="literal">None</span></span><br><span class="line">    )</span><br><span class="line">    tfidf_vec.fit(train_df.review)</span><br><span class="line">    xtrain = tfidf_vec.transform(train_df.review)</span><br><span class="line">    xtest = tfidf_vec.transform(test_df.review)</span><br><span class="line">    model = linear_model.LogisticRegression()</span><br><span class="line">    model.fit(xtrain, train_df.sentiment)</span><br><span class="line">    preds = model.predict(xtest)</span><br><span class="line">    accuracy = metrics.accuracy_score(test_df.sentiment, preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold: <span class="subst">&#123;fold_&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Accuracy = <span class="subst">&#123;accuracy&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure><p>我们可以看看 TF-IDF 在逻辑回归模型上的表现如何。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Fold: <span class="number">0</span></span><br><span class="line">Accuracy = <span class="number">0.8976</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">1</span></span><br><span class="line">Accuracy = <span class="number">0.8998</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">2</span></span><br><span class="line">Accuracy = <span class="number">0.8948</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">3</span></span><br><span class="line">Accuracy = <span class="number">0.8912</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">4</span></span><br><span class="line">Accuracy = <span class="number">0.8995</span></span><br></pre></td></tr></table></figure><p>我们看到，这些分数都比 CountVectorizer 高一些，因此它成为了我们想要击败的新基准。</p><p>NLP 中另一个有趣的概念是 N-gram。N-grams 是按顺序排列的单词组合。N-grams 很容易创建。您只需注意顺序即可。为了让事情变得更简单，我们可以使用 NLTK 的 N-gram 实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk <span class="keyword">import</span> ngrams</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"></span><br><span class="line">N = <span class="number">3</span></span><br><span class="line">sentence = <span class="string">&quot;hi, how are you?&quot;</span></span><br><span class="line">tokenized_sentence = word_tokenize(sentence)</span><br><span class="line">n_grams = <span class="built_in">list</span>(ngrams(tokenized_sentence, N))</span><br><span class="line"><span class="built_in">print</span>(n_grams)</span><br></pre></td></tr></table></figure><p>由此得到：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[(<span class="string">&#x27;hi&#x27;</span>, <span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;how&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;how&#x27;</span>, <span class="string">&#x27;are&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;how&#x27;</span>, <span class="string">&#x27;are&#x27;</span>, <span class="string">&#x27;you&#x27;</span>),</span><br><span class="line">(<span class="string">&#x27;are&#x27;</span>, <span class="string">&#x27;you&#x27;</span>, <span class="string">&#x27;?&#x27;</span>)]</span><br></pre></td></tr></table></figure><p>同样，我们还可以创建 2-gram 或 4-gram 等。现在，这些 n-gram 将成为我们词汇表的一部分，当我们计算计数或 tf-idf 时，我们会将一个 n-gram 视为一个全新的标记。因此，在某种程度上，我们是在结合上下文。scikit-learn 的 CountVectorizer 和 TfidfVectorizer 实现都通过 ngram_range 参数提供 n-gram，该参数有最小和最大限制。默认情况下，该参数为（1, 1）。当我们将其改为 (1, 3) 时，我们将看到单字元、双字元和三字元。代码改动很小。</p><p>由于到目前为止我们使用 tf-idf 得到了最好的结果，让我们来看看包含 n-grams 直至 trigrams 是否能改进模型。唯一需要修改的是 TfidfVectorizer 的初始化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tfidf_vec = TfidfVectorizer(</span><br><span class="line">    tokenizer=word_tokenize,</span><br><span class="line">    token_pattern=<span class="literal">None</span>,</span><br><span class="line">    ngram_range=(<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>让我们看看是否会有改进。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Fold: <span class="number">0</span></span><br><span class="line">Accuracy = <span class="number">0.8931</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">1</span></span><br><span class="line">Accuracy = <span class="number">0.8941</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">2</span></span><br><span class="line">Accuracy = <span class="number">0.897</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">3</span></span><br><span class="line">Accuracy = <span class="number">0.8922</span></span><br><span class="line"></span><br><span class="line">Fold: <span class="number">4</span></span><br><span class="line">Accuracy = <span class="number">0.8847</span></span><br></pre></td></tr></table></figure><p>看起来还行，但我们看不到任何改进。 也许我们可以通过多使用 bigrams 来获得改进。 我不会在这里展示这一部分。也许你可以自己试着做。</p><p>NLP 的基础知识还有很多。你必须知道的一个术语是词干提取（strmming）。另一个是词形还原（lemmatization）。<strong>词干提取和词形还原</strong>可以将一个词减少到最小形式。在词干提取的情况下，处理后的单词称为词干单词，而在词形还原情况下，处理后的单词称为词形。必须指出的是，词形还原比词干提取更激进，而词干提取更流行和广泛。词干和词形都来自语言学。如果你打算为某种语言制作词干或词型，需要对该语言有深入的了解。如果要过多地介绍这些知识，就意味着要在本书中增加一章。使用 NLTK 软件包可以轻松完成词干提取和词形还原。让我们来看看这两种方法的一些示例。有许多不同类型的词干提取和词形还原器。我将用最常见的 Snowball Stemmer 和 WordNet Lemmatizer 来举例说明。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> nltk.stem <span class="keyword">import</span> WordNetLemmatizer</span><br><span class="line"><span class="keyword">from</span> nltk.stem.snowball <span class="keyword">import</span> SnowballStemmer</span><br><span class="line"></span><br><span class="line">lemmatizer = WordNetLemmatizer()</span><br><span class="line">stemmer = SnowballStemmer(<span class="string">&quot;english&quot;</span>)</span><br><span class="line">words = [<span class="string">&quot;fishing&quot;</span>, <span class="string">&quot;fishes&quot;</span>, <span class="string">&quot;fished&quot;</span>]</span><br><span class="line"><span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;word=<span class="subst">&#123;word&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;stemmed_word=<span class="subst">&#123;stemmer.stem(word)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;lemma=<span class="subst">&#123;lemmatizer.lemmatize(word)&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure><p>这将打印：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">word=fishing</span><br><span class="line">stemmed_word=fish</span><br><span class="line">lemma=fishing</span><br><span class="line">word=fishes</span><br><span class="line">stemmed_word=fish</span><br><span class="line">lemma=fish</span><br><span class="line">word=fished</span><br><span class="line">stemmed_word=fish</span><br><span class="line">lemma=fished</span><br></pre></td></tr></table></figure><p>正如您所看到的，词干提取和词形还原是截然不同的。当我们进行词干提取时，我们得到的是一个词的最小形式，它可能是也可能不是该词所属语言词典中的一个词。但是，在词形还原情况下，这将是一个词。现在，您可以自己尝试添加词干和词素化，看看是否能改善结果。</p><p>您还应该了解的一个主题是主题提取。<strong>主题提取</strong>可以使用非负矩阵因式分解（NMF）或潜在语义分析（LSA）来完成，后者也被称为奇异值分解或 SVD。这些分解技术可将数据简化为给定数量的成分。 您可以在从 CountVectorizer 或 TfidfVectorizer 中获得的稀疏矩阵上应用其中任何一种技术。</p><p>让我们把它应用到之前使用过的 TfidfVetorizer 上。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> decomposition</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line">corpus = pd.read_csv(<span class="string">&quot;../input/imdb.csv&quot;</span>, nrows=<span class="number">10000</span>)</span><br><span class="line">corpus = corpus.review.values</span><br><span class="line">tfv = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=<span class="literal">None</span>)</span><br><span class="line">tfv.fit(corpus)</span><br><span class="line">corpus_transformed = tfv.transform(corpus)</span><br><span class="line">svd = decomposition.TruncatedSVD(n_components=<span class="number">10</span>)</span><br><span class="line">corpus_svd = svd.fit(corpus_transformed)</span><br><span class="line">sample_index = <span class="number">0</span></span><br><span class="line">feature_scores = <span class="built_in">dict</span>(</span><br><span class="line">    <span class="built_in">zip</span>(</span><br><span class="line">        tfv.get_feature_names(),</span><br><span class="line">        corpus_svd.components_[sample_index]</span><br><span class="line">    )</span><br><span class="line">)</span><br><span class="line">N = <span class="number">5</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">sorted</span>(feature_scores, key=feature_scores.get, reverse=<span class="literal">True</span>)[:N])</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>您可以使用循环来运行多个样本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">N = <span class="number">5</span></span><br><span class="line"><span class="keyword">for</span> sample_index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    feature_scores = <span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">zip</span>(</span><br><span class="line">            tfv.get_feature_names(),</span><br><span class="line">            corpus_svd.components_[sample_index]</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(</span><br><span class="line">        <span class="built_in">sorted</span>(</span><br><span class="line">            feature_scores,</span><br><span class="line">            key=feature_scores.get,</span><br><span class="line">            reverse=<span class="literal">True</span></span><br><span class="line">        )[:N]</span><br><span class="line">    )</span><br></pre></td></tr></table></figure><p>输出结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">&#x27;the&#x27;</span>, <span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;.&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;and&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;br&#x27;</span>, <span class="string">&#x27;&lt;&#x27;</span>, <span class="string">&#x27;&gt;&#x27;</span>, <span class="string">&#x27;/&#x27;</span>, <span class="string">&#x27;-&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;i&#x27;</span>, <span class="string">&#x27;movie&#x27;</span>, <span class="string">&#x27;!&#x27;</span>, <span class="string">&#x27;it&#x27;</span>, <span class="string">&#x27;was&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;,&#x27;</span>, <span class="string">&#x27;!&#x27;</span>, <span class="string">&quot;&#x27;&#x27;&quot;</span>, <span class="string">&#x27;``&#x27;</span>, <span class="string">&#x27;you&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;!&#x27;</span>, <span class="string">&#x27;the&#x27;</span>, <span class="string">&#x27;...&#x27;</span>, <span class="string">&quot;&#x27;&#x27;&quot;</span>, <span class="string">&#x27;``&#x27;</span>]</span><br></pre></td></tr></table></figure><p>你可以看到，这根本说不通。怎么办呢？让我们试着清理一下，看看是否有意义。要清理任何文本数据，尤其是 pandas 数据帧中的文本数据，可以创建一个函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> string</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clean_text</span>(<span class="params">s</span>):</span><br><span class="line">    s = s.split()</span><br><span class="line">    s = <span class="string">&quot; &quot;</span>.join(s)</span><br><span class="line">    s = re.sub(<span class="string">f&#x27;[<span class="subst">&#123;re.escape(string.punctuation)&#125;</span>]&#x27;</span>, <span class="string">&#x27;&#x27;</span>, s)</span><br><span class="line">    <span class="keyword">return</span> s</span><br></pre></td></tr></table></figure><p>该函数会将 “hi, how are you????” 这样的字符串转换为 “hi how are you”。让我们把这个函数应用到旧的 SVD 代码中，看看它是否能给提取的主题带来提升。使用 pandas，你可以使用 apply 函数将清理代码 “应用 “到任意给定的列中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">corpus = pd.read_csv(<span class="string">&quot;../input/imdb.csv&quot;</span>, nrows=<span class="number">10000</span>)</span><br><span class="line">corpus.loc[:, <span class="string">&quot;review&quot;</span>] = corpus.review.apply(clean_text)</span><br></pre></td></tr></table></figure><p>请注意，我们只在主 SVD 脚本中添加了一行代码，这就是使用函数和 pandas 应用的好处。这次生成的主题如下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">&#x27;the&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;and&#x27;</span>, <span class="string">&#x27;of&#x27;</span>, <span class="string">&#x27;to&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;i&#x27;</span>, <span class="string">&#x27;movie&#x27;</span>, <span class="string">&#x27;it&#x27;</span>, <span class="string">&#x27;was&#x27;</span>, <span class="string">&#x27;this&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;the&#x27;</span>, <span class="string">&#x27;was&#x27;</span>, <span class="string">&#x27;i&#x27;</span>, <span class="string">&#x27;were&#x27;</span>, <span class="string">&#x27;of&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;her&#x27;</span>, <span class="string">&#x27;was&#x27;</span>, <span class="string">&#x27;she&#x27;</span>, <span class="string">&#x27;i&#x27;</span>, <span class="string">&#x27;he&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;br&#x27;</span>, <span class="string">&#x27;to&#x27;</span>, <span class="string">&#x27;they&#x27;</span>, <span class="string">&#x27;he&#x27;</span>, <span class="string">&#x27;show&#x27;</span>]</span><br></pre></td></tr></table></figure><p>呼！至少这比我们之前好多了。但你知道吗？你可以通过在清理功能中删除停止词（stopwords）来使它变得更好。什么是 stopwords？它们是存在于每种语言中的高频词。例如，在英语中，这些词包括 “a”、”an”、”the”、”for “等。删除停止词并非总是明智的选择，这在很大程度上取决于业务问题。像 “I need a new dog”这样的句子，去掉停止词后会变成 “need new dog”，此时我们不知道谁需要 new dog。</p><p>如果我们总是删除停止词，就会丢失很多上下文信息。你可以在 NLTK 中找到许多语言的停止词，如果没有，你也可以在自己喜欢的搜索引擎上快速搜索一下。</p><p>现在，让我们转到大多数人都喜欢使用的方法：深度学习。但首先，我们必须知道什么是词嵌入（embedings for words）。你已经看到，到目前为止，我们已经将标记转换成了数字。因此，如果某个语料库中有 N 个唯一的词块，它们可以用 0 到 N-1 之间的整数来表示。现在，我们将用向量来表示这些整数词块。这种将单词表示成向量的方法被称为单词嵌入或单词向量。谷歌的 Word2Vec 是将单词转换为向量的最古老方法之一。此外，还有 Facebook 的 FastText 和斯坦福大学的 GloVe（用于单词表示的全局向量）。这些方法彼此大相径庭。</p><p>其基本思想是建立一个浅层网络，通过重构输入句子来学习单词的嵌入。因此，您可以通过使用周围的所有单词来训练网络预测一个缺失的单词，在此过程中，网络将学习并更新所有相关单词的嵌入。这种方法也被称为连续词袋或 CBoW 模型。您也可以尝试使用一个单词来预测上下文中的单词。这就是所谓的跳格模型。Word2Vec 可以使用这两种方法学习嵌入。</p><p>FastText 可以学习字符 n-gram 的嵌入。和单词 n-gram 一样，如果我们使用的是字符，则称为字符 n-gram，最后，GloVe 通过共现矩阵来学习这些嵌入。因此，我们可以说，所有这些不同类型的嵌入最终都会返回一个字典，其中键是语料库（例如英语维基百科）中的单词，值是大小为 N（通常为 300）的向量。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page244_image.png" alt=""></p><p align="center"><b>图 1：可视化二维单词嵌入。</b> </p><p>图 1 显示了二维单词嵌入的可视化效果。假设我们以某种方式完成了词语的二维表示。图 1 显示，如果从 Berlin（德国首都）的向量中减去德国（Germany）的向量，再加上法国（France）的向量，就会得到一个接近 Paris（法国首都）的向量。由此可见，嵌入式也能进行类比。 这并不总是正确的，但这样的例子有助于理解单词嵌入的作用。像 “hi, how are you?” 这样的句子可以用下面的一堆向量来表示。</p><p>hi ─&gt; [vector (v1) of size 300]</p><p>, ─&gt; [vector (v2) of size 300]</p><p>how ─&gt; [vector (v3) of size 300]</p><p>are ─&gt; [vector (v4) of size 300]</p><p>you ─&gt; [vector (v5) of size 300]</p><p>? ─&gt; [vector (v6) of size 300]</p><p>使用这些信息有多种方法。最简单的方法之一就是使用嵌入向量。如上例所示，每个单词都有一个 1x300 的嵌入向量。利用这些信息，我们可以计算出整个句子的嵌入。计算方法有多种。其中一种方法如下所示。在这个函数中，我们将给定句子中的所有单词向量提取出来，然后从所有标记词的单词向量中创建一个归一化的单词向量。这样就得到了一个句子向量。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sentence_to_vec</span>(<span class="params">s, embedding_dict, stop_words, tokenizer</span>):</span><br><span class="line">    words = <span class="built_in">str</span>(s).lower()</span><br><span class="line">    words = tokenizer(words)</span><br><span class="line">    words = [w <span class="keyword">for</span> w <span class="keyword">in</span> words <span class="keyword">if</span> <span class="keyword">not</span> w <span class="keyword">in</span> stop_words]</span><br><span class="line">    words = [w <span class="keyword">for</span> w <span class="keyword">in</span> words <span class="keyword">if</span> w.isalpha()]</span><br><span class="line">    M = []</span><br><span class="line">    <span class="keyword">for</span> w <span class="keyword">in</span> words:</span><br><span class="line">        <span class="keyword">if</span> w <span class="keyword">in</span> embedding_dict:</span><br><span class="line">            M.append(embedding_dict[w])</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(M) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> np.zeros(<span class="number">300</span>)</span><br><span class="line">    M = np.array(M)</span><br><span class="line">    v = M.<span class="built_in">sum</span>(axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> v / np.sqrt((v ** <span class="number">2</span>).<span class="built_in">sum</span>())</span><br></pre></td></tr></table></figure><p>我们可以用这种方法将所有示例转换成一个向量。我们能否使用 fastText 向量来改进之前的结果？每篇评论都有 300 个特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> word_tokenize</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_vectors</span>(<span class="params">fname</span>):</span><br><span class="line">    fin = io.<span class="built_in">open</span>(</span><br><span class="line">        fname,</span><br><span class="line">        <span class="string">&#x27;r&#x27;</span>,</span><br><span class="line">        encoding=<span class="string">&#x27;utf-8&#x27;</span>,</span><br><span class="line">        newline=<span class="string">&#x27;\n&#x27;</span>,</span><br><span class="line">        errors=<span class="string">&#x27;ignore&#x27;</span></span><br><span class="line">    )</span><br><span class="line">    n, d = <span class="built_in">map</span>(<span class="built_in">int</span>, fin.readline().split())</span><br><span class="line">    data = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fin:</span><br><span class="line">        tokens = line.rstrip().split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        data[tokens[<span class="number">0</span>]] = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">float</span>, tokens[<span class="number">1</span>:]))</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sentence_to_vec</span>(<span class="params">s, embedding_dict, stop_words, tokenizer</span>):</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/imdb.csv&quot;</span>)</span><br><span class="line">    df.sentiment = df.sentiment.apply(</span><br><span class="line">        <span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x == <span class="string">&quot;positive&quot;</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    )</span><br><span class="line">    df = df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Loading embeddings&quot;</span>)</span><br><span class="line">    embeddings = load_vectors(<span class="string">&quot;../input/crawl-300d-2M.vec&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Creating sentence vectors&quot;</span>)</span><br><span class="line">    vectors = []</span><br><span class="line">    <span class="keyword">for</span> review <span class="keyword">in</span> df.review.values:</span><br><span class="line">        vectors.append(</span><br><span class="line">            sentence_to_vec(</span><br><span class="line">                s = review,</span><br><span class="line">                embedding_dict = embeddings,</span><br><span class="line">                stop_words = [],</span><br><span class="line">                tokenizer = word_tokenize</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        vectors = np.array(vectors)</span><br><span class="line">        y = df.sentiment.values</span><br><span class="line">        kf = model_selection.StratifiedKFold(n_splits=<span class="number">5</span>)</span><br><span class="line">        <span class="keyword">for</span> fold_, (t_, v_) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kf.split(X=vectors, y=y)):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;Training fold: <span class="subst">&#123;fold_&#125;</span>&quot;</span>)</span><br><span class="line">        xtrain = vectors[t_, :]</span><br><span class="line">        ytrain = y[t_]</span><br><span class="line">        xtest = vectors[v_, :]</span><br><span class="line">        ytest = y[v_]</span><br><span class="line">        model = linear_model.LogisticRegression()</span><br><span class="line">        model.fit(xtrain, ytrain)</span><br><span class="line">        preds = model.predict(xtest)</span><br><span class="line">        accuracy = metrics.accuracy_score(ytest, preds)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Accuracy = <span class="subst">&#123;accuracy&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br></pre></td></tr></table></figure><p>这将得到如下结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Loading embeddings</span><br><span class="line">Creating sentence vectors</span><br><span class="line"></span><br><span class="line">Training fold: <span class="number">0</span></span><br><span class="line">Accuracy = <span class="number">0.8619</span></span><br><span class="line"></span><br><span class="line">Training fold: <span class="number">1</span></span><br><span class="line">Accuracy = <span class="number">0.8661</span></span><br><span class="line"></span><br><span class="line">Training fold: <span class="number">2</span></span><br><span class="line">Accuracy = <span class="number">0.8544</span></span><br><span class="line"></span><br><span class="line">Training fold: <span class="number">3</span></span><br><span class="line">Accuracy = <span class="number">0.8624</span></span><br><span class="line"></span><br><span class="line">Training fold: <span class="number">4</span></span><br><span class="line">Accuracy = <span class="number">0.8595</span></span><br></pre></td></tr></table></figure><p>Wow！真是出乎意料。我们所做的一切都是为了使用 FastText 嵌入。试着把嵌入式换成 GloVe，看看会发生什么。我把它作为一个练习留给大家。<br>当我们谈论文本数据时，我们必须牢记一件事。文本数据与时间序列数据非常相似。如图 2 所示，我们评论中的任何样本都是在不同时间戳上按递增顺序排列的标记序列，每个标记都可以表示为一个向量/嵌入。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page249_image.png" alt=""></p><p align="center"><b>图 2：将标记表示为嵌入，并将其视为时间序列</b> </p><p>这意味着我们可以使用广泛用于时间序列数据的模型，例如长短期记忆（LSTM）或门控递归单元（GRU），甚至卷积神经网络（CNN）。让我们看看如何在该数据集上训练一个简单的双向 LSTM 模型。</p><p>首先，我们将创建一个项目。你可以随意给它命名。然后，我们的第一步将是分割数据进行交叉验证。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/imdb.csv&quot;</span>)</span><br><span class="line">    df.sentiment = df.sentiment.apply(</span><br><span class="line">        <span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x == <span class="string">&quot;positive&quot;</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    )</span><br><span class="line">    df[<span class="string">&quot;kfold&quot;</span>] = -<span class="number">1</span></span><br><span class="line">    df = df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    y = df.sentiment.values</span><br><span class="line">    kf = model_selection.StratifiedKFold(n_splits=<span class="number">5</span>)</span><br><span class="line">    <span class="keyword">for</span> f, (t_, v_) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kf.split(X=df, y=y)):</span><br><span class="line">        df.loc[v_, <span class="string">&#x27;kfold&#x27;</span>] = f</span><br><span class="line">        df.to_csv(<span class="string">&quot;../input/imdb_folds.csv&quot;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>将数据集划分为多个折叠后，我们就可以在 dataset.py 中创建一个简单的数据集类。数据集类会返回一个训练或验证数据样本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">IMDBDataset</span>:</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, reviews, targets</span>):</span><br><span class="line">    self.reviews = reviews</span><br><span class="line">    self.target = targets</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(self.reviews)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">    review = self.reviews[item, :]</span><br><span class="line">    target = self.target[item]</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;review&quot;</span>: torch.tensor(review, dtype=torch.long),</span><br><span class="line">        <span class="string">&quot;target&quot;</span>: torch.tensor(target, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>完成数据集分类后，我们就可以创建 lstm.py，其中包含我们的 LSTM 模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LSTM</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, embedding_matrix</span>):</span><br><span class="line">        <span class="built_in">super</span>(LSTM, self).__init__()</span><br><span class="line">        num_words = embedding_matrix.shape[<span class="number">0</span>]</span><br><span class="line">        embed_dim = embedding_matrix.shape[<span class="number">1</span>]</span><br><span class="line">        self.embedding = nn.Embedding(</span><br><span class="line">            num_embeddings=num_words,</span><br><span class="line">            embedding_dim=embed_dim)</span><br><span class="line">        self.embedding.weight = nn.Parameter(</span><br><span class="line">            torch.tensor(</span><br><span class="line">                embedding_matrix,</span><br><span class="line">                dtype=torch.float32</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        self.embedding.weight.requires_grad = <span class="literal">False</span></span><br><span class="line">        self.lstm = nn.LSTM(</span><br><span class="line">            embed_dim,</span><br><span class="line">            <span class="number">128</span>,</span><br><span class="line">            bidirectional=<span class="literal">True</span>,</span><br><span class="line">            batch_first=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line">        self.out = nn.Linear(<span class="number">512</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">            x = self.embedding(x)</span><br><span class="line">            x, _ = self.lstm(x)</span><br><span class="line">            avg_pool = torch.mean(x, <span class="number">1</span>)</span><br><span class="line">            max_pool, _ = torch.<span class="built_in">max</span>(x, <span class="number">1</span>)</span><br><span class="line">            out = torch.cat((avg_pool, max_pool), <span class="number">1</span>)</span><br><span class="line">            out = self.out(out)</span><br><span class="line">            <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>现在，我们创建 engine.py，其中包含训练和评估函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">data_loader, model, optimizer, device</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> data_loader:</span><br><span class="line">        reviews = data[<span class="string">&quot;review&quot;</span>]</span><br><span class="line">        targets = data[<span class="string">&quot;target&quot;</span>]</span><br><span class="line">        reviews = reviews.to(device, dtype=torch.long)</span><br><span class="line">        targets = targets.to(device, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        predictions = model(reviews)</span><br><span class="line">        loss = nn.BCEWithLogitsLoss()(</span><br><span class="line">            predictions,</span><br><span class="line">            targets.view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">data_loader, model, device</span>):</span><br><span class="line">    final_predictions = []</span><br><span class="line">    final_targets = []</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> data_loader:</span><br><span class="line">            reviews = data[<span class="string">&quot;review&quot;</span>]</span><br><span class="line">            targets = data[<span class="string">&quot;target&quot;</span>]</span><br><span class="line">            reviews = reviews.to(device, dtype=torch.long)</span><br><span class="line">            targets = targets.to(device, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">            predictions = model(reviews)</span><br><span class="line">            predictions = predictions.cpu().numpy().tolist()</span><br><span class="line">            targets = data[<span class="string">&quot;target&quot;</span>].cpu().numpy().tolist()</span><br><span class="line">            final_predictions.extend(predictions)</span><br><span class="line">            final_targets.extend(targets)</span><br><span class="line">            <span class="keyword">return</span> final_predictions, final_targets</span><br></pre></td></tr></table></figure><p>这些函数将在 train.py 中为我们提供帮助，该函数用于训练多个折叠。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> config</span><br><span class="line"><span class="keyword">import</span> dataset</span><br><span class="line"><span class="keyword">import</span> engine</span><br><span class="line"><span class="keyword">import</span> lstm</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_vectors</span>(<span class="params">fname</span>):</span><br><span class="line">    fin = io.<span class="built_in">open</span>(</span><br><span class="line">        fname,</span><br><span class="line">        <span class="string">&#x27;r&#x27;</span>,</span><br><span class="line">        encoding=<span class="string">&#x27;utf-8&#x27;</span>,</span><br><span class="line">        newline=<span class="string">&#x27;\n&#x27;</span>,</span><br><span class="line">        errors=<span class="string">&#x27;ignore&#x27;</span></span><br><span class="line">    )</span><br><span class="line">    n, d = <span class="built_in">map</span>(<span class="built_in">int</span>, fin.readline().split())</span><br><span class="line">    data = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fin:</span><br><span class="line">        tokens = line.rstrip().split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">        data[tokens[<span class="number">0</span>]] = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">float</span>, tokens[<span class="number">1</span>:]))</span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_embedding_matrix</span>(<span class="params">word_index, embedding_dict</span>):</span><br><span class="line">    embedding_matrix = np.zeros((<span class="built_in">len</span>(word_index) + <span class="number">1</span>, <span class="number">300</span>))</span><br><span class="line">    <span class="keyword">for</span> word, i <span class="keyword">in</span> word_index.items():</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> embedding_dict:</span><br><span class="line">            embedding_matrix[i] = embedding_dict[word]</span><br><span class="line">    <span class="keyword">return</span> embedding_matrix</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">df, fold</span>):</span><br><span class="line">    train_df = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    valid_df = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Fitting tokenizer&quot;</span>)</span><br><span class="line">    tokenizer = tf.keras.preprocessing.text.Tokenizer()</span><br><span class="line">    tokenizer.fit_on_texts(df.review.values.tolist())</span><br><span class="line">    xtrain = tokenizer.texts_to_sequences(train_df.review.values)</span><br><span class="line">    xtest = tokenizer.texts_to_sequences(valid_df.review.values)</span><br><span class="line">    xtrain = tf.keras.preprocessing.sequence.pad_sequences(</span><br><span class="line">        xtrain, maxlen=config.MAX_LEN</span><br><span class="line">    )</span><br><span class="line">    xtest = tf.keras.preprocessing.sequence.pad_sequences(</span><br><span class="line">        xtest, maxlen=config.MAX_LEN</span><br><span class="line">    )</span><br><span class="line">    train_dataset = dataset.IMDBDataset(</span><br><span class="line">        reviews=xtrain,</span><br><span class="line">        targets=train_df.sentiment.values</span><br><span class="line">    )</span><br><span class="line">    train_data_loader = torch.utils.data.DataLoader(</span><br><span class="line">        train_dataset,</span><br><span class="line">        batch_size=config.TRAIN_BATCH_SIZE,</span><br><span class="line">        num_workers=<span class="number">2</span></span><br><span class="line">    )</span><br><span class="line">    valid_dataset = dataset.IMDBDataset(</span><br><span class="line">        reviews=xtest,</span><br><span class="line">        targets=valid_df.sentiment.values</span><br><span class="line">    )</span><br><span class="line">    valid_data_loader = torch.utils.data.DataLoader(</span><br><span class="line">        valid_dataset,</span><br><span class="line">        batch_size=config.VALID_BATCH_SIZE,</span><br><span class="line">        num_workers=<span class="number">1</span></span><br><span class="line">    )</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Loading embeddings&quot;</span>)</span><br><span class="line">    embedding_dict = load_vectors(<span class="string">&quot;../input/crawl-300d-2M.vec&quot;</span>)</span><br><span class="line">    embedding_matrix = create_embedding_matrix(</span><br><span class="line">        tokenizer.word_index, embedding_dict</span><br><span class="line">    )</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">    model = lstm.LSTM(embedding_matrix)</span><br><span class="line">    model.to(device)</span><br><span class="line">    optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Training Model&quot;</span>)</span><br><span class="line">    best_accuracy = <span class="number">0</span></span><br><span class="line">    early_stopping_counter = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(config.EPOCHS):</span><br><span class="line">        engine.train(train_data_loader, model, optimizer, device)</span><br><span class="line">        outputs, targets = engine.evaluate(</span><br><span class="line">            valid_data_loader, model, device</span><br><span class="line">        )</span><br><span class="line">        outputs = np.array(outputs) &gt;= <span class="number">0.5</span></span><br><span class="line">        accuracy = metrics.accuracy_score(targets, outputs)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;FOLD:<span class="subst">&#123;fold&#125;</span>, Epoch: <span class="subst">&#123;epoch&#125;</span>, Accuracy Score = <span class="subst">&#123;accuracy&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> accuracy &gt; best_accuracy:</span><br><span class="line">            best_accuracy = accuracy</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            early_stopping_counter += <span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> early_stopping_counter &gt; <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/imdb_folds.csv&quot;</span>)</span><br><span class="line">    run(df, fold=<span class="number">0</span>)</span><br><span class="line">    run(df, fold=<span class="number">1</span>)</span><br><span class="line">    run(df, fold=<span class="number">2</span>)</span><br><span class="line">    run(df, fold=<span class="number">3</span>)</span><br><span class="line">    run(df, fold=<span class="number">4</span>)</span><br></pre></td></tr></table></figure><p>最后是 config.py。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">MAX_LEN = <span class="number">128</span></span><br><span class="line">TRAIN_BATCH_SIZE = <span class="number">16</span></span><br><span class="line">VALID_BATCH_SIZE = <span class="number">8</span></span><br><span class="line">EPOCHS = <span class="number">10</span></span><br></pre></td></tr></table></figure><p>让我们看看输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FOLD:<span class="number">0</span>, Epoch: <span class="number">3</span>, Accuracy Score = <span class="number">0.9015</span></span><br><span class="line">FOLD:<span class="number">1</span>, Epoch: <span class="number">4</span>, Accuracy Score = <span class="number">0.9007</span></span><br><span class="line">FOLD:<span class="number">2</span>, Epoch: <span class="number">3</span>, Accuracy Score = <span class="number">0.8924</span></span><br><span class="line">FOLD:<span class="number">3</span>, Epoch: <span class="number">2</span>, Accuracy Score = <span class="number">0.9</span></span><br><span class="line">FOLD:<span class="number">4</span>, Epoch: <span class="number">1</span>, Accuracy Score = <span class="number">0.878</span></span><br></pre></td></tr></table></figure><p>这是迄今为止我们获得的最好成绩。 请注意，我只显示了每个折叠中精度最高的 Epoch。</p><p>你一定已经注意到，我们使用了预先训练的嵌入和简单的双向 LSTM。 如果你想改变模型，你可以只改变 lstm.py 中的模型并保持一切不变。 这种代码只需要很少的实验改动，并且很容易理解。 例如，您可以自己学习嵌入而不是使用预训练的嵌入，您可以使用其他一些预训练的嵌入，您可以组合多个预训练的嵌入，您可以使用 GRU，您可以在嵌入后使用空间 dropout，您可以添加 GRU LSTM 层之后，您可以添加两个 LSTM 层，您可以进行 LSTM-GRU-LSTM 配置，您可以用卷积层替换 LSTM 等，而无需对代码进行太多更改。 我提到的大部分内容只需要更改模型类。</p><p>当您使用预训练的嵌入时，尝试查看有多少单词无法找到嵌入以及原因。 预训练嵌入的单词越多，结果就越好。 我向您展示以下未注释的 (!) 函数，您可以使用它为任何类型的预训练嵌入创建嵌入矩阵，其格式与 glove 或 fastText 相同（可能需要进行一些更改）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">load_embeddings</span>(<span class="params">word_index, embedding_file, vector_length=<span class="number">300</span></span>):</span><br><span class="line">    max_features = <span class="built_in">len</span>(word_index) + <span class="number">1</span></span><br><span class="line">    words_to_find = <span class="built_in">list</span>(word_index.keys())</span><br><span class="line">    more_words_to_find = []</span><br><span class="line">    <span class="keyword">for</span> wtf <span class="keyword">in</span> words_to_find:</span><br><span class="line">        more_words_to_find.append(wtf)</span><br><span class="line">        more_words_to_find.append(<span class="built_in">str</span>(wtf).capitalize())</span><br><span class="line">    more_words_to_find = <span class="built_in">set</span>(more_words_to_find)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_coefs</span>(<span class="params">word, *arr</span>):</span><br><span class="line">    <span class="keyword">return</span> word, np.asarray(arr, dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line"></span><br><span class="line">embeddings_index = <span class="built_in">dict</span>(</span><br><span class="line">    get_coefs(*o.strip().split(<span class="string">&quot; &quot;</span>))</span><br><span class="line">    <span class="keyword">for</span> o <span class="keyword">in</span> <span class="built_in">open</span>(embedding_file)</span><br><span class="line">    <span class="keyword">if</span> o.split(<span class="string">&quot; &quot;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">in</span> more_words_to_find</span><br><span class="line">    <span class="keyword">and</span> <span class="built_in">len</span>(o) &gt; <span class="number">100</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">embedding_matrix = np.zeros((max_features, vector_length))</span><br><span class="line"><span class="keyword">for</span> word, i <span class="keyword">in</span> word_index.items():</span><br><span class="line">    <span class="keyword">if</span> i &gt;= max_features:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    embedding_vector = embeddings_index.get(word)</span><br><span class="line">    <span class="keyword">if</span> embedding_vector <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        embedding_vector = embeddings_index.get(</span><br><span class="line">            <span class="built_in">str</span>(word).capitalize()</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">if</span> embedding_vector <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        embedding_vector = embeddings_index.get(</span><br><span class="line">            <span class="built_in">str</span>(word).upper()</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">if</span> (embedding_vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">and</span> <span class="built_in">len</span>(embedding_vector) == vector_length):</span><br><span class="line">        embedding_matrix[i] = embedding_vector</span><br><span class="line">    <span class="keyword">return</span> embedding_matrix</span><br></pre></td></tr></table></figure><p>阅读并运行上面的函数，看看发生了什么。 该函数还可以修改为使用词干词或词形还原词。 最后，您希望训练语料库中的未知单词数量最少。 另一个技巧是学习嵌入层，即使其可训练，然后训练网络。</p><p>到目前为止，我们已经为分类问题构建了很多模型。 然而，现在是布偶时代，越来越多的人转向基于 Transformer 的模型。 基于 Transformer 的网络能够处理本质上长期的依赖关系。 LSTM 仅当它看到前一个单词时才查看下一个单词。 Transformer 的情况并非如此。 它可以同时查看整个句子中的所有单词。 因此，另一个优点是它可以轻松并行化并更有效地使用 GPU。</p><p>Transformers 是一个非常广泛的话题，有太多的模型：<strong>BERT、RoBERTa、XLNet、XLM-RoBERTa、T5</strong> 等。我将向您展示一种可用于所有这些模型（T5 除外）进行分类的通用方法 我们一直在讨论的问题。 请注意，这些 Transformer 需要训练它们所需的计算能力。 因此，如果您没有高端系统，与基于 LSTM 或 TF-IDF 的模型相比，训练模型可能需要更长的时间。</p><p>我们要做的第一件事是创建一个配置文件。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> transformers</span><br><span class="line">MAX_LEN = <span class="number">512</span></span><br><span class="line">TRAIN_BATCH_SIZE = <span class="number">8</span></span><br><span class="line">VALID_BATCH_SIZE = <span class="number">4</span></span><br><span class="line">EPOCHS = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">BERT_PATH = <span class="string">&quot;../input/bert_base_uncased/&quot;</span></span><br><span class="line">MODEL_PATH = <span class="string">&quot;model.bin&quot;</span></span><br><span class="line">TRAINING_FILE = <span class="string">&quot;../input/imdb.csv&quot;</span></span><br><span class="line">TOKENIZER = transformers.BertTokenizer.from_pretrained(</span><br><span class="line">    BERT_PATH,</span><br><span class="line">    do_lower_case=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>这里的配置文件是我们定义分词器和其他我们想要经常更改的参数的唯一地方 —— 这样我们就可以做很多实验而不需要进行大量更改。</p><p>下一步是构建数据集类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> config</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BERTDataset</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, review, target</span>):</span><br><span class="line">        self.review = review</span><br><span class="line">        self.target = target</span><br><span class="line">        self.tokenizer = config.TOKENIZER</span><br><span class="line">        self.max_len = config.MAX_LEN</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.review)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        review = <span class="built_in">str</span>(self.review[item])</span><br><span class="line">        review = <span class="string">&quot; &quot;</span>.join(review.split())</span><br><span class="line">        inputs = self.tokenizer.encode_plus(</span><br><span class="line">            review,</span><br><span class="line">            <span class="literal">None</span>,</span><br><span class="line">            add_special_tokens=<span class="literal">True</span>,</span><br><span class="line">            max_length=self.max_len,</span><br><span class="line">            pad_to_max_length=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line">        ids = inputs[<span class="string">&quot;input_ids&quot;</span>]</span><br><span class="line">        mask = inputs[<span class="string">&quot;attention_mask&quot;</span>]</span><br><span class="line">        token_type_ids = inputs[<span class="string">&quot;token_type_ids&quot;</span>]</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            <span class="string">&quot;ids&quot;</span>: torch.tensor(</span><br><span class="line">                ids, dtype=torch.long</span><br><span class="line">            ),</span><br><span class="line">            <span class="string">&quot;mask&quot;</span>: torch.tensor(</span><br><span class="line">                mask, dtype=torch.long</span><br><span class="line">            ),</span><br><span class="line">            <span class="string">&quot;token_type_ids&quot;</span>: torch.tensor(</span><br><span class="line">                token_type_ids, dtype=torch.long</span><br><span class="line">            ),</span><br><span class="line">            <span class="string">&quot;targets&quot;</span>: torch.tensor(</span><br><span class="line">                self.target[item], dtype=torch.<span class="built_in">float</span></span><br><span class="line">            )</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>现在我们来到了该项目的核心，即模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> config</span><br><span class="line"><span class="keyword">import</span> transformers</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">BERTBaseUncased</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(BERTBaseUncased, self).__init__()</span><br><span class="line">        self.bert = transformers.BertModel.from_pretrained(</span><br><span class="line">            config.BERT_PATH</span><br><span class="line">        )</span><br><span class="line">        self.bert_drop = nn.Dropout(<span class="number">0.3</span>)</span><br><span class="line">        self.out = nn.Linear(<span class="number">768</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, ids, mask, token_type_ids</span>):</span><br><span class="line">        hidden state</span><br><span class="line">        _, o2 = self.bert(</span><br><span class="line">            ids,</span><br><span class="line">            attention_mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids</span><br><span class="line">        )</span><br><span class="line">        bo = self.bert_drop(o2)</span><br><span class="line">        output = self.out(bo)</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure><p>该模型返回单个输出。 我们可以使用带有 logits 的二元交叉熵损失，它首先应用 sigmoid，然后计算损失。 这是在 engine.py 中完成的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loss_fn</span>(<span class="params">outputs, targets</span>):</span><br><span class="line">    <span class="keyword">return</span> nn.BCEWithLogitsLoss()(outputs, targets.view(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_fn</span>(<span class="params">data_loader, model, optimizer, device, scheduler</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> d <span class="keyword">in</span> data_loader:</span><br><span class="line">        ids = d[<span class="string">&quot;ids&quot;</span>]</span><br><span class="line">        token_type_ids = d[<span class="string">&quot;token_type_ids&quot;</span>]</span><br><span class="line">        mask = d[<span class="string">&quot;mask&quot;</span>]</span><br><span class="line">        targets = d[<span class="string">&quot;targets&quot;</span>]</span><br><span class="line">        ids = ids.to(device, dtype=torch.long)</span><br><span class="line">        token_type_ids = token_type_ids.to(device, dtype=torch.long)</span><br><span class="line">        mask = mask.to(device, dtype=torch.long)</span><br><span class="line">        targets = targets.to(device, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = model(</span><br><span class="line">            ids=ids,</span><br><span class="line">            mask=mask,</span><br><span class="line">            token_type_ids=token_type_ids</span><br><span class="line">        )</span><br><span class="line">        loss = loss_fn(outputs, targets)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        scheduler.step()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">eval_fn</span>(<span class="params">data_loader, model, device</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    fin_targets = []</span><br><span class="line">    fin_outputs = []</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> d <span class="keyword">in</span> data_loader:</span><br><span class="line">            ids = d[<span class="string">&quot;ids&quot;</span>]</span><br><span class="line">            token_type_ids = d[<span class="string">&quot;token_type_ids&quot;</span>]</span><br><span class="line">            mask = d[<span class="string">&quot;mask&quot;</span>]</span><br><span class="line">            targets = d[<span class="string">&quot;targets&quot;</span>]</span><br><span class="line">            ids = ids.to(device, dtype=torch.long)</span><br><span class="line">            token_type_ids = token_type_ids.to(device, dtype=torch.long)</span><br><span class="line">            mask = mask.to(device, dtype=torch.long)</span><br><span class="line">            targets = targets.to(device, dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">            outputs = model(</span><br><span class="line">                ids=ids,</span><br><span class="line">                mask=mask,</span><br><span class="line">                token_type_ids=token_type_ids</span><br><span class="line">            )</span><br><span class="line">            targets = targets.cpu().detach()</span><br><span class="line">            fin_targets.extend(targets.numpy().tolist())</span><br><span class="line">            outputs = torch.sigmoid(outputs).cpu().detach()</span><br><span class="line">fin_outputs.extend(outputs.numpy().tolist())</span><br><span class="line"><span class="keyword">return</span> fin_outputs, fin_targets</span><br></pre></td></tr></table></figure><p>最后，我们准备好训练了。 我们来看看训练脚本吧！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> config</span><br><span class="line"><span class="keyword">import</span> dataset</span><br><span class="line"><span class="keyword">import</span> engine</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> BERTBaseUncased</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AdamW</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> get_linear_schedule_with_warmup</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>():</span><br><span class="line">    dfx = pd.read_csv(config.TRAINING_FILE).fillna(<span class="string">&quot;none&quot;</span>)</span><br><span class="line">    dfx.sentiment = dfx.sentiment.apply(</span><br><span class="line">        <span class="keyword">lambda</span> x: <span class="number">1</span> <span class="keyword">if</span> x == <span class="string">&quot;positive&quot;</span> <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">    )</span><br><span class="line">    df_train, df_valid = model_selection.train_test_split(</span><br><span class="line">        dfx,</span><br><span class="line">        test_size=<span class="number">0.1</span>,</span><br><span class="line">        random_state=<span class="number">42</span>,</span><br><span class="line">        stratify=dfx.sentiment.values</span><br><span class="line">    )</span><br><span class="line">    df_train = df_train.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    df_valid = df_valid.reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    train_dataset = dataset.BERTDataset(</span><br><span class="line">        review=df_train.review.values,</span><br><span class="line">        target=df_train.sentiment.values</span><br><span class="line">    )</span><br><span class="line">    train_data_loader = torch.utils.data.DataLoader(</span><br><span class="line">        train_dataset,</span><br><span class="line">        batch_size=config.TRAIN_BATCH_SIZE,</span><br><span class="line">        num_workers=<span class="number">4</span></span><br><span class="line">    )</span><br><span class="line">    valid_dataset = dataset.BERTDataset(</span><br><span class="line">        review=df_valid.review.values,</span><br><span class="line">        target=df_valid.sentiment.values</span><br><span class="line">    )</span><br><span class="line">    valid_data_loader = torch.utils.data.DataLoader(</span><br><span class="line">        valid_dataset,</span><br><span class="line">        batch_size=config.VALID_BATCH_SIZE,</span><br><span class="line">        num_workers=<span class="number">1</span></span><br><span class="line">    )</span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">    model = BERTBaseUncased()</span><br><span class="line">    model.to(device)</span><br><span class="line">    param_optimizer = <span class="built_in">list</span>(model.named_parameters())</span><br><span class="line">    no_decay = [<span class="string">&quot;bias&quot;</span>, <span class="string">&quot;LayerNorm.bias&quot;</span>, <span class="string">&quot;LayerNorm.weight&quot;</span>]</span><br><span class="line">    optimizer_parameters = [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;params&quot;</span>: [</span><br><span class="line">                p <span class="keyword">for</span> n, p <span class="keyword">in</span> param_optimizer <span class="keyword">if</span></span><br><span class="line">                <span class="keyword">not</span> <span class="built_in">any</span>(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)</span><br><span class="line">            ],</span><br><span class="line">            <span class="string">&quot;weight_decay&quot;</span>: <span class="number">0.001</span>,</span><br><span class="line">        &#125;，</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&quot;params&quot;</span>: [</span><br><span class="line">                p <span class="keyword">for</span> n, p <span class="keyword">in</span> param_optimizer <span class="keyword">if</span></span><br><span class="line">                <span class="built_in">any</span>(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)</span><br><span class="line">            ],</span><br><span class="line">            <span class="string">&quot;weight_decay&quot;</span>: <span class="number">0.0</span>,</span><br><span class="line">        &#125;]</span><br><span class="line">    num_train_steps = <span class="built_in">int</span>(</span><br><span class="line">        <span class="built_in">len</span>(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS</span><br><span class="line">    )</span><br><span class="line">    optimizer = AdamW(optimizer_parameters, lr=<span class="number">3e-5</span>)</span><br><span class="line">    scheduler = get_linear_schedule_with_warmup(</span><br><span class="line">        optimizer,</span><br><span class="line">        num_warmup_steps=<span class="number">0</span>,</span><br><span class="line">        num_training_steps=num_train_steps</span><br><span class="line">    )</span><br><span class="line">    model = nn.DataParallel(model)</span><br><span class="line">    best_accuracy = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(config.EPOCHS):</span><br><span class="line">        engine.train_fn(</span><br><span class="line">            train_data_loader, model, optimizer, device, scheduler</span><br><span class="line">        )</span><br><span class="line">        outputs, targets = engine.eval_fn(</span><br><span class="line">            valid_data_loader, model, device</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        outputs = np.array(outputs) &gt;= <span class="number">0.5</span></span><br><span class="line">        accuracy = metrics.accuracy_score(targets, outputs)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Accuracy Score = <span class="subst">&#123;accuracy&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> accuracy &gt; best_accuracy:</span><br><span class="line">            torch.save(model.state_dict(), config.MODEL_PATH)</span><br><span class="line">            best_accuracy = accuracy</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    train()</span><br></pre></td></tr></table></figure><p>乍一看可能看起来很多，但一旦您了解了各个组件，就不再那么简单了。 您只需更改几行代码即可轻松将其更改为您想要使用的任何其他 Transformer 模型。</p><p>该模型的准确率为 93%！ 哇！ 这比任何其他模型都要好得多。 但是这值得吗？</p><p>我们使用 LSTM 能够实现 90% 的目标，而且它们更简单、更容易训练并且推理速度更快。 通过使用不同的数据处理或调整层、节点、dropout、学习率、更改优化器等参数，我们可以将该模型改进一个百分点。然后我们将从 BERT 中获得约 2% 的收益。 另一方面，BERT 的训练时间要长得多，参数很多，而且推理速度也很慢。 最后，您应该审视自己的业务并做出明智的选择。 不要仅仅因为 BERT“酷”而选择它。</p><p>必须注意的是，我们在这里讨论的唯一任务是分类，但将其更改为回归、多标签或多类只需要更改几行代码。 例如，多类分类设置中的同一问题将有多个输出和交叉熵损失。 其他一切都应该保持不变。 自然语言处理非常庞大，我们只讨论了其中的一小部分。 显然，这是一个很大的比例，因为大多数工业模型都是分类或回归模型。 如果我开始详细写所有内容，我最终可能会写几百页，这就是为什么我决定将所有内容包含在一本单独的书中：接近（几乎）任何 NLP 问题！</p>]]></content>
      
      
      <categories>
          
          <category> AAAMLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无监督和有监督学习</title>
      <link href="/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%92%8C%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
      <url>/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%92%8C%E6%9C%89%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1 id="无监督和有监督学习"><a href="#无监督和有监督学习" class="headerlink" title="无监督和有监督学习"></a>无监督和有监督学习</h1><p>在处理机器学习问题时，通常有两类数据（和机器学习模型）：</p><ul><li>监督数据：总是有一个或多个与之相关的目标</li><li>无监督数据：没有任何目标变量。</li></ul><p>有监督问题比无监督问题更容易解决。我们需要预测一个值的问题被称为有监督问题。例如，如果问题是根据历史房价预测房价，那么医院、学校或超市的存在，与最近公共交通的距离等特征就是一个有监督的问题。同样，当我们得到猫和狗的图像时，我们事先知道哪些是猫，哪些是狗，如果任务是创建一个模型来预测所提供的图像是猫还是狗，那么这个问题就被认为是有监督的问题。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page6_image.png" alt=""></p><p align="center"><b>图 1：有监督学习数据</b> </p><p>如图 1 所示，数据的每一行都与一个目标或标签相关联。列是不同的特征，行代表不同的数据点，通常称为样本。示例中的十个样本有十个特征和一个目标变量，目标变量可以是数字或类别。如果目标变量是分类变量，问题就变成了分类问题。如果目标变量是实数，问题就被定义为回归问题。因此，有监督问题可分为两个子类：</p><ul><li>分类：预测类别，如猫或狗</li><li>回归：预测值，如房价</li></ul><p>必须注意的是，有时我们可能会在分类设置中使用回归，这取决于用于评估的指标。不过，我们稍后会讨论这个问题。</p><p>另一种机器学习问题是无监督类型。<strong>无监督</strong>数据集没有与之相关的目标，一般来说，与有监督问题相比，处理无监督数据集更具挑战性。</p><p>假设你在一家处理信用卡交易的金融公司工作。每秒钟都有大量数据涌入。唯一的问题是，很难找到一个人来将每笔交易标记为有效交易、真实交易或欺诈交易。当我们没有任何关于交易是欺诈还是真实的信息时，问题就变成了无监督问题。要解决这类问题，我们必须考虑可以将数据分为多少个<strong>聚类</strong>。聚类是解决此类问题的方法之一，但必须注意的是，还有其他几种方法可以应用于无监督问题。对于欺诈检测问题，我们可以说数据可以分为两类（欺诈或真实）。</p><p>当我们知道聚类的数量后，就可以使用聚类算法来解决无监督问题。在图 2 中，假设数据分为两类，深色代表欺诈，浅色代表真实交易。然而，在使用聚类方法之前，我们并不知道这些类别。应用聚类算法后，我们应该能够区分这两个假定目标。 为了理解无监督问题，我们还可以使用许多分解技术，如<strong>主成分分析（PCA）、t-分布随机邻域嵌入（t-SNE）</strong>等。</p><p>有监督的问题更容易解决，因为它们很容易评估。我们将在接下来的章节中详细介绍评估技术。然而，对无监督算法的结果进行评估具有挑战性，需要大量的人为干预或启发式方法。在本书中，我们将主要关注有监督数据和模型，但这并不意味着我们会忽略无监督数据问题。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page8_image.png" alt=""></p><p align="center"><b>图 2：无监督学习数据集</b> </p><p>大多数情况下，当人们开始学习数据科学或机器学习时，都会从非常著名的数据集开始，例如泰坦尼克数据集或鸢尾花数据集，这些都是有监督的问题。在泰坦尼克号数据集中，你必须根据船票等级、性别、年龄等因素预测泰坦尼克号上乘客的存活率。同样，在鸢尾花数据集中，您必须根据萼片宽度、花瓣长度、萼片长度和花瓣宽度等因素预测花的种类。</p><p>无监督数据集可能包括用于客户细分的数据集。 例如，您拥有访问您的电子商务网站的客户数据，或者访问商店或商场的客户数据，而您希望将它们细分或聚类为不同的类别。无监督数据集的另一个例子可能包括信用卡欺诈检测或对几张图片进行聚类等。</p><p>大多数情况下，还可以将有监督数据集转换为无监督数据集，以查看它们在绘制时的效果。</p><p>例如，让我们来看看图 3 中的数据集。图 3 显示的是 MNIST 数据集，这是一个非常流行的手写数字数据集，它是一个有监督的问题，在这个问题中，你会得到数字图像和与之相关的正确标签。你必须建立一个模型，在只提供图像的情况下识别出哪个数字是它。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page9_image.png" alt=""></p><p align="center"><b>图 3：MNIST数据集</b> </p><p>如果我们对这个数据集进行 t 分布随机邻域嵌入（t-SNE）分解，我们可以看到，只需在图像像素上降维至 2 个维度，就能在一定程度上分离图像。如图 4 所示。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page9_image_1.png" alt=""></p><p align="center"><b>图 4：MNIST 数据集的 t-SNE 可视化。使用了 3000 幅图像。</b> </p><p>让我们来看看是如何实现的。首先是导入所有需要的库。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> manifold</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><p>我们使用 matplotlib 和 seaborn 进行绘图，使用 numpy 处理数值数组，使用 pandas 从数值数组创建数据帧，使用 scikit-learn (sklearn) 获取数据并执行 t-SNE。</p><p>导入后，我们需要下载数据并单独读取，或者使用 sklearn 的内置函数来提供 MNIST 数据集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data = datasets.fetch_openml(<span class="string">&#x27;mnist_784&#x27;</span>, version=<span class="number">1</span>, return_X_y=<span class="literal">True</span>)</span><br><span class="line">pixel_values, targets = data</span><br><span class="line">targets = targets.astype(<span class="built_in">int</span>)</span><br></pre></td></tr></table></figure><p>在这部分代码中，我们使用 sklearn 数据集获取了数据，并获得了一个像素值数组和另一个目标数组。由于目标是字符串类型，我们将其转换为整数。</p><p>pixel_values 是一个形状为 70000x784 的二维数组。 共有 70000 张不同的图像，每张图像大小为 28x28 像素。平铺 28x28 后得到 784 个数据点。</p><p>我们可以将该数据集中的样本重塑为原来的形状，然后使用 matplotlib 绘制成图表，从而将其可视化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">single_image = pixel_values[<span class="number">1</span>, :].reshape(<span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">plt.imshow(single_image, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br></pre></td></tr></table></figure><p>这段代码将绘制如下图像：</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page11_image.png" alt=""></p><p align="center"><b>图 5：绘制MNIST数据集单张图片</b> </p><p>最重要的一步是在我们获取数据之后。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tsne = manifold.TSNE(n_components=<span class="number">2</span>, random_state=<span class="number">42</span>)</span><br><span class="line">transformed_data = tsne.fit_transform(pixel_values[:<span class="number">3000</span>, :])</span><br></pre></td></tr></table></figure><p>这一步创建了数据的 t-SNE 变换。我们只使用 2 个维度，因为在二维环境中可以很好地将它们可视化。在本例中，转换后的数据是一个 3000x2 形状的数组（3000 行 2 列）。在数组上调用 pd.DataFrame 可以将这样的数据转换为 pandas 数据帧。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tsne_df = pd.DataFrame(np.column_stack((transformed_data, targets[:<span class="number">3000</span>])),</span><br><span class="line">                       columns=[<span class="string">&quot;x&quot;</span>, <span class="string">&quot;y&quot;</span>, <span class="string">&quot;targets&quot;</span>])</span><br><span class="line">tsne_df.loc[:, <span class="string">&quot;targets&quot;</span>] = tsne_df.targets.astype(<span class="built_in">int</span>)</span><br></pre></td></tr></table></figure><p>在这里，我们从一个 numpy 数组创建一个 pandas 数据帧。x 和 y 是 t-SNE 分解的两个维度，target 是实际数字。这样我们就得到了如图 6 所示的数据帧。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page12_image.png" alt=""></p><p align="center"><b>图 6：t-SNE后数据前10行</b> </p><p>最后，我们可以使用 seaborn 和 matplotlib 绘制它。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grid = sns.FacetGrid(tsne_df, hue=<span class="string">&quot;targets&quot;</span>, size=<span class="number">8</span>)</span><br><span class="line">grid.<span class="built_in">map</span>(plt.scatter, <span class="string">&quot;x&quot;</span>, <span class="string">&quot;y&quot;</span>).add_legend()</span><br></pre></td></tr></table></figure><p>这是无监督数据集可视化的一种方法。我们还可以在同一数据集上进行 k-means 聚类，看看它在无监督环境下的表现如何。一个经常出现的问题是，如何在 k-means 聚类中找到最佳的簇数。这个问题没有正确答案。你必须通过交叉验证来找到最佳簇数。本书稍后将讨论交叉验证。请注意，上述代码是在 jupyter 笔记本中运行的。</p><p>在本书中，我们将使用 jupyter 做一些简单的事情，比如上面的例子和 绘图。对于本书中的大部分内容，我们将使用 python 脚本。您可以使用其他 IDE 因为结果都是一样的。</p><p>MNIST 是一个有监督的分类问题，我们把它转换成一个无监督的问题，只是为了检查它是否能带来任何好的结果。如果我们使用分类算法，效果会更好。让我们在接下来的章节中一探究竟。</p>]]></content>
      
      
      <categories>
          
          <category> AAAMLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>组合和堆叠方法</title>
      <link href="/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E7%BB%84%E5%90%88%E5%92%8C%E5%A0%86%E5%8F%A0%E6%96%B9%E6%B3%95/"/>
      <url>/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E7%BB%84%E5%90%88%E5%92%8C%E5%A0%86%E5%8F%A0%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="组合和堆叠方法"><a href="#组合和堆叠方法" class="headerlink" title="组合和堆叠方法"></a>组合和堆叠方法</h1><p>听到上面两个词，我们首先想到的就是在线（online）/离线（offline）机器学习竞赛。几年前是这样，但现在随着计算能力的进步和虚拟实例的廉价，人们甚至开始在行业中使用组合模型（ensemble models）。例如，部署多个神经网络并实时为它们提供服务非常容易，响应时间小于 500 毫秒。有时，一个庞大的神经网络或大型模型也可以被其他几个模型取代，这些模型体积小，性能与大型模型相似，速度却快一倍。如果是这种情况，你会选择哪个（些）模型呢？我个人更倾向于选择多个小机型，它们速度更快，性能与大机型和慢机型相同。请记住，较小的型号也更容易和更快地进行调整。</p><p>组合（ensembling）不过是不同模型的组合。模型可以通过预测/概率进行组合。组合模型最简单的方法就是求平均值。</p><script type="math/tex; mode=display">Ensemble Probabilities = (M1\_proba + M2\_proba + ... + Mn\_Proba)/n</script><p>这是最简单也是最有效的组合模型的方法。在简单平均法中，所有模型的权重都是相等的。无论采用哪种组合方法，您都应该牢记一点，那就是您应该始终将不同模型的预测/概率组合在一起。简单地说，组合相关性不高的模型比组合相关性很高的模型效果更好。</p><p>如果没有概率，也可以组合预测。最简单的方法就是投票。假设我们正在进行多类分类，有三个类别： 0、1 和 2。</p><p>[0, 0, 1] : 最高票数： 0</p><p>[0, 1, 2] : 最高票级： 无（随机选择一个）</p><p>[2, 2, 2] : 最高票数： 2</p><p>以下简单函数可以完成这些简单操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mean_predictions</span>(<span class="params">probas</span>):</span><br><span class="line">    <span class="comment"># 计算第二个维度（列）每行平均值</span></span><br><span class="line">    <span class="keyword">return</span> np.mean(probas, axis=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">max_voting</span>(<span class="params">preds</span>):</span><br><span class="line">    <span class="comment"># 沿着第二个维度（列）查找每行中最大值的索引</span></span><br><span class="line">idxs = np.argmax(preds, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 根据索引取出每行中最大值对应的元素</span></span><br><span class="line"><span class="keyword">return</span> np.take_along_axis(preds, idxs[:, <span class="literal">None</span>], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>请注意，probas 的每一列都只有一个概率（即二元分类，通常为类别 1）。因此，每一列都是一个新模型。同样，对于 preds，每一列都是来自不同模型的预测值。这两个函数都假设了一个 2 维 numpy 数组。您可以根据自己的需求对其进行修改。例如，您可能有一个 2 维数组，其中包含每个模型的概率。在这种情况下，函数会有一些变化。 另一种组合多个模型的方法是通过它们的<strong>概率排序</strong>。当相关指标是曲线下面积（AUC）时，这种组合方式非常有效，因为 AUC 就是对样本进行排序。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">rank_mean</span>(<span class="params">probas</span>):</span><br><span class="line">    <span class="comment"># 创建空列表ranked存储每个类别概率值排名</span></span><br><span class="line">    ranked = []</span><br><span class="line">    <span class="comment"># 遍历概率值每一列（每个类别的概率值）</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(probas.shape[<span class="number">1</span>]):</span><br><span class="line">        <span class="comment"># 当前列概率值排名，rank_data是排名结果</span></span><br><span class="line">        rank_data = stats.rankdata(probas[:, i])</span><br><span class="line">        <span class="comment"># 将当前列排名结果添加到ranked列表中</span></span><br><span class="line">        ranked.append(rank_data)</span><br><span class="line">        <span class="comment"># 将ranked列表中排名结果按列堆叠，形成二维数组</span></span><br><span class="line">        ranked = np.column_stack(ranked)</span><br><span class="line">    <span class="comment"># 沿着第二个维度（列）计算样本排名平均值</span></span><br><span class="line">    <span class="keyword">return</span> np.mean(ranked, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>请注意，在 scipy 的 rankdata 中，等级从 1 开始。</p><p>为什么这类集合有效？让我们看看图 1。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page273_image.png" alt=""></p><p align="center"><b>图 1：三人猜大象的身高</b> </p><p>图 1 显示，如果有三个人在猜大象的高度，那么原始高度将非常接近三个人猜测的平均值。我们假设这些人都能猜到非常接近大象原来的高度。接近估计值意味着误差，但如果我们将三个预测值平均，就能将误差降到最低。这就是多个模型平均的主要思想。</p><script type="math/tex; mode=display">Final\ Probabilities = w_1 \times M1\_proba + w_2 \times M2\_proba + \cdots + w_n \times Mn\_proba</script><p>其中$(w_1 + w_2 + w_3 + \cdots + w_n)=1.0$</p><p>例如，如果你有一个 AUC 非常高的随机森林模型和一个 AUC 稍低的逻辑回归模型，你可以把它们结合起来，随机森林模型占 70%，逻辑回归模型占 30%。那么，我是如何得出这些数字的呢？让我们再添加一个模型，假设现在我们也有一个 xgboost 模型，它的 AUC 比随机森林高。现在，我将把它们结合起来，xgboost：随机森林：逻辑回归的比例为 3:2:1。很简单吧？得出这些数字易如反掌。让我们看看是如何做到的。</p><p>假定我们有三只猴子，三只旋钮的数值在 0 和 1 之间。这些猴子转动旋钮，我们计算它们每转到一个数值时的 AUC 分数。最终，猴子们会找到一个能给出最佳 AUC 的组合。没错，这就是随机搜索！在进行这类搜索之前，你必须记住两个最重要的组合规则。</p><p>组合的第一条规则是，在开始合奏之前，一定要先创建折叠。</p><p>组合的第二条规则是，在开始合奏之前，一定要先创建折叠。</p><p>是的。这是最重要的两条规则。第一步是创建折叠。为了简单起见，假设我们将数据分为两部分：折叠 1 和折叠 2。请注意，这样做只是为了简化解释。在实际应用中，您应该创建更多的折叠。</p><p>现在，我们在折叠 1 上训练随机森林模型、逻辑回归模型和 xgboost 模型，并在折叠 2 上进行预测。之后，我们在折叠 2 上从头开始训练模型，并在折叠 1 上进行预测。这样，我们就为所有训练数据创建了预测结果。现在，为了合并这些模型，我们将折叠 1 和折叠 1 的所有预测数据合并在一起，然后创建一个优化函数，试图找到最佳权重，以便针对折叠 2 的目标最小化误差或最大化 AUC。因此，我们是用三个模型的预测概率在折叠 1 上训练一个优化模型，然后在折叠 2 上对其进行评估。让我们先来看看我们可以用来找到多个模型的最佳权重，以优化 AUC（或任何类型的预测指标组合）的类。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> fmin</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OptimizeAUC</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 初始化系数</span></span><br><span class="line">        self.coef_ = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_auc</span>(<span class="params">self, coef, X, y</span>):</span><br><span class="line">        <span class="comment"># 对输入数据乘以系数</span></span><br><span class="line">        x_coef = X * coef</span><br><span class="line">        <span class="comment"># 计算每个样本预测值</span></span><br><span class="line">        predictions = np.<span class="built_in">sum</span>(x_coef, axis=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 计算AUC分数</span></span><br><span class="line">        auc_score = metrics.roc_auc_score(y, predictions)</span><br><span class="line">        <span class="comment"># 返回负AUC以便最小化</span></span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1.0</span> * auc_score</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y</span>):</span><br><span class="line">        <span class="comment"># 创建带有部分参数的目标函数</span></span><br><span class="line">        loss_partial = partial(self._auc, X=X, y=y)</span><br><span class="line">        <span class="comment"># 初始化系数</span></span><br><span class="line">        initial_coef = np.random.dirichlet(np.ones(X.shape[<span class="number">1</span>]), size=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 使用fmin函数优化AUC目标函数，找到最优系数</span></span><br><span class="line">        self.coef_ = fmin(loss_partial, initial_coef, disp=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">predict</span>(<span class="params">self, X</span>):</span><br><span class="line">        <span class="comment"># 对输入数据乘以训练好的系数</span></span><br><span class="line">        x_coef = X * self.coef_</span><br><span class="line">        <span class="comment"># 计算每个样本预测值</span></span><br><span class="line">        predictions = np.<span class="built_in">sum</span>(x_coef, axis=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 返回预测结果</span></span><br><span class="line">        <span class="keyword">return</span> predictions</span><br></pre></td></tr></table></figure><p>让我们来看看如何使用它，并将其与简单平均法进行比较。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> ensemble</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成一个分类数据集</span></span><br><span class="line">X, y = make_classification(n_samples=<span class="number">10000</span>, n_features=<span class="number">25</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分数据集为两个交叉验证折叠</span></span><br><span class="line">xfold1, xfold2, yfold1, yfold2 = model_selection.train_test_split(X,</span><br><span class="line">                                                                  y,</span><br><span class="line">                                                                  test_size=<span class="number">0.5</span>,</span><br><span class="line">                                                                  stratify=y)</span><br><span class="line"><span class="comment"># 初始化三个不同的分类器</span></span><br><span class="line">logreg = linear_model.LogisticRegression()</span><br><span class="line">rf = ensemble.RandomForestClassifier()</span><br><span class="line">xgbc = xgb.XGBClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用第一个折叠数据集训练分类器</span></span><br><span class="line">logreg.fit(xfold1, yfold1)</span><br><span class="line">rf.fit(xfold1, yfold1)</span><br><span class="line">xgbc.fit(xfold1, yfold1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对第二个折叠数据集进行预测</span></span><br><span class="line">pred_logreg = logreg.predict_proba(xfold2)[:, <span class="number">1</span>]</span><br><span class="line">pred_rf = rf.predict_proba(xfold2)[:, <span class="number">1</span>]</span><br><span class="line">pred_xgbc = xgbc.predict_proba(xfold2)[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算平均预测结果</span></span><br><span class="line">avg_pred = (pred_logreg + pred_rf + pred_xgbc) / <span class="number">3</span></span><br><span class="line">fold2_preds = np.column_stack((pred_logreg, pred_rf, pred_xgbc, avg_pred))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算每个模型的AUC分数并打印</span></span><br><span class="line">aucs_fold2 = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(fold2_preds.shape[<span class="number">1</span>]):</span><br><span class="line">    auc = metrics.roc_auc_score(yfold2, fold2_preds[:, i])</span><br><span class="line">    aucs_fold2.append(auc)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Fold-2: LR AUC = <span class="subst">&#123;aucs_fold2[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Fold-2: RF AUC = <span class="subst">&#123;aucs_fold2[<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Fold-2: XGB AUC = <span class="subst">&#123;aucs_fold2[<span class="number">2</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Fold-2: Average Pred AUC = <span class="subst">&#123;aucs_fold2[<span class="number">3</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重新初始化分类器</span></span><br><span class="line">logreg = linear_model.LogisticRegression()</span><br><span class="line">rf = ensemble.RandomForestClassifier()</span><br><span class="line">xgbc = xgb.XGBClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用第二个折叠数据集训练分类器</span></span><br><span class="line">logreg.fit(xfold2, yfold2)</span><br><span class="line">rf.fit(xfold2, yfold2)</span><br><span class="line">xgbc.fit(xfold2, yfold2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对第一个折叠数据集进行预测</span></span><br><span class="line">pred_logreg = logreg.predict_proba(xfold1)[:, <span class="number">1</span>]</span><br><span class="line">pred_rf = rf.predict_proba(xfold1)[:, <span class="number">1</span>]</span><br><span class="line">pred_xgbc = xgbc.predict_proba(xfold1)[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算平均预测结果</span></span><br><span class="line">avg_pred = (pred_logreg + pred_rf + pred_xgbc) / <span class="number">3</span></span><br><span class="line">fold1_preds = np.column_stack((pred_logreg, pred_rf, pred_xgbc, avg_pred))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算每个模型的AUC分数并打印</span></span><br><span class="line">aucs_fold1 = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(fold1_preds.shape[<span class="number">1</span>]):</span><br><span class="line">    auc = metrics.roc_auc_score(yfold1, fold1_preds[:, i])</span><br><span class="line">    aucs_fold1.append(auc)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Fold-1: LR AUC = <span class="subst">&#123;aucs_fold1[<span class="number">0</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Fold-1: RF AUC = <span class="subst">&#123;aucs_fold1[<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Fold-1: XGB AUC = <span class="subst">&#123;aucs_fold1[<span class="number">2</span>]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Fold-1: Average prediction AUC = <span class="subst">&#123;aucs_fold1[<span class="number">3</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化AUC优化器</span></span><br><span class="line">opt = OptimizeAUC()</span><br><span class="line"><span class="comment"># 使用第一个折叠数据集的预测结果来训练优化器</span></span><br><span class="line">opt.fit(fold1_preds[:, :-<span class="number">1</span>], yfold1)</span><br><span class="line"><span class="comment"># 使用优化器对第二个折叠数据集的预测结果进行优化</span></span><br><span class="line">opt_preds_fold2 = opt.predict(fold2_preds[:, :-<span class="number">1</span>])</span><br><span class="line">auc = metrics.roc_auc_score(yfold2, opt_preds_fold2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Optimized AUC, Fold 2 = <span class="subst">&#123;auc&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Coefficients = <span class="subst">&#123;opt.coef_&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化AUC优化器</span></span><br><span class="line">opt = OptimizeAUC()</span><br><span class="line"><span class="comment"># 使用第二个折叠数据集的预测结果来</span></span><br><span class="line">opt.fit(fold2_preds[:, :-<span class="number">1</span>], yfold2)</span><br><span class="line"><span class="comment"># 使用优化器对第一个折叠数据集的预测结果进行优化</span></span><br><span class="line">opt_preds_fold1 = opt.predict(fold1_preds[:, :-<span class="number">1</span>])</span><br><span class="line">auc = metrics.roc_auc_score(yfold1, opt_preds_fold1)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Optimized AUC, Fold 1 = <span class="subst">&#123;auc&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Coefficients = <span class="subst">&#123;opt.coef_&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>让我们看一下输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">❯ python auc_opt.py</span><br><span class="line">Fold-<span class="number">2</span>: LR AUC = <span class="number">0.9145446769443348</span></span><br><span class="line">Fold-<span class="number">2</span>: RF AUC = <span class="number">0.9269918948683287</span></span><br><span class="line">Fold-<span class="number">2</span>: XGB AUC = <span class="number">0.9302436595508696</span></span><br><span class="line">Fold-<span class="number">2</span>: Average Pred AUC = <span class="number">0.927701495890154</span></span><br><span class="line">Fold-<span class="number">1</span>: LR AUC = <span class="number">0.9050872233256017</span></span><br><span class="line">Fold-<span class="number">1</span>: RF AUC = <span class="number">0.9179382818311258</span></span><br><span class="line">Fold-<span class="number">1</span>: XGB AUC = <span class="number">0.9195837242005629</span></span><br><span class="line">Fold-<span class="number">1</span>: Average prediction AUC = <span class="number">0.9189669233123695</span></span><br><span class="line">Optimization terminated successfully.</span><br><span class="line">Current function value: -<span class="number">0.920643</span></span><br><span class="line">Iterations: <span class="number">50</span></span><br><span class="line">Function evaluations: <span class="number">109</span></span><br><span class="line">Optimized AUC, Fold <span class="number">2</span> = <span class="number">0.9305386199756128</span></span><br><span class="line">Coefficients = [-<span class="number">0.00188194</span> <span class="number">0.19328336</span> <span class="number">0.35891836</span>]</span><br><span class="line">Optimization terminated successfully.</span><br><span class="line">Current function value: -<span class="number">0.931232</span></span><br><span class="line">Iterations: <span class="number">56</span></span><br><span class="line">Function evaluations: <span class="number">113</span></span><br><span class="line">Optimized AUC, Fold <span class="number">1</span> = <span class="number">0.9192523637234037</span></span><br><span class="line">Coefficients = [-<span class="number">0.15655124</span> <span class="number">0.22393151</span> <span class="number">0.58711366</span>]</span><br></pre></td></tr></table></figure><p>我们看到，平均值更好，但使用优化器找到阈值更好！有时，平均值是最好的选择。正如你所看到的，系数加起来并没有达到 1.0，但这没关系，因为我们要处理的是 AUC，而 AUC 只关心等级。</p><p>即使随机森林也是一个集合模型。随机森林只是许多简单决策树的组合。随机森林属于集合模型的一种，也就是俗称的<strong>“bagging”</strong>。在袋集模型中，我们创建小数据子集并训练多个简单模型。最终结果由所有这些小模型的预测结果（如平均值）组合而成。</p><p>我们使用的 xgboost 模型也是一个集合模型。所有梯度提升模型都是集合模型，统称为<strong>提升模型（boosting models）</strong>。提升模型的工作原理与装袋模型类似，不同之处在于提升模型中的连续模型是根据误差残差训练的，并倾向于最小化前面模型的误差。这样，提升模型就能完美地学习数据，因此容易出现过拟合。</p><p>到目前为止，我们看到的代码片段只考虑了一列。但情况并非总是如此，很多时候您需要处理多列预测。例如，您可能会遇到从多个类别中预测一个类别的问题，即多类分类问题。对于多类分类问题，你可以很容易地选择投票方法。但投票法并不总是最佳方法。如果要组合概率，就会有一个二维数组，而不是像我们之前优化 AUC 时的向量。如果有多个类别，可以尝试优化对数损失（或其他与业务相关的指标）。 要进行组合，可以在拟合函数 (X) 中使用 numpy 数组列表而不是 numpy 数组，随后还需要更改优化器和预测函数。我就把它作为一个练习留给大家吧。</p><p>现在，我们可以进入下一个有趣的话题，这个话题相当流行，被称为<strong>堆叠</strong>。图 2 展示了如何堆叠模型。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page280_image.png" alt=""></p><p align="center"><b>图2 : Stacking</b> </p><p>堆叠不像制造火箭。它简单明了。如果您进行了正确的交叉验证，并在整个建模过程中保持折叠不变，那么就不会出现任何过度贴合的情况。</p><p>让我用简单的要点向你描述一下这个想法。</p><ul><li>将训练数据分成若干折叠。</li><li>训练一堆模型： M1、M2…..Mn。</li><li>创建完整的训练预测（使用非折叠训练），并使用所有这些模型进行测试预测。</li><li>直到这里是第 1 层 (L1)。</li><li>将这些模型的折叠预测作为另一个模型的特征。这就是二级模型（L2）。</li><li>使用与之前相同的折叠来训练这个 L2 模型。</li><li>现在，在训练集和测试集上创建 OOF（折叠外）预测。</li><li>现在您就有了训练数据的 L2 预测和最终测试集预测。</li></ul><p>您可以不断重复 L1 部分，也可以创建任意多的层次。</p><p>有时，你还会遇到一个叫混合的术语<strong>blending</strong>。如果你遇到了，不用太担心。它只不过是用一个保留组来堆叠，而不是多重折叠。必须指出的是，我在本章中所描述的内容可以应用于任何类型的问题：分类、回归、多标签分类等。</p>]]></content>
      
      
      <categories>
          
          <category> AAAMLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>AAAMLP前言</title>
      <link href="/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/index/"/>
      <url>/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/index/</url>
      
        <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>Abhishek Thakur，很多 kaggler 对他都非常熟悉，2017 年，他在 Linkedin 发表了一篇名为<strong>Approaching (Almost) Any Machine Learning Problem</strong>的文章，介绍他建立的一个自动的机器学习框架，几乎可以解决任何机器学习问题，这篇文章曾火遍 Kaggle。</p><p>Abhishek 在 Kaggle 上的成就：</p><ul><li>Competitions Grandmaster（17 枚金牌，世界排名第 3）</li><li>Kernels Expert （Kagglers 排名前 1％）</li><li>Discussion Grandmaster（65 枚金牌，世界排名第 2）</li></ul><p>目前，Abhishek 在挪威 boost 公司担任首席数据科学家的职位，这是一家专门从事会话人工智能的软件公司。</p><p>本文对<strong>Approaching (Almost) Any Machine Learning Problem</strong>进行了<strong>中文翻译</strong>，由于本人水平有限，且未使用机器翻译，可能有部分言语不通顺或本土化程度不足，也请大家在阅读过程中多提供宝贵意见。另附上书籍原<a href="https://github.com/abhishekkrthakur/approachingalmost">项目地址</a></p><p>本项目<strong>支持在线阅读</strong>，方便您随时随地进行查阅。</p><p>因为有几章内容太过基础，所以未进行翻译，详细情况请参照书籍目录：</p><ul><li>准备环境（未翻译）</li><li>无监督和有监督学习（未翻译）</li><li><strong>交叉检验（已翻译）</strong></li><li><strong>评估指标（已翻译）</strong> -</li><li><strong>组织机器学习（已翻译）</strong></li><li><strong>处理分类变量（已翻译）</strong></li><li><strong>特征工程（已翻译）</strong></li><li><strong>特征选择（已翻译）</strong></li><li><strong>超参数优化（已翻译）</strong></li><li>图像分类和分割方法（未翻译）</li><li>文本分类或回归方法（未翻译）</li><li>组合和堆叠方法（未翻译）</li><li>可重复代码和模型方法（未翻译）</li></ul><p>我将会把完整的翻译版 <code>Markdown</code> 文件上传到 GitHub，以供大家免费下载和阅读。为了最佳的阅读体验，推荐使用 PDF 格式或是在线阅读进行查看</p><p>若您在阅读过程中发现任何错误或不准确之处，非常欢迎通过提交 Issue 或 Pull Request 来协助我进行修正。</p><p>随着时间推移，我可能会<strong>继续翻译尚未完成的章节</strong>。如果您觉得这个项目对您有帮助，请不吝给予 Star 或者进行关注。</p>]]></content>
      
      
      <categories>
          
          <category> AAAMLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>交叉检验</title>
      <link href="/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E4%BA%A4%E5%8F%89%E6%A3%80%E9%AA%8C/"/>
      <url>/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E4%BA%A4%E5%8F%89%E6%A3%80%E9%AA%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="交叉检验"><a href="#交叉检验" class="headerlink" title="交叉检验"></a>交叉检验</h1><blockquote><p>博客就像与人进行长时间的对话一样，因此你所喜欢谈论的事情与你的激情密切相关是有道理的。</p></blockquote><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><ul><li>承诺声明</li><li>即将到来的内容的预览</li></ul><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ul><li>简单的定义</li><li>示例</li><li>过渡到下一节</li></ul><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><ul><li>每个步骤的详细说明</li></ul><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><ul><li>提醒指南的有用性</li><li>重申你的话题的重要性</li><li>呼吁行动</li></ul><h1 id="清单"><a href="#清单" class="headerlink" title="清单"></a>清单</h1><p>灵感 ⛅</p><ul><li>[ ] 阅读启发我的文章和观看视频</li><li>[ ] 用子弹点列出我想写的主题</li><li>[ ] 重新排列这些子弹点以形成思路<pre><code>草稿 ✏️</code></pre></li><li>[ ] 将这些子弹点扩展成句子/文本</li><li>[ ] 审阅文档<pre><code>准备发布 🌐</code></pre></li><li>[ ] 拟定 5 个标题并选择一个</li><li>[ ] 校对全文的错别字</li><li>[ ] 预览文本</li><li>[ ] 发布或安排帖子</li><li>[ ] 在社交媒体上推广</li></ul><h1 id="交叉检验-1"><a href="#交叉检验-1" class="headerlink" title="交叉检验"></a>交叉检验</h1><p>在上一章中，我们没有建立任何模型。原因很简单，在创建任何一种机器学习模型之前，我们必须知道什么是交叉检验，以及如何根据数据集选择最佳交叉检验数据集。</p><p>那么，什么是<strong>交叉检验</strong>，我们为什么要关注它？</p><h1 id="交叉检验-2"><a href="#交叉检验-2" class="headerlink" title="交叉检验"></a>交叉检验</h1><blockquote><p>博客就像与人进行长时间的对话一样，因此你所喜欢谈论的事情与你的激情密切相关是有道理的。</p></blockquote><h2 id="引言-1"><a href="#引言-1" class="headerlink" title="引言"></a>引言</h2><ul><li>承诺声明</li><li>即将到来的内容的预览</li></ul><h2 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h2><ul><li>简单的定义</li><li>示例</li><li>过渡到下一节</li></ul><h2 id="步骤-1"><a href="#步骤-1" class="headerlink" title="步骤"></a>步骤</h2><ul><li>每个步骤的详细说明</li></ul><h1 id="结论-1"><a href="#结论-1" class="headerlink" title="结论"></a>结论</h1><ul><li>提醒指南的有用性</li><li>重申你的话题的重要性</li><li>呼吁行动</li></ul><h1 id="清单-1"><a href="#清单-1" class="headerlink" title="清单"></a>清单</h1><p>灵感 ⛅</p><ul><li>[ ] 阅读启发我的文章和观看视频</li><li>[ ] 用子弹点列出我想写的主题</li><li>[ ] 重新排列这些子弹点以形成思路<pre><code>草稿 ✏️</code></pre></li><li>[ ] 将这些子弹点扩展成句子/文本</li><li>[ ] 审阅文档<pre><code>准备发布 🌐</code></pre></li><li>[ ] 拟定 5 个标题并选择一个</li><li>[ ] 校对全文的错别字</li><li>[ ] 预览文本</li><li>[ ] 发布或安排帖子</li><li>[ ] 在社交媒体上推广</li></ul><p>关于什么是交叉检验，# 交叉检验</p><blockquote><p>博客就像与人进行长时间的对话一样，因此你所喜欢谈论的事情与你的激情密切相关是有道理的。</p></blockquote><h2 id="引言-2"><a href="#引言-2" class="headerlink" title="引言"></a>引言</h2><ul><li>承诺声明</li><li>即将到来的内容的预览</li></ul><h2 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h2><ul><li>简单的定义</li><li>示例</li><li>过渡到下一节</li></ul><h2 id="步骤-2"><a href="#步骤-2" class="headerlink" title="步骤"></a>步骤</h2><ul><li>每个步骤的详细说明</li></ul><h1 id="结论-2"><a href="#结论-2" class="headerlink" title="结论"></a>结论</h1><ul><li>提醒指南的有用性</li><li>重申你的话题的重要性</li><li>呼吁行动</li></ul><h1 id="清单-2"><a href="#清单-2" class="headerlink" title="清单"></a>清单</h1><p>灵感 ⛅</p><ul><li>[ ] 阅读启发我的文章和观看视频</li><li>[ ] 用子弹点列出我想写的主题</li><li>[ ] 重新排列这些子弹点以形成思路<pre><code>草稿 ✏️</code></pre></li><li>[ ] 将这些子弹点扩展成句子/文本</li><li>[ ] 审阅文档<pre><code>准备发布 🌐</code></pre></li><li>[ ] 拟定 5 个标题并选择一个</li><li>[ ] 校对全文的错别字</li><li>[ ] 预览文本</li><li>[ ] 发布或安排帖子</li><li>[ ] 在社交媒体上推广<pre><code>我们可以找到多种定义。我的定义只有一句话：交叉检验是构建机器学习模型过程中的一个步骤，它可以帮助我们确保模型准确拟合数据，同时确保我们不会过拟合。但这又引出了另一个词：**过拟合**。</code></pre></li></ul><p>要解释过拟合，我认为最好先看一个数据集。有一个相当有名的红酒质量数据集（<strong>red wine quality dataset</strong>）。这个数据集有 11 个不同的特征，这些特征决定了红酒的质量。</p><p>这些属性包括：</p><ul><li>固定酸度（fixed acidity）</li><li>挥发性酸度（volatile acidity）</li><li>柠檬酸（citric acid）</li><li>残留糖（residual sugar）</li><li>氯化物（chlorides）</li><li>游离二氧化硫（free sulfur dioxide）</li><li>二氧化硫总量（total sulfur dioxide）</li><li>密度（density）</li><li>PH 值（pH）</li><li>硫酸盐（sulphates）</li><li>酒精（alcohol）</li></ul><p>根据这些不同特征，我们需要预测红葡萄酒的质量，质量值介于 0 到 10 之间。</p><p>让我们看看这些数据是怎样的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;winequality-red.csv&quot;</span>)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page14_image.png" alt=""></p><p align="center"><b>图 1:红葡萄酒质量数据集简单展示</b> </p><p>我们可以将这个问题视为分类问题，也可以视为回归问题。为了简单起见，我们选择分类。然而，这个数据集值包含 6 种质量值。因此，我们将所有质量值映射到 0 到 5 之间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一个映射字典，用于将质量值从 0 到 5 进行映射</span></span><br><span class="line">quality_mapping = &#123;</span><br><span class="line"> <span class="number">3</span>: <span class="number">0</span>,</span><br><span class="line"> <span class="number">4</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="number">5</span>: <span class="number">2</span>,</span><br><span class="line"> <span class="number">6</span>: <span class="number">3</span>,</span><br><span class="line"> <span class="number">7</span>: <span class="number">4</span>,</span><br><span class="line"> <span class="number">8</span>: <span class="number">5</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 你可以使用 pandas 的 map 函数以及任何字典，</span></span><br><span class="line"><span class="comment"># 来转换给定列中的值为字典中的值</span></span><br><span class="line">df.loc[:, <span class="string">&quot;quality&quot;</span>] = df.quality.<span class="built_in">map</span>(quality_mapping)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>当我们看大这些数据并将其视为一个分类问题时，我们脑海中会浮现出很多可以应用的算法，也许，我们可以使用神经网络。但是，如果我们从一开始就深入研究神经网络，那就有点牵强了。所以，让我们从简单的、我们也能可视化的东西开始：决策树。</p><p>在开始了解什么是过拟合之前，我们先将数据分为两部分。这个数据集有 1599 个样本。我们保留 1000 个样本用于训练，599 个样本作为一个单独的集合。</p><p>以下代码可以轻松完成划分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 frac=1 的 sample 方法来打乱 dataframe</span></span><br><span class="line"><span class="comment"># 由于打乱后索引会改变，所以我们重置索引</span></span><br><span class="line">df = df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选取前 1000 行作为训练数据</span></span><br><span class="line">df_train = df.head(<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选取最后的 599 行作为测试/验证数据</span></span><br><span class="line">df_test = df.tail(<span class="number">599</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>现在，我们将在训练集上使用 scikit-learn 训练一个决策树模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从 scikit-learn 导入需要的模块</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化一个决策树分类器，设置最大深度为 3</span></span><br><span class="line">clf = tree.DecisionTreeClassifier(max_depth=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择你想要训练模型的列</span></span><br><span class="line"><span class="comment"># 这些列作为模型的特征</span></span><br><span class="line">cols = [<span class="string">&#x27;fixed acidity&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;volatile acidity&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;citric acid&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;residual sugar&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;chlorides&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;free sulfur dioxide&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;total sulfur dioxide&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;density&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;pH&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;sulphates&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;alcohol&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用之前映射的质量以及提供的特征来训练模型</span></span><br><span class="line">clf.fit(df_train[cols], df_train.quality)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>请注意，我将决策树分类器的最大深度（max_depth）设为 3。该模型的所有其他参数均保持默认值。现在，我们在训练集和测试集上测试该模型的准确性：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在训练集上生成预测</span></span><br><span class="line">train_predictions = clf.predict(df_train[cols])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在测试集上生成预测</span></span><br><span class="line">test_predictions = clf.predict(df_test[cols])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算训练数据集上预测的准确度</span></span><br><span class="line">train_accuracy = metrics.accuracy_score(</span><br><span class="line"> df_train.quality, train_predictions</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算测试数据集上预测的准确度</span></span><br><span class="line">test_accuracy = metrics.accuracy_score(</span><br><span class="line"> df_test.quality, test_predictions</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>训练和测试的准确率分别为 58.9%和 54.25%。现在，我们将最大深度（max_depth）增加到 7，并重复上述过程。这样，训练准确率为 76.6%，测试准确率为 57.3%。在这里，我们使用准确率，主要是因为它是最直接的指标。对于这个问题来说，它可能不是最好的指标。我们可以根据最大深度（max_depth）的不同值来计算这些准确率，并绘制曲线图。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意：这段代码在 Jupyter 笔记本中编写</span></span><br><span class="line"><span class="comment"># 导入 scikit-learn 的 tree 和 metrics</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="comment"># 导入 matplotlib 和 seaborn</span></span><br><span class="line"><span class="comment"># 用于绘图</span></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置全局标签文本的大小</span></span><br><span class="line">matplotlib.rc(<span class="string">&#x27;xtick&#x27;</span>, labelsize=<span class="number">20</span>)</span><br><span class="line">matplotlib.rc(<span class="string">&#x27;ytick&#x27;</span>, labelsize=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 确保图表直接在笔记本内显示</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化用于存储训练和测试准确度的列表</span></span><br><span class="line"><span class="comment"># 我们从 50% 的准确度开始</span></span><br><span class="line">train_accuracies = [<span class="number">0.5</span>]</span><br><span class="line">test_accuracies = [<span class="number">0.5</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历几个不同的树深度值</span></span><br><span class="line"><span class="keyword">for</span> depth <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">25</span>):</span><br><span class="line">    <span class="comment"># 初始化模型</span></span><br><span class="line">    clf = tree.DecisionTreeClassifier(max_depth=depth)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 选择用于训练的列/特征</span></span><br><span class="line">    cols = [</span><br><span class="line">        <span class="string">&#x27;fixed acidity&#x27;</span>, <span class="string">&#x27;volatile acidity&#x27;</span>, <span class="string">&#x27;citric acid&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;residual sugar&#x27;</span>, <span class="string">&#x27;chlorides&#x27;</span>, <span class="string">&#x27;free sulfur dioxide&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;total sulfur dioxide&#x27;</span>, <span class="string">&#x27;density&#x27;</span>, <span class="string">&#x27;pH&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;sulphates&#x27;</span>, <span class="string">&#x27;alcohol&#x27;</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在给定特征上拟合模型</span></span><br><span class="line">    clf.fit(df_train[cols], df_train.quality)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建训练和测试预测</span></span><br><span class="line">    train_predictions = clf.predict(df_train[cols])</span><br><span class="line">    test_predictions = clf.predict(df_test[cols])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算训练和测试准确度</span></span><br><span class="line">    train_accuracy = metrics.accuracy_score(</span><br><span class="line">        df_train.quality, train_predictions</span><br><span class="line">    )</span><br><span class="line">    test_accuracy = metrics.accuracy_score(</span><br><span class="line">        df_test.quality, test_predictions</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加准确度到列表</span></span><br><span class="line">    train_accuracies.append(train_accuracy)</span><br><span class="line">    test_accuracies.append(test_accuracy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 matplotlib 和 seaborn 创建两个图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">sns.set_style(<span class="string">&quot;whitegrid&quot;</span>)</span><br><span class="line">plt.plot(train_accuracies, label=<span class="string">&quot;train accuracy&quot;</span>)</span><br><span class="line">plt.plot(test_accuracies, label=<span class="string">&quot;test accuracy&quot;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&quot;upper left&quot;</span>, prop=&#123;<span class="string">&#x27;size&#x27;</span>: <span class="number">15</span>&#125;)</span><br><span class="line">plt.xticks(<span class="built_in">range</span>(<span class="number">0</span>, <span class="number">26</span>, <span class="number">5</span>))</span><br><span class="line">plt.xlabel(<span class="string">&quot;max_depth&quot;</span>, size=<span class="number">20</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;accuracy&quot;</span>, size=<span class="number">20</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这将生成如图 2 所示的曲线图。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page19_image.png" alt=""></p><p align="center"><b>图 2：不同 max_depth 训练和测试准确率。</b> </p><p>我们可以看到，当最大深度（max_depth）的值为 14 时，测试数据的得分最高。随着我们不断增加这个参数的值，测试准确率会保持不变或变差，但训练准确率会不断提高。这说明，随着最大深度（max_depth）的增加，决策树模型对训练数据的学习效果越来越好，但测试数据的性能却丝毫没有提高。</p><p><strong>这就是所谓的过拟合</strong>。</p><p>模型在训练集上完全拟合，而在测试集上却表现不佳。这意味着模型可以很好地学习训练数据，但无法泛化到未见过的样本上。在上面的数据集中，我们可以建立一个最大深度（max_depth）非常高的模型，它在训练数据上会有出色的结果，但这种模型并不实用，因为它在真实世界的样本或实时数据上不会提供类似的结果。</p><p>有人可能会说，这种方法并没有过拟合，因为测试集的准确率基本保持不变。过拟合的另一个定义是，当我们不断提高训练损失时，测试损失也在增加。这种情况在神经网络中非常常见。</p><p>每当我们训练一个神经网络时，都必须在训练期间监控训练集和测试集的损失。如果我们有一个非常大的网络来处理一个非常小的数据集（即样本数非常少），我们就会观察到，随着我们不断训练，训练集和测试集的损失都会减少。但是，在某个时刻，测试损失会达到最小值，之后，即使训练损失进一步减少，测试损失也会开始增加。我们必须在验证损失达到最小值时停止训练。</p><p><strong>这是对过拟合最常见的解释</strong>。</p><p>奥卡姆剃刀用简单的话说，就是不要试图把可以用简单得多的方法解决的事情复杂化。换句话说，最简单的解决方案就是最具通用性的解决方案。一般来说，只要你的模型不符合奥卡姆剃刀原则，就很可能是过拟合。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page20_image.png" alt=""></p><p align="center"><b>图 3：过拟合的最一般定义</b> </p><p>现在我们可以回到交叉检验。</p><p>在解释过拟合时，我决定将数据分为两部分。我在其中一部分上训练模型，然后在另一部分上检查其性能。这也是交叉检验的一种，通常被称为 “暂留集”（<strong>hold-out set</strong>）。当我们拥有大量数据，而模型推理是一个耗时的过程时，我们就会使用这种（交叉）验证。</p><p>交叉检验有许多不同的方法，它是建立一个良好的机器学习模型的最关键步骤。<strong>选择正确的交叉检验</strong>取决于所处理的数据集，在一个数据集上适用的交叉检验也可能不适用于其他数据集。不过，有几种类型的交叉检验技术最为流行和广泛使用。</p><p>其中包括：</p><ul><li>k 折交叉检验</li><li>分层 k 折交叉检验</li><li>暂留交叉检验</li><li>留一交叉检验</li><li>分组 k 折交叉检验</li></ul><p>交叉检验是将训练数据分层几个部分，我们在其中一部分上训练模型，然后在其余部分上进行测试。请看图 4。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page21_image.png" alt=""></p><p align="center"><b>图 4：将数据集拆分为训练集和验证集</b> </p><p>图 4 和图 5 说明，当你得到一个数据集来构建机器学习模型时，你会把它们分成<strong>两个不同的集：训练集和验证集</strong>。很多人还会将其分成第三组，称之为测试集。不过，我们将只使用两个集。如你所见，我们将样本和与之相关的目标进行了划分。我们可以将数据分为 k 个互不关联的不同集合。这就是所谓的 <strong>k 折交叉检验</strong>。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page21_image_1.png" alt=""></p><p align="center"><b>图 5：K 折交叉检验</b> </p><p>我们可以使用 scikit-learn 中的 KFold 将任何数据分割成 k 个相等的部分。每个样本分配一个从 0 到 k-1 的值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入 pandas 和 scikit-learn 的 model_selection 模块</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 训练数据存储在名为 train.csv 的 CSV 文件中</span></span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;train.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 我们创建一个名为 kfold 的新列，并用 -1 填充</span></span><br><span class="line">    df[<span class="string">&quot;kfold&quot;</span>] = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 接下来的步骤是随机打乱数据的行</span></span><br><span class="line">    df = df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从 model_selection 模块初始化 kfold 类</span></span><br><span class="line">    kf = model_selection.KFold(n_splits=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 填充新的 kfold 列（enumerate的作用是返回一个迭代器）</span></span><br><span class="line">    <span class="keyword">for</span> fold, (trn_, val_) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kf.split(X=df)):</span><br><span class="line">        df.loc[val_, <span class="string">&#x27;kfold&#x27;</span>] = fold</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存带有 kfold 列的新 CSV 文件</span></span><br><span class="line">    df.to_csv(<span class="string">&quot;train_folds.csv&quot;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>几乎所有类型的数据集都可以使用此流程。例如，当数据图像时，您可以创建一个包含图像 ID、图像位置和图像标签的 CSV，然后使用上述流程。</p><p>另一种重要的交叉检验类型是<strong>分层 k 折交叉检验</strong>。如果你有一个偏斜的二元分类数据集，其中正样本占 90%，负样本只占 10%，那么你就不应该使用随机 k 折交叉。对这样的数据集使用简单的 k 折交叉检验可能会导致折叠样本全部为负样本。在这种情况下，我们更倾向于使用分层 k 折交叉检验。分层 k 折交叉检验可以保持每个折中标签的比例不变。因此，在每个折叠中，都会有相同的 90% 正样本和 10% 负样本。因此，无论您选择什么指标进行评估，都会在所有折叠中得到相似的结果。</p><p>修改创建 k 折交叉检验的代码以创建分层 k 折交叉检验也很容易。我们只需将 model_selection.KFold 更改为 model_selection.StratifiedKFold ，并在 kf.split(…) 函数中指定要分层的目标列。我们假设 CSV 数据集有一列名为 “target” ，并且是一个分类问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入 pandas 和 scikit-learn 的 model_selection 模块</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 训练数据保存在名为 train.csv 的 CSV 文件中</span></span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;train.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 添加一个新列 kfold，并用 -1 初始化</span></span><br><span class="line">    df[<span class="string">&quot;kfold&quot;</span>] = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 随机打乱数据行</span></span><br><span class="line">    df = df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取目标变量</span></span><br><span class="line">    y = df.target.values</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化 StratifiedKFold 类，设置折数（folds）为 5</span></span><br><span class="line">    kf = model_selection.StratifiedKFold(n_splits=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用 StratifiedKFold 对象的 split 方法来获取训练和验证索引</span></span><br><span class="line">    <span class="keyword">for</span> f, (t_, v_) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kf.split(X=df, y=y)):</span><br><span class="line">        df.loc[v_, <span class="string">&#x27;kfold&#x27;</span>] = f</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存包含 kfold 列的新 CSV 文件</span></span><br><span class="line">    df.to_csv(<span class="string">&quot;train_folds.csv&quot;</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>对于葡萄酒数据集，我们来看看标签的分布情况。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">b = sns.countplot(x=<span class="string">&#x27;quality&#x27;</span>, data=df)</span><br><span class="line">b.set_xlabel(<span class="string">&quot;quality&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">b.set_ylabel(<span class="string">&quot;count&quot;</span>, fontsize=<span class="number">20</span>)</span><br></pre></td></tr></table></figure><p>请注意，我们继续上面的代码。因此，我们已经转换了目标值。从图 6 中我们可以看出，质量偏差很大。有些类别有很多样本，有些则没有那么多。如果我们进行简单的 k 折交叉检验，那么每个折叠中的目标值分布都不会相同。因此，在这种情况下，我们选择分层 k 折交叉检验。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page24_image.png" alt=""></p><p align="center"><b>图 6：葡萄酒数据集中 "质量" 分布情况</b> </p><p>规则很简单，如果是标准分类问题，就盲目选择分层 k 折交叉检验。</p><p>但如果数据量很大，该怎么办呢？假设我们有 100 万个样本。5 倍交叉检验意味着在 800k 个样本上进行训练，在 200k 个样本上进行验证。根据我们选择的算法，对于这样规模的数据集来说，训练甚至验证都可能非常昂贵。在这种情况下，我们可以选择<strong>暂留交叉检验</strong>。</p><p>创建保持结果的过程与分层 k 折交叉检验相同。对于拥有 100 万个样本的数据集，我们可以创建 10 个折叠而不是 5 个，并保留其中一个折叠作为保留样本。这意味着，我们将有 10 万个样本被保留下来，我们将始终在这个样本集上计算损失、准确率和其他指标，并在 90 万个样本上进行训练。</p><p>在处理时间序列数据时，暂留交叉检验也非常常用。假设我们要解决的问题是预测一家商店 2020 年的销售额，而我们得到的是 2015-2019 年的所有数据。在这种情况下，你可以选择 2019 年的所有数据作为保留数据，然后在 2015 年至 2018 年的所有数据上训练你的模型。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page25_image.png" alt=""></p><p align="center"><b>图 7：时间序列数据示例</b> </p><p>在图 7 所示的示例中，假设我们的任务是预测从时间步骤 31 到 40 的销售额。我们可以保留 21 至 30 步的数据，然后从 0 步到 20 步训练模型。需要注意的是，在预测 31 步至 40 步时，应将 21 步至 30 步的数据纳入模型，否则，模型的性能将大打折扣。</p><p>在很多情况下，我们必须处理小型数据集，而创建大型验证集意味着模型学习会丢失大量数据。在这种情况下，我们可以选择留一交叉检验，相当于特殊的 k 则交叉检验其中 k=N ，N 是数据集中的样本数。这意味着在所有的训练折叠中，我们将对除 1 之外的所有数据样本进行训练。这种类型的交叉检验的折叠数与数据集中的样本数相同。</p><p>需要注意的是，如果模型的速度不够快，这种类型的交叉检验可能会耗费大量时间，但由于这种交叉检验只适用于小型数据集，因此并不重要。</p><p>现在我们可以转向回归问题了。回归问题的好处在于，除了分层 k 折交叉检验之外，我们可以在回归问题上使用上述所有交叉检验技术。也就是说，我们不能直接使用分层 k 折交叉检验，但有一些方法可以稍稍改变问题，从而在回归问题中使用分层 k 折交叉检验。大多数情况下，简单的 k 折交叉检验适用于任何回归问题。但是，如果发现目标分布不一致，就可以使用分层 k 折交叉检验。</p><p>要在回归问题中使用分层 k 折交叉检验，我们必须先将目标划分为若干个分层，然后再以处理分类问题的相同方式使用分层 k 折交叉检验。选择合适的分层数有几种选择。如果样本量很大（&gt; 10k，&gt; 100k），那么就不需要考虑分层的数量。只需将数据分为 10 或 20 层即可。如果样本数不多，则可以使用 Sturge’s Rule 这样的简单规则来计算适当的分层数。</p><p>Sturge’s Rule：</p><script type="math/tex; mode=display">Number of Bins = 1 + log_2(N)</script><p>其中 $N$ 是数据集中的样本数。该函数如图 8 所示。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page26_image.png" alt=""></p><p align="center"><b>图 8：利用斯特格法则绘制样本与箱数对比图</b> </p><p>让我们制作一个回归数据集样本，并尝试应用分层 k 折交叉检验，如下面的 python 代码段所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># stratified-kfold for regression</span></span><br><span class="line"><span class="comment"># 为回归问题进行分层K-折交叉验证</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入需要的库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建分折（folds）的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_folds</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="comment"># 创建一个新列叫做kfold，并用-1来填充</span></span><br><span class="line">    data[<span class="string">&quot;kfold&quot;</span>] = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 随机打乱数据的行</span></span><br><span class="line">    data = data.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用Sturge规则计算bin的数量</span></span><br><span class="line">    num_bins = <span class="built_in">int</span>(np.floor(<span class="number">1</span> + np.log2(<span class="built_in">len</span>(data))))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用pandas的cut函数进行目标变量（target）的分箱</span></span><br><span class="line">    data.loc[:, <span class="string">&quot;bins&quot;</span>] = pd.cut(</span><br><span class="line">        data[<span class="string">&quot;target&quot;</span>], bins=num_bins, labels=<span class="literal">False</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化StratifiedKFold类</span></span><br><span class="line">    kf = model_selection.StratifiedKFold(n_splits=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 填充新的kfold列</span></span><br><span class="line">    <span class="comment"># 注意：我们使用的是bins而不是实际的目标变量（target）！</span></span><br><span class="line">    <span class="keyword">for</span> f, (t_, v_) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kf.split(X=data, y=data.bins.values)):</span><br><span class="line">        data.loc[v_, <span class="string">&#x27;kfold&#x27;</span>] = f</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 删除bins列</span></span><br><span class="line">    data = data.drop(<span class="string">&quot;bins&quot;</span>, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回包含folds的数据</span></span><br><span class="line">    <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 主程序开始</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 创建一个带有15000个样本、100个特征和1个目标变量的样本数据集</span></span><br><span class="line">    X, y = datasets.make_regression(</span><br><span class="line">        n_samples=<span class="number">15000</span>, n_features=<span class="number">100</span>, n_targets=<span class="number">1</span></span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 使用numpy数组创建一个数据框</span></span><br><span class="line">    df = pd.DataFrame(</span><br><span class="line">        X,</span><br><span class="line">        columns=[<span class="string">f&quot;f_<span class="subst">&#123;i&#125;</span>&quot;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(X.shape[<span class="number">1</span>])]</span><br><span class="line">    )</span><br><span class="line">    df.loc[:, <span class="string">&quot;target&quot;</span>] = y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建folds</span></span><br><span class="line">    df = create_folds(df)</span><br></pre></td></tr></table></figure><p>交叉检验是构建机器学习模型的第一步，也是最基本的一步。如果要做特征工程，首先要拆分数据。如果要建立模型，首先要拆分数据。如果你有一个好的交叉检验方案，其中验证数据能够代表训练数据和真实世界的数据，那么你就能建立一个具有高度通用性的好的机器学习模型。</p><p>本章介绍的交叉检验类型几乎适用于所有机器学习问题。不过，你必须记住，交叉检验也在很大程度上取决于数据，你可能需要根据你的问题和数据采用新的交叉检验形式。</p><p>例如，假设我们有一个问题，希望建立一个模型，从患者的皮肤图像中检测出皮肤癌。我们的任务是建立一个二元分类器，该分类器接收输入图像并预测其良性或恶性的概率。</p><p>在这类数据集中，训练数据集中可能有同一患者的多张图像。因此，要在这里建立一个良好的交叉检验系统，必须有分层的 k 折交叉检验，但也必须确保训练数据中的患者不会出现在验证数据中。幸运的是，scikit-learn 提供了一种称为 GroupKFold 的交叉检验类型。 在这里，患者可以被视为组。 但遗憾的是，scikit-learn 无法将 GroupKFold 与 StratifiedKFold 结合起来。所以你需要自己动手。我把它作为一个练习留给读者的练习。</p>]]></content>
      
      
      <categories>
          
          <category> AAAMLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>处理分类变量</title>
      <link href="/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E5%A4%84%E7%90%86%E5%88%86%E7%B1%BB%E5%8F%98%E9%87%8F/"/>
      <url>/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E5%A4%84%E7%90%86%E5%88%86%E7%B1%BB%E5%8F%98%E9%87%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="处理分类变量"><a href="#处理分类变量" class="headerlink" title="处理分类变量"></a>处理分类变量</h1><p>很多人在处理分类变量时都会遇到很多困难，因此这值得用整整一章的篇幅来讨论。在本章中，我将讲述不同类型的分类数据，以及如何处理分类变量问题。</p><p><strong>什么是分类变量？</strong></p><p>分类变量/特征是指任何特征类型，可分为两大类：</p><ul><li>无序</li><li>有序</li></ul><p><strong>无序变量</strong>是指有两个或两个以上类别的变量，这些类别没有任何相关顺序。例如，如果将性别分为两组，即男性和女性，则可将其视为名义变量。</p><p><strong>有序变量</strong>则有 “等级 “或类别，并有特定的顺序。例如，一个顺序分类变量可以是一个具有低、中、高三个不同等级的特征。顺序很重要。</p><p>就定义而言，我们也可以将分类变量分为<strong>二元变量</strong>，即只有两个类别的分类变量。有些人甚至把分类变量称为 “<strong>循环</strong> “变量。周期变量以 “周期 “的形式存在，例如一周中的天数： 周日、周一、周二、周三、周四、周五和周六。周六过后，又是周日。这就是一个循环。另一个例子是一天中的小时数，如果我们将它们视为类别的话。</p><p>分类变量有很多不同的定义，很多人也谈到要根据分类变量的类型来处理不同的分类变量。不过，我认为没有必要这样做。所有涉及分类变量的问题都可以用同样的方法处理。</p><p>开始之前，我们需要一个数据集（一如既往）。要了解分类变量，最好的免费数据集之一是 Kaggle 分类特征编码挑战赛中的 <em>cat-in-the-dat</em>。共有两个挑战，我们将使用第二个挑战的数据，因为它比前一个版本有更多变量，难度也更大。</p><p>让我们来看看数据。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page85_image.png" alt=""></p><p align="center"><b>图 1：Cat-in-the-dat-ii challenge部分数据展示</b> </p><p>数据集由各种分类变量组成：</p><ul><li>无序</li><li>有序</li><li>循环</li><li>二元</li></ul><p>在图 1 中，我们只看到所有存在的变量和目标变量的子集。</p><p>这是一个二元分类问题。</p><p>目标变量对于我们学习分类变量来说并不十分重要，但最终我们将建立一个端到端模型，因此让我们看看图 2 中的目标变量分布。我们看到目标是<strong>偏斜</strong>的，因此对于这个二元分类问题来说，最好的指标是 ROC 曲线下面积（AUC）。我们也可以使用精确度和召回率，但 AUC 结合了这两个指标。因此，我们将使用 AUC 来评估我们在该数据集上建立的模型。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page86_image.png" alt=""></p><p align="center"><b>图 2：标签计数。X 轴表示标签，Y 轴表示标签计数</b> </p><p>总体而言，有：</p><ul><li>5 个二元变量</li><li>10 个无序变量</li><li>6 个有序变量</li><li>2 个循环变量</li><li>1 个目标变量</li></ul><p>让我们来看看数据集中的 <strong>ord_2</strong> 特征。它包括 6 个不同的类别：</p><ul><li>冰冻</li><li>温暖</li><li>寒冷</li><li>较热</li><li>热</li><li>非常热</li></ul><p>我们必须知道，计算机无法理解文本数据，因此我们需要将这些类别转换为数字。一个简单的方法是创建一个字典，将这些值映射为从 0 到 N-1 的数字，其中 N 是给定特征中类别的总数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 映射字典</span></span><br><span class="line">mapping = &#123;</span><br><span class="line"><span class="string">&quot;Freezing&quot;</span>: <span class="number">0</span>,</span><br><span class="line"><span class="string">&quot;Warm&quot;</span>: <span class="number">1</span>,</span><br><span class="line"><span class="string">&quot;Cold&quot;</span>: <span class="number">2</span>,</span><br><span class="line"><span class="string">&quot;Boiling Hot&quot;</span>: <span class="number">3</span>,</span><br><span class="line"><span class="string">&quot;Hot&quot;</span>: <span class="number">4</span>,</span><br><span class="line"><span class="string">&quot;Lava Hot&quot;</span>: <span class="number">5</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在，我们可以读取数据集，并轻松地将这些类别转换为数字。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;../input/cat_train.csv&quot;</span>)</span><br><span class="line"><span class="comment"># 取*ord_2*列，并使用映射将类别转换为数字</span></span><br><span class="line">df.loc[:, <span class="string">&quot;*ord_2*&quot;</span>] = df.*ord_2*.<span class="built_in">map</span>(mapping)</span><br></pre></td></tr></table></figure><p>映射前的数值计数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">df.*ord_2*.value_counts()</span><br><span class="line">Freezing <span class="number">142726</span></span><br><span class="line">Warm <span class="number">124239</span></span><br><span class="line">Cold           <span class="number">97822</span></span><br><span class="line">Boiling Hot    <span class="number">84790</span></span><br><span class="line">Hot            <span class="number">67508</span></span><br><span class="line">Lava Hot       <span class="number">64840</span></span><br><span class="line">Name: *ord_2*, dtype: int64</span><br></pre></td></tr></table></figure><p>映射后的数值计数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0.0</span>   <span class="number">142726</span></span><br><span class="line"><span class="number">1.0</span>   <span class="number">124239</span></span><br><span class="line"><span class="number">2.0</span>    <span class="number">97822</span></span><br><span class="line"><span class="number">3.0</span>    <span class="number">84790</span></span><br><span class="line"><span class="number">4.0</span>    <span class="number">67508</span></span><br><span class="line"><span class="number">5.0</span>    <span class="number">64840</span></span><br><span class="line">Name: *ord_2*, dtype: int64</span><br></pre></td></tr></table></figure><p>这种分类变量的编码方式被称为标签编码（Label Encoding）我们将每个类别编码为一个数字标签。</p><p>我们也可以使用 scikit-learn 中的 LabelEncoder 进行编码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;../input/cat_train.csv&quot;</span>)</span><br><span class="line"><span class="comment"># 将缺失值填充为&quot;NONE&quot;</span></span><br><span class="line">df.loc[:, <span class="string">&quot;*ord_2*&quot;</span>] = df.*ord_2*.fillna(<span class="string">&quot;NONE&quot;</span>)</span><br><span class="line"><span class="comment"># LabelEncoder编码</span></span><br><span class="line">lbl_enc = preprocessing.LabelEncoder()</span><br><span class="line"><span class="comment"># 转换数据</span></span><br><span class="line">df.loc[:, <span class="string">&quot;*ord_2*&quot;</span>] = lbl_enc.fit_transform(df.*ord_2*.values)</span><br></pre></td></tr></table></figure><p>你会看到我使用了 pandas 的 fillna。原因是 scikit-learn 的 LabelEncoder 无法处理 NaN 值，而 <em>ord_2</em> 列中有 NaN 值。</p><p>我们可以在许多基于树的模型中直接使用它：</p><ul><li>决策树</li><li>随机森林</li><li>提升树</li><li>或任何一种提升树模型</li><li>XGBoost</li><li>GBM</li><li>LightGBM</li></ul><p>这种编码方式不能用于线性模型、支持向量机或神经网络，因为它们希望数据是标准化的。</p><p>对于这些类型的模型，我们可以对数据进行二值化（binarize）处理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Freezing    --&gt; <span class="number">0</span> --&gt; <span class="number">0</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line">Warm        --&gt; <span class="number">1</span> --&gt; <span class="number">0</span> <span class="number">0</span> <span class="number">1</span></span><br><span class="line">Cold        --&gt; <span class="number">2</span> --&gt; <span class="number">0</span> <span class="number">1</span> <span class="number">0</span></span><br><span class="line">Boiling Hot --&gt; <span class="number">3</span> --&gt; <span class="number">0</span> <span class="number">1</span> <span class="number">1</span></span><br><span class="line">Hot         --&gt; <span class="number">4</span> --&gt; <span class="number">1</span> <span class="number">0</span> <span class="number">0</span></span><br><span class="line">Lava Hot    --&gt; <span class="number">5</span> --&gt; <span class="number">1</span> <span class="number">0</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><p>这只是将类别转换为数字，然后再转换为二值化表示。这样，我们就把一个特征分成了三个（在本例中）特征（或列）。如果我们有更多的类别，最终可能会分成更多的列。</p><p>如果我们用稀疏格式存储大量二值化变量，就可以轻松地存储这些变量。稀疏格式不过是一种在内存中存储数据的表示或方式，在这种格式中，你并不存储所有的值，而只存储重要的值。在上述二进制变量的情况中，最重要的就是有 1 的地方。</p><p>很难想象这样的格式，但举个例子就会明白。</p><p>假设上面的数据帧中只有一个特征：<em>ord_2</em>。</p><div class="table-container"><table><thead><tr><th style="text-align:center">Index</th><th style="text-align:center">Feature</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">Warm</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">Hot</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">Lava hot</td></tr></tbody></table></div><p>目前，我们只看到数据集中的三个样本。让我们将其转换为二值表示法，即每个样本有三个项目。</p><p>这三个项目就是三个特征。</p><div class="table-container"><table><thead><tr><th style="text-align:center">Index</th><th style="text-align:center">Feature_0</th><th style="text-align:center">Feature_1</th><th style="text-align:center">Feature_2</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">1</td></tr></tbody></table></div><p>因此，我们的特征存储在一个有 3 行 3 列（3x3）的矩阵中。矩阵的每个元素占用 8 个字节。因此，这个数组的总内存需求为 8x3x3 = 72 字节。</p><p>我们还可以使用一个简单的 python 代码段来检查这一点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">example = np.array(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(example.nbytes)</span><br></pre></td></tr></table></figure><p>这段代码将打印出 72，就像我们之前计算的那样。但我们需要存储这个矩阵的所有元素吗？如前所述，我们只对 1 感兴趣。0 并不重要，因为任何与 0 相乘的元素都是 0，而 0 与任何元素相加或相减也没有任何区别。只用 1 表示矩阵的一种方法是某种字典方法，其中键是行和列的索引，值是 1：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">0</span>, <span class="number">2</span>)      <span class="number">1</span></span><br><span class="line">(<span class="number">1</span>, <span class="number">0</span>)      <span class="number">1</span></span><br><span class="line">(<span class="number">2</span>, <span class="number">0</span>)      <span class="number">1</span></span><br><span class="line">(<span class="number">2</span>, <span class="number">2</span>)      <span class="number">1</span></span><br></pre></td></tr></table></figure><p>这样的符号占用的内存要少得多，因为它只需存储四个值（在本例中）。使用的总内存为 8x4 = 32 字节。任何 numpy 数组都可以通过简单的 python 代码转换为稀疏矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> sparse</span><br><span class="line"></span><br><span class="line">example = np.array(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line">sparse_example = sparse.csr_matrix(example)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(sparse_example.data.nbytes)</span><br></pre></td></tr></table></figure><p>这将打印 32，比我们的密集数组少了这么多！稀疏 csr 矩阵的总大小是三个值的总和。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(</span><br><span class="line">    sparse_example.data.nbytes +</span><br><span class="line">    sparse_example.indptr.nbytes +</span><br><span class="line">    sparse_example.indices.nbytes</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>这将打印出 64 个元素，仍然少于我们的密集数组。遗憾的是，我不会详细介绍这些元素。你可以在 scipy 文档中了解更多。当我们拥有更大的数组时，比如说拥有数千个样本和数万个特征的数组，大小差异就会变得非常大。例如，我们使用基于计数特征的文本数据集。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> sparse</span><br><span class="line">n_rows = <span class="number">10000</span></span><br><span class="line">n_cols = <span class="number">100000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成符合伯努利分布的随机数组，维度为[10000, 100000]</span></span><br><span class="line">example = np.random.binomial(<span class="number">1</span>, p=<span class="number">0.05</span>, size=(n_rows, n_cols))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size of dense array: <span class="subst">&#123;example.nbytes&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># 将随机矩阵转换为洗漱矩阵</span></span><br><span class="line">sparse_example = sparse.csr_matrix(example)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size of sparse array: <span class="subst">&#123;sparse_example.data.nbytes&#125;</span>&quot;</span>)</span><br><span class="line">full_size = (</span><br><span class="line">    sparse_example.data.nbytes +</span><br><span class="line">    sparse_example.indptr.nbytes +</span><br><span class="line">    sparse_example.indices.nbytes</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Full size of sparse array: <span class="subst">&#123;full_size&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>这将打印：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Size of dense array: <span class="number">8000000000</span></span><br><span class="line">Size of sparse array: <span class="number">399932496</span></span><br><span class="line">Full size of sparse array: <span class="number">599938748</span></span><br></pre></td></tr></table></figure><p>因此，密集阵列需要 ~8000MB 或大约 8GB 内存。而稀疏阵列只占用 399MB 内存。</p><p>这就是为什么当我们的特征中有大量零时，我们更喜欢稀疏阵列而不是密集阵列的原因。</p><p>请注意，稀疏矩阵有多种不同的表示方法。这里我只展示了其中一种（可能也是最常用的）方法。深入探讨这些方法超出了本书的范围，因此留给读者一个练习。</p><p>尽管二值化特征的稀疏表示比其密集表示所占用的内存要少得多，但对于分类变量来说，还有一种转换所占用的内存更少。这就是所谓的 “<strong>独热编码</strong>“。</p><p>独热编码也是一种二值编码，因为只有 0 和 1 两个值。但必须注意的是，它并不是二值表示法。我们可以通过下面的例子来理解它的表示法。</p><p>假设我们用一个向量来表示 <em>ord_2</em> 变量的每个类别。这个向量的大小与 <em>ord_2</em> 变量的类别数相同。在这种特定情况下，每个向量的大小都是 6，并且除了一个位置外，其他位置都是 0。让我们来看看这个特殊的向量表。</p><div class="table-container"><table><thead><tr><th style="text-align:center">Freezing</th><th style="text-align:center">0</th><th style="text-align:center">0</th><th style="text-align:center">0</th><th style="text-align:center">0</th><th style="text-align:center">0</th><th style="text-align:center">1</th></tr></thead><tbody><tr><td style="text-align:center">Warm</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">Cold</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">Boiling Hot</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">Hot</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">Lava Hot</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr></tbody></table></div><p>我们看到向量的大小是 1x6，即向量中有 6 个元素。这个数字是怎么来的呢？如果你仔细观察，就会发现如前所述，有 6 个类别。在进行独热编码时，向量的大小必须与我们要查看的类别数相同。每个向量都有一个 1，其余所有值都是 0。现在，让我们用这些特征来代替之前的二值化特征，看看能节省多少内存。</p><p>如果你还记得以前的数据，它看起来如下：</p><div class="table-container"><table><thead><tr><th style="text-align:center">Index</th><th style="text-align:center">Feature</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">Warm</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">Hot</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">Lava hot</td></tr></tbody></table></div><p>每个样本有 3 个特征。但在这种情况下，独热向量的大小为 6。因此，我们有 6 个特征，而不是 3 个。</p><div class="table-container"><table><thead><tr><th style="text-align:center">Index</th><th style="text-align:center">F_0</th><th style="text-align:center">F_1</th><th style="text-align:center">F_2</th><th style="text-align:center">F_3</th><th style="text-align:center">F_4</th><th style="text-align:center">F_5</th></tr></thead><tbody><tr><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">1</td><td style="text-align:center">0</td><td style="text-align:center">0</td><td style="text-align:center">0</td></tr></tbody></table></div><p>因此，我们有 6 个特征，而在这个 3x6 数组中，只有 3 个 1。使用 numpy 计算大小与二值化大小计算脚本非常相似。你需要改变的只是数组。让我们看看这段代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> sparse</span><br><span class="line">example = np.array(</span><br><span class="line">    [</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size of dense array: <span class="subst">&#123;example.nbytes&#125;</span>&quot;</span>)</span><br><span class="line">sparse_example = sparse.csr_matrix(example)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size of sparse array: <span class="subst">&#123;sparse_example.data.nbytes&#125;</span>&quot;</span>)</span><br><span class="line">full_size = (</span><br><span class="line">    sparse_example.data.nbytes +</span><br><span class="line">    sparse_example.indptr.nbytes +</span><br><span class="line">    sparse_example.indices.nbytes</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Full size of sparse array: <span class="subst">&#123;full_size&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>打印内存大小为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Size of dense array: <span class="number">144</span></span><br><span class="line">Size of sparse array: <span class="number">24</span></span><br><span class="line">Full size of sparse array: <span class="number">52</span></span><br></pre></td></tr></table></figure><p>我们可以看到，密集矩阵的大小远远大于二值化矩阵的大小。不过，稀疏数组的大小要更小。让我们用更大的数组来试试。在本例中，我们将使用 scikit-learn 中的 OneHotEncoder 将包含 1001 个类别的特征数组转换为密集矩阵和稀疏矩阵。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成符合均匀分布的随机整数，维度为[1000000, 10000000]</span></span><br><span class="line">example = np.random.randint(<span class="number">1000</span>, size=<span class="number">1000000</span>)</span><br><span class="line"><span class="comment"># 独热编码，非稀疏矩阵</span></span><br><span class="line">ohe = preprocessing.OneHotEncoder(sparse=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 将随机数组展平</span></span><br><span class="line">ohe_example = ohe.fit_transform(example.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size of dense array: <span class="subst">&#123;ohe_example.nbytes&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># 独热编码，稀疏矩阵</span></span><br><span class="line">ohe = preprocessing.OneHotEncoder(sparse=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 将随机数组展平</span></span><br><span class="line">ohe_example = ohe.fit_transform(example.reshape(-<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Size of sparse array: <span class="subst">&#123;ohe_example.data.nbytes&#125;</span>&quot;</span>)</span><br><span class="line">full_size = (</span><br><span class="line">    ohe_example.data.nbytes +</span><br><span class="line">    ohe_example.indptr.nbytes +</span><br><span class="line">    ohe_example.indices.nbytes</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Full size of sparse array: <span class="subst">&#123;full_size&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>上面代码打印的输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Size of dense array: <span class="number">8000000000</span></span><br><span class="line">Size of sparse array: <span class="number">8000000</span></span><br><span class="line">Full size of sparse array: <span class="number">16000004</span></span><br></pre></td></tr></table></figure><p>这里的密集阵列大小约为 8GB，稀疏阵列为 8MB。如果可以选择，你会选择哪个？在我看来，选择很简单，不是吗？</p><p>这三种方法（标签编码、稀疏矩阵、独热编码）是处理分类变量的最重要方法。不过，你还可以用很多其他不同的方法来处理分类变量。将分类变量转换为数值变量就是其中的一个例子。</p><p>假设我们回到之前的分类特征数据（原始数据中的 cat-in-the-dat-ii）。在数据中，<em>ord_2</em> 的值为“热“的 id 有多少？</p><p>我们可以通过计算数据的形状（shape）轻松计算出这个值，其中 <em>ord_2</em> 列的值为 <em>Boiling Hot</em>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">In [X]: df[df.ord_2 == <span class="string">&quot;Boiling Hot&quot;</span>].shape</span><br><span class="line">Out[X]: (<span class="number">84790</span>, <span class="number">25</span>)</span><br></pre></td></tr></table></figure><p>我们可以看到，有 84790 条记录具有此值。我们还可以使用 pandas 中的 <em>groupby</em> 计算所有类别的该值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [X]: df.groupby([<span class="string">&quot;ord_2&quot;</span>])[<span class="string">&quot;id&quot;</span>].count()</span><br><span class="line">Out[X]:</span><br><span class="line">ord_2</span><br><span class="line">Boiling Hot    <span class="number">84790</span></span><br><span class="line">Cold <span class="number">97822</span></span><br><span class="line">Freezing <span class="number">142726</span></span><br><span class="line">Hot <span class="number">67508</span></span><br><span class="line">Lava Hot <span class="number">64840</span></span><br><span class="line">Warm <span class="number">124239</span></span><br><span class="line">Name: <span class="built_in">id</span>, dtype: int64</span><br></pre></td></tr></table></figure><p>如果我们只是将 <em>ord_2</em> 列替换为其计数值，那么我们就将其转换为一种数值特征了。我们可以使用 pandas 的<em>transform</em>函数和 <em>groupby</em> 来创建新列或替换这一列。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">In [X]: df.groupby([<span class="string">&quot;ord_2&quot;</span>])[<span class="string">&quot;id&quot;</span>].transform(<span class="string">&quot;count&quot;</span>)</span><br><span class="line">Out[X]:</span><br><span class="line"><span class="number">0</span>         <span class="number">67508.0</span></span><br><span class="line"><span class="number">1</span>        <span class="number">124239.0</span></span><br><span class="line"><span class="number">2</span>        <span class="number">142726.0</span></span><br><span class="line"><span class="number">3</span>         <span class="number">64840.0</span></span><br><span class="line"><span class="number">4</span>         <span class="number">97822.0</span></span><br><span class="line">...</span><br><span class="line"><span class="number">599995</span>   <span class="number">142726.0</span></span><br><span class="line"><span class="number">599996</span>    <span class="number">84790.0</span></span><br><span class="line"><span class="number">599997</span>   <span class="number">142726.0</span></span><br><span class="line"><span class="number">599998</span>   <span class="number">124239.0</span></span><br><span class="line"><span class="number">599999</span>    <span class="number">84790.0</span></span><br><span class="line">Name: <span class="built_in">id</span>, Length: <span class="number">600000</span>, dtype: float64</span><br></pre></td></tr></table></figure><p>你可以添加所有特征的计数，也可以替换它们，或者根据多个列及其计数进行分组。例如，以下代码通过对 <em>ord_1</em> 和 <em>ord_2</em> 列分组进行计数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">In [X]: df.groupby(</span><br><span class="line">   ...:     [</span><br><span class="line">   ...:        <span class="string">&quot;ord_1&quot;</span>,</span><br><span class="line">   ...:        <span class="string">&quot;ord_2&quot;</span></span><br><span class="line">   ...:     ]</span><br><span class="line">   ...: )[<span class="string">&quot;id&quot;</span>].count().reset_index(name=<span class="string">&quot;count&quot;</span>)</span><br><span class="line">Out[X]:</span><br><span class="line">ord_1        ord_2  count</span><br><span class="line"><span class="number">0</span>  Contributor  Boiling Hot <span class="number">15634</span></span><br><span class="line"><span class="number">1</span>  Contributor         Cold <span class="number">17734</span></span><br><span class="line"><span class="number">2</span>  Contributor     Freezing <span class="number">26082</span></span><br><span class="line"><span class="number">3</span>  Contributor          Hot <span class="number">12428</span></span><br><span class="line"><span class="number">4</span>  Contributor     Lava Hot <span class="number">11919</span></span><br><span class="line"><span class="number">5</span>  Contributor         Warm <span class="number">22774</span></span><br><span class="line"><span class="number">6</span>       Expert  Boiling Hot <span class="number">19477</span></span><br><span class="line"><span class="number">7</span>       Expert         Cold <span class="number">22956</span></span><br><span class="line"><span class="number">8</span>       Expert     Freezing <span class="number">33249</span></span><br><span class="line"><span class="number">9</span>       Expert          Hot <span class="number">15792</span></span><br><span class="line"><span class="number">10</span>      Expert     Lava Hot <span class="number">15078</span></span><br><span class="line"><span class="number">11</span>      Expert         Warm <span class="number">28900</span></span><br><span class="line"><span class="number">12</span> Grandmaster  Boiling Hot <span class="number">13623</span></span><br><span class="line"><span class="number">13</span> Grandmaster         Cold <span class="number">15464</span></span><br><span class="line"><span class="number">14</span> Grandmaster     Freezing <span class="number">22818</span></span><br><span class="line"><span class="number">15</span> Grandmaster          Hot <span class="number">10805</span></span><br><span class="line"><span class="number">16</span> Grandmaster     Lava Hot <span class="number">10363</span></span><br><span class="line"><span class="number">17</span> Grandmaster         Warm <span class="number">19899</span></span><br><span class="line"><span class="number">18</span>      Master  Boiling Hot <span class="number">10800</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>请注意，我已经从输出中删除了一些行，以便在一页中容纳这些行。这是另一种可以作为功能添加的计数。您现在一定已经注意到，我使用 id 列进行计数。不过，你也可以通过对列的组合进行分组，对其他列进行计数。</p><p>还有一个小窍门，就是从这些分类变量中创建新特征。你可以从现有的特征中创建新的分类特征，而且可以毫不费力地做到这一点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [X]: df[<span class="string">&quot;new_feature&quot;</span>] = (</span><br><span class="line">   ...:     df.ord_1.astype(<span class="built_in">str</span>)</span><br><span class="line">   ...:     + <span class="string">&quot;_&quot;</span></span><br><span class="line">   ...:     + df.ord_2.astype(<span class="built_in">str</span>)</span><br><span class="line">   ...: )</span><br><span class="line">In [X]: df.new_feature</span><br><span class="line">Out[X]:</span><br><span class="line"><span class="number">0</span>                Contributor_Hot</span><br><span class="line"><span class="number">1</span>               Grandmaster_Warm</span><br><span class="line"><span class="number">2</span>                   nan_Freezing</span><br><span class="line"><span class="number">3</span>                Novice_Lava Hot</span><br><span class="line"><span class="number">4</span>               Grandmaster_Cold</span><br><span class="line">               ...</span><br><span class="line"><span class="number">599999</span>   Contributor_Boiling Hot</span><br><span class="line">Name: new_feature, Length: <span class="number">600000</span>, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure><p>在这里，我们用下划线将 <em>ord_1</em> 和 <em>ord_2</em> 合并，然后将这些列转换为字符串类型。请注意，NaN 也会转换为字符串。不过没关系。我们也可以将 NaN 视为一个新的类别。这样，我们就有了一个由这两个特征组合而成的新特征。您还可以将三列以上或四列甚至更多列组合在一起。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">In [X]: df[<span class="string">&quot;new_feature&quot;</span>] = (</span><br><span class="line">   ...:     df.ord_1.astype(<span class="built_in">str</span>)</span><br><span class="line">   ...:     + <span class="string">&quot;_&quot;</span></span><br><span class="line">   ...:     + df.ord_2.astype(<span class="built_in">str</span>)</span><br><span class="line">   ...:     + <span class="string">&quot;_&quot;</span></span><br><span class="line">   ...:     + df.ord_3.astype(<span class="built_in">str</span>)</span><br><span class="line">   ...: )</span><br><span class="line">In [X]: df.new_feature</span><br><span class="line">Out[X]:</span><br><span class="line"><span class="number">0</span>                Contributor_Hot_c</span><br><span class="line"><span class="number">1</span>               Grandmaster_Warm_e</span><br><span class="line"><span class="number">2</span>                   nan_Freezing_n</span><br><span class="line"><span class="number">3</span>                Novice_Lava Hot_a</span><br><span class="line"><span class="number">4</span>               Grandmaster_Cold_h</span><br><span class="line">               ...</span><br><span class="line"><span class="number">599999</span>   Contributor_Boiling Hot_b</span><br><span class="line">Name: new_feature, Length: <span class="number">600000</span>, dtype: <span class="built_in">object</span></span><br></pre></td></tr></table></figure><p>那么，我们应该把哪些类别结合起来呢？这并没有一个简单的答案。这取决于您的数据和特征类型。一些领域知识对于创建这样的特征可能很有用。但是，如果你不担心内存和 CPU 的使用，你可以采用一种贪婪的方法，即创建许多这样的组合，然后使用一个模型来决定哪些特征是有用的，并保留它们。我们将在本书稍后部分介绍这种方法。</p><p>无论何时获得分类变量，都要遵循以下简单步骤：</p><ul><li>填充 NaN 值（这一点非常重要！）。</li><li>使用 scikit-learn 的 LabelEncoder 或映射字典进行标签编码，将它们转换为整数。如果没有填充 NaN 值，可能需要在这一步中进行处理</li><li>创建独热编码。是的，你可以跳过二值化！</li><li>建模！我指的是机器学习。</li></ul><p>在分类特征中处理 NaN 数据非常重要，否则您可能会从 scikit-learn 的 LabelEncoder 中得到臭名昭著的错误信息：</p><p>ValueError: y 包含以前未见过的标签： [Nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan)</p><p>这仅仅意味着，在转换测试数据时，数据中出现了 NaN 值。这是因为你在训练时忘记了处理它们。<strong>处理 NaN 值</strong>的一个简单方法就是丢弃它们。虽然简单，但并不理想。NaN 值中可能包含很多信息，如果只是丢弃这些值，就会丢失这些信息。在很多情况下，大部分数据都是 NaN 值，因此不能丢弃 NaN 值的行/样本。处理 NaN 值的另一种方法是将其作为一个全新的类别。这是处理 NaN 值最常用的方法。如果使用 pandas，还可以通过非常简单的方式实现。</p><p>请看我们之前查看过的数据的 <em>ord_2</em> 列。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [X]: df.ord_2.value_counts()</span><br><span class="line">Out[X]:</span><br><span class="line">Freezing <span class="number">142726</span></span><br><span class="line">Warm <span class="number">124239</span></span><br><span class="line">Cold           <span class="number">97822</span></span><br><span class="line">Boiling Hot    <span class="number">84790</span></span><br><span class="line">Hot            <span class="number">67508</span></span><br><span class="line">Lava Hot       <span class="number">64840</span></span><br><span class="line">Name: ord_2, dtype: int64</span><br></pre></td></tr></table></figure><p>填入 NaN 值后，就变成了</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [X]: df.ord_2.fillna(<span class="string">&quot;NONE&quot;</span>).value_counts()</span><br><span class="line">Out[X]:</span><br><span class="line">Freezing <span class="number">142726</span></span><br><span class="line">Warm <span class="number">124239</span></span><br><span class="line">Cold           <span class="number">97822</span></span><br><span class="line">Boiling Hot    <span class="number">84790</span></span><br><span class="line">Hot            <span class="number">67508</span></span><br><span class="line">Lava Hot       <span class="number">64840</span></span><br><span class="line">NONE           <span class="number">18075</span></span><br><span class="line">Name: ord_2, dtype: int64</span><br></pre></td></tr></table></figure><p>哇！这一列中有 18075 个 NaN 值，而我们之前甚至都没有考虑使用它们。增加了这个新类别后，类别总数从 6 个增加到了 7 个。这没关系，因为现在我们在建立模型时，也会考虑 NaN。相关信息越多，模型就越好。</p><p>假设 <em>ord_2</em> 没有任何 NaN 值。我们可以看到，这一列中的所有类别都有显著的计数。其中没有 “罕见 “类别，即只在样本总数中占很小比例的类别。现在，让我们假设您在生产中部署了使用这一列的模型，当模型或项目上线时，您在 <em>ord_2</em> 列中得到了一个在训练中不存在的类别。在这种情况下，模型管道会抛出一个错误，您对此无能为力。如果出现这种情况，那么可能是生产中的管道出了问题。如果这是预料之中的，那么您就必须修改您的模型管道，并在这六个类别中加入一个新类别。</p><p>这个新类别被称为 “罕见 “类别。罕见类别是一种不常见的类别，可以包括许多不同的类别。您也可以尝试使用近邻模型来 “预测 “未知类别。请记住，如果您预测了这个类别，它就会成为训练数据中的一个类别。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page101_image.png" alt=""></p><p align="center"><b>图 3：具有不同特征且无标签的数据集示意图，其中一个特征可能会在测试集或实时数据中出现新值</b> </p><p>当我们有一个如图 3 所示的数据集时，我们可以建立一个简单的模型，对除 “f3 “之外的所有特征进行训练。这样，你将创建一个模型，在不知道或训练中没有 “f3 “时预测它。我不敢说这样的模型是否能带来出色的性能，但也许能处理测试集或实时数据中的缺失值，就像机器学习中的其他事情一样，不尝试一下是说不准的。</p><p>如果你有一个固定的测试集，你可以将测试数据添加到训练中，以了解给定特征中的类别。这与半监督学习非常相似，即使用无法用于训练的数据来改进模型。这也会照顾到在训练数据中出现次数极少但在测试数据中大量存在的稀有值。你的模型将更加稳健。</p><p>很多人认为这种想法会过度拟合。可能过拟合，也可能不过拟合。有一个简单的解决方法。如果你在设计交叉验证时，能够在测试数据上运行模型时复制预测过程，那么它就永远不会过拟合。这意味着第一步应该是分离折叠，在每个折叠中，你应该应用与测试数据相同的预处理。假设您想合并训练数据和测试数据，那么在每个折叠中，您必须合并训练数据和验证数据，并确保验证数据集复制了测试集。在这种特定情况下，您必须以这样一种方式设计验证集，使其包含训练集中 “未见 “的类别。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page102_image.png" alt=""></p><p align="center"><b>图 4：对训练集和测试集进行简单合并，以了解测试集中存在但训练集中不存在的类别或训练集中罕见的类别</b> </p><p>只要看一下图 4 和下面的代码，就能很容易理解其工作原理。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="comment"># 读取训练集</span></span><br><span class="line">train = pd.read_csv(<span class="string">&quot;../input/cat_train.csv&quot;</span>)</span><br><span class="line"><span class="comment"># 读取测试集</span></span><br><span class="line">test = pd.read_csv(<span class="string">&quot;../input/cat_test.csv&quot;</span>)</span><br><span class="line"><span class="comment"># 将测试集&quot;target&quot;列全部置为-1</span></span><br><span class="line">test.loc[:, <span class="string">&quot;target&quot;</span>] = -<span class="number">1</span></span><br><span class="line"><span class="comment"># 将训练集、测试集沿行拼接</span></span><br><span class="line">data = pd.concat([train, test]).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 将除&quot;id&quot;和&quot;target&quot;列的其他特征列名取出</span></span><br><span class="line">features = [x <span class="keyword">for</span> x <span class="keyword">in</span> train.columns <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&quot;id&quot;</span>, <span class="string">&quot;target&quot;</span>]]</span><br><span class="line"><span class="comment"># 遍历特征</span></span><br><span class="line"><span class="keyword">for</span> feat <span class="keyword">in</span> features:</span><br><span class="line">    <span class="comment"># 标签编码</span></span><br><span class="line">    lbl_enc = preprocessing.LabelEncoder()</span><br><span class="line">    <span class="comment"># 将空值替换为&quot;NONE&quot;,并将该列格式变为str</span></span><br><span class="line">    temp_col = data[feat].fillna(<span class="string">&quot;NONE&quot;</span>).astype(<span class="built_in">str</span>).values</span><br><span class="line">    <span class="comment"># 转换数值</span></span><br><span class="line">    data.loc[:, feat] = lbl_enc.fit_transform(temp_col)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据&quot;target&quot;列将训练集与测试集分开</span></span><br><span class="line">train = data[data.target != -<span class="number">1</span>].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">test = data[data.target == -<span class="number">1</span>].reset_index(drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p>当您遇到已经有测试数据集的问题时，这个技巧就会起作用。必须注意的是，这一招在实时环境中不起作用。例如，假设您所在的公司提供实时竞价解决方案（RTB）。RTB 系统会对在线看到的每个用户进行竞价，以购买广告空间。这种模式可使用的功能可能包括网站中浏览的页面。我们假设这些特征是用户访问的最后五个类别/页面。在这种情况下，如果网站引入了新的类别，我们将无法再准确预测。在这种情况下，我们的模型就会失效。这种情况可以通过使用 <strong>“未知 “类别来避免</strong>。</p><p>在我们的 cat-in-the-dat 数据集中，<em>ord_2</em> 列中已经有了未知类别。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [X]: df.ord_2.fillna(<span class="string">&quot;NONE&quot;</span>).value_counts()</span><br><span class="line">Out[X]:</span><br><span class="line">Freezing       <span class="number">142726</span></span><br><span class="line">Warm           <span class="number">124239</span></span><br><span class="line">Cold           <span class="number">97822</span></span><br><span class="line">Boiling Hot    <span class="number">84790</span></span><br><span class="line">Hot            <span class="number">67508</span></span><br><span class="line">Lava Hot       <span class="number">64840</span></span><br><span class="line">NONE           <span class="number">18075</span></span><br><span class="line">Name: ord_2, dtype: int64</span><br></pre></td></tr></table></figure><p>我们可以将 “NONE “视为未知。因此，如果在实时测试过程中，我们获得了以前从未见过的新类别，我们就会将其标记为 “NONE”。</p><p>这与自然语言处理问题非常相似。我们总是基于固定的词汇建立模型。增加词汇量就会增加模型的大小。像 BERT 这样的转换器模型是在 ~30000 个单词（英语）的基础上训练的。因此，当有新词输入时，我们会将其标记为 UNK（未知）。</p><p>因此，您可以假设测试数据与训练数据具有相同的类别，也可以在训练数据中引入罕见或未知类别，以处理测试数据中的新类别。</p><p>让我们看看填入 NaN 值后 ord_4 列的值计数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">In [X]: df.ord_4.fillna(<span class="string">&quot;NONE&quot;</span>).value_counts()</span><br><span class="line">Out[X]:</span><br><span class="line">N       <span class="number">39978</span></span><br><span class="line">P       <span class="number">37890</span></span><br><span class="line">Y       <span class="number">36657</span></span><br><span class="line">A       <span class="number">36633</span></span><br><span class="line">R       <span class="number">33045</span></span><br><span class="line">U       <span class="number">32897</span></span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">K       <span class="number">21676</span></span><br><span class="line">I       <span class="number">19805</span></span><br><span class="line">NONE    <span class="number">17930</span></span><br><span class="line">D       <span class="number">17284</span></span><br><span class="line">F       <span class="number">16721</span></span><br><span class="line">W       <span class="number">8268</span></span><br><span class="line">Z       <span class="number">5790</span></span><br><span class="line">S       <span class="number">4595</span></span><br><span class="line">G       <span class="number">3404</span></span><br><span class="line">V       <span class="number">3107</span></span><br><span class="line">J       <span class="number">1950</span></span><br><span class="line">L       <span class="number">1657</span></span><br><span class="line">Name: ord_4, dtype: int64</span><br></pre></td></tr></table></figure><p>我们看到，有些数值只出现了几千次，有些则出现了近 40000 次。NaN 也经常出现。请注意，我已经从输出中删除了一些值。</p><p>现在，我们可以定义将一个值称为 “<strong>罕见（rare）</strong> “的标准了。比方说，在这一列中，稀有值的要求是计数小于 2000。这样看来，J 和 L 就可以被标记为稀有值了。使用 pandas，根据计数阈值替换类别非常简单。让我们来看看它是如何实现的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">In [X]: df.ord_4 = df.ord_4.fillna(<span class="string">&quot;NONE&quot;</span>)</span><br><span class="line">In [X]: df.loc[</span><br><span class="line">   ...:     df[<span class="string">&quot;ord_4&quot;</span>].value_counts()[df[<span class="string">&quot;ord_4&quot;</span>]].values &lt; <span class="number">2000</span>,</span><br><span class="line">   ...:    <span class="string">&quot;ord_4&quot;</span></span><br><span class="line">   ...: ] = <span class="string">&quot;RARE&quot;</span></span><br><span class="line">In [X]: df.ord_4.value_counts()</span><br><span class="line">Out[X]:</span><br><span class="line">N      <span class="number">39978</span></span><br><span class="line">P      <span class="number">37890</span></span><br><span class="line">Y      <span class="number">36657</span></span><br><span class="line">A      <span class="number">36633</span></span><br><span class="line">R      <span class="number">33045</span></span><br><span class="line">U      <span class="number">32897</span></span><br><span class="line">M      <span class="number">32504</span></span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">B      <span class="number">25212</span></span><br><span class="line">E      <span class="number">21871</span></span><br><span class="line">K      <span class="number">21676</span></span><br><span class="line">I      <span class="number">19805</span></span><br><span class="line">NONE   <span class="number">17930</span></span><br><span class="line">D      <span class="number">17284</span></span><br><span class="line">F      <span class="number">16721</span></span><br><span class="line">W       <span class="number">8268</span></span><br><span class="line">Z       <span class="number">5790</span></span><br><span class="line">S       <span class="number">4595</span></span><br><span class="line">RARE    <span class="number">3607</span></span><br><span class="line">G       <span class="number">3404</span></span><br><span class="line">V       <span class="number">3107</span></span><br><span class="line">Name: ord_4, dtype: int64</span><br></pre></td></tr></table></figure><p>我们认为，只要某个类别的值小于 2000，就将其替换为罕见。因此，现在在测试数据时，所有未见过的新类别都将被映射为 “RARE”，而所有缺失值都将被映射为 “NONE”。</p><p>这种方法还能确保即使有新的类别，模型也能在实际环境中正常工作。</p><p>现在，我们已经具备了处理任何带有分类变量问题所需的一切条件。让我们尝试建立第一个模型，并逐步提高其性能。</p><p>在构建任何类型的模型之前，交叉检验至关重要。我们已经看到了标签/目标分布，知道这是一个目标偏斜的二元分类问题。因此，我们将使用 StratifiedKFold 来分割数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 读取数据文件</span></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;../input/cat_train.csv&quot;</span>)</span><br><span class="line">    <span class="comment"># 添加&quot;kfold&quot;列，并置为-1</span></span><br><span class="line">df[<span class="string">&quot;kfold&quot;</span>] = -<span class="number">1</span></span><br><span class="line">    <span class="comment"># 打乱数据顺序，重置索引</span></span><br><span class="line">df = df.sample(frac=<span class="number">1</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 将目标列取出</span></span><br><span class="line">y = df.target.values</span><br><span class="line">    <span class="comment"># 分层k折交叉检验</span></span><br><span class="line">kf = model_selection.StratifiedKFold(n_splits=<span class="number">5</span>)</span><br><span class="line"><span class="keyword">for</span> f, (t_, v_) <span class="keyword">in</span> <span class="built_in">enumerate</span>(kf.split(X=df, y=y)):</span><br><span class="line">        <span class="comment"># 区分折叠</span></span><br><span class="line">df.loc[v_, <span class="string">&#x27;kfold&#x27;</span>] = f</span><br><span class="line">    <span class="comment"># 保存文件</span></span><br><span class="line">df.to_csv(<span class="string">&quot;../input/cat_train_folds.csv&quot;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>现在我们可以检查新的折叠 csv，查看每个折叠的样本数：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [X]: <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">In [X]: df = pd.read_csv(<span class="string">&quot;../input/cat_train_folds.csv&quot;</span>)</span><br><span class="line">In [X]: df.kfold.value_counts()</span><br><span class="line">Out[X]:</span><br><span class="line"><span class="number">4</span>   <span class="number">120000</span></span><br><span class="line"><span class="number">3</span>   <span class="number">120000</span></span><br><span class="line"><span class="number">2</span>   <span class="number">120000</span></span><br><span class="line"><span class="number">1</span>   <span class="number">120000</span></span><br><span class="line"><span class="number">0</span>   <span class="number">120000</span></span><br><span class="line">Name: kfold, dtype: int64</span><br></pre></td></tr></table></figure><p>所有折叠都有 120000 个样本。这是意料之中的，因为训练数据有 600000 个样本，而我们做了 5 次折叠。到目前为止，一切顺利。</p><p>现在，我们还可以检查每个折叠的目标分布。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">In [X]: df[df.kfold==<span class="number">0</span>].target.value_counts()</span><br><span class="line">Out[X]:</span><br><span class="line"><span class="number">0</span>   <span class="number">97536</span></span><br><span class="line"><span class="number">1</span>   <span class="number">22464</span></span><br><span class="line">Name: target, dtype: int64</span><br><span class="line">In [X]: df[df.kfold==<span class="number">1</span>].target.value_counts()</span><br><span class="line">Out[X]:</span><br><span class="line"><span class="number">0</span>   <span class="number">97536</span></span><br><span class="line"><span class="number">1</span>   <span class="number">22464</span></span><br><span class="line">Name: target, dtype: int64</span><br><span class="line">In [X]: df[df.kfold==<span class="number">2</span>].target.value_counts()</span><br><span class="line">Out[X]:</span><br><span class="line"><span class="number">0</span>   <span class="number">97535</span></span><br><span class="line"><span class="number">1</span>   <span class="number">22465</span></span><br><span class="line">Name: target, dtype: int64</span><br><span class="line">In [X]: df[df.kfold==<span class="number">3</span>].target.value_counts()</span><br><span class="line">Out[X]:</span><br><span class="line"><span class="number">0</span>   <span class="number">97535</span></span><br><span class="line"><span class="number">1</span>   <span class="number">22465</span></span><br><span class="line">Name: target, dtype: int64</span><br><span class="line">In [X]: df[df.kfold==<span class="number">4</span>].target.value_counts()</span><br><span class="line">Out[X]:</span><br><span class="line"><span class="number">0</span>   <span class="number">97535</span></span><br><span class="line"><span class="number">1</span>   <span class="number">22465</span></span><br><span class="line">Name: target, dtype: int64</span><br></pre></td></tr></table></figure><p>我们看到，在每个折叠中，目标的分布都是一样的。这正是我们所需要的。它也可以是相似的，并不一定要一直相同。现在，当我们建立模型时，每个折叠中的标签分布都将相同。</p><p>我们可以建立的最简单的模型之一是对所有数据进行独热编码并使用逻辑回归。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    <span class="comment"># 读取分层k折交叉检验数据</span></span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/cat_train_folds.csv&quot;</span>)</span><br><span class="line">    <span class="comment"># 取除&quot;id&quot;, &quot;target&quot;, &quot;kfold&quot;外的其他特征列</span></span><br><span class="line">    features = [</span><br><span class="line">        f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;id&quot;</span>, <span class="string">&quot;target&quot;</span>, <span class="string">&quot;kfold&quot;</span>)</span><br><span class="line">    ]</span><br><span class="line">    <span class="comment"># 遍历特征列表</span></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="comment"># 将空值置为&quot;NONE&quot;</span></span><br><span class="line">        df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>)</span><br><span class="line">    <span class="comment"># 取训练集（kfold列中不为fold的样本，重置索引）</span></span><br><span class="line">    df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 取验证集（kfold列中为fold的样本，重置索引）</span></span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 独热编码</span></span><br><span class="line">    ohe = preprocessing.OneHotEncoder()</span><br><span class="line">    <span class="comment"># 将训练集、验证集沿行合并</span></span><br><span class="line">    full_data = pd.concat([df_train[features], df_valid[features]], axis=<span class="number">0</span>)</span><br><span class="line">    ohe.fit(full_data[features])</span><br><span class="line">    <span class="comment"># 转换训练集</span></span><br><span class="line">    x_train = ohe.transform(df_train[features])</span><br><span class="line">    <span class="comment"># 转换测试集</span></span><br><span class="line">    x_valid = ohe.transform(df_valid[features])</span><br><span class="line">    <span class="comment"># 逻辑回归</span></span><br><span class="line">    model = linear_model.LogisticRegression()</span><br><span class="line">    <span class="comment"># 使用训练集训练模型</span></span><br><span class="line">    model.fit(x_train, df_train.target.values)</span><br><span class="line">    <span class="comment"># 使用验证集得到预测标签</span></span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 计算auc指标</span></span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(auc)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 运行折叠0</span></span><br><span class="line">    run(<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>那么，发生了什么呢？</p><p>我们创建了一个函数，将数据分为训练和验证两部分，给定折叠数，处理 NaN 值，对所有数据进行单次编码，并训练一个简单的逻辑回归模型。</p><p>当我们运行这部分代码时，会产生如下输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">❯ python ohe_logres.py</span><br><span class="line">/home/abhishek/miniconda3/envs/ml/lib/python3<span class="number">.7</span>/site-</span><br><span class="line">packages/sklearn/linear_model/_logistic.py:<span class="number">939</span>: ConvergenceWarning: lbfgs</span><br><span class="line">failed to converge (status=<span class="number">1</span>):</span><br><span class="line">STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.</span><br><span class="line">Increase the number of iterations (max_iter) <span class="keyword">or</span> scale the data <span class="keyword">as</span> shown</span><br><span class="line"><span class="keyword">in</span>:</span><br><span class="line">https://scikit-learn.org/stable/modules/preprocessing.html.</span><br><span class="line">Please also refer to the documentation <span class="keyword">for</span> alternative solver options:</span><br><span class="line">https://scikit-learn.org/stable/modules/linear_model.html<span class="comment">#logistic-</span></span><br><span class="line">regression</span><br><span class="line">extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)</span><br><span class="line"><span class="number">0.7847865042255127</span></span><br></pre></td></tr></table></figure><p>有一些警告。逻辑回归似乎没有收敛到最大迭代次数。我们没有调整参数，所以没有问题。我们看到 AUC 为 0.785。</p><p>现在让我们对代码进行简单修改，运行所有折叠。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">....</span><br><span class="line"></span><br><span class="line">model = linear_model.LogisticRegression()</span><br><span class="line">model.fit(x_train, df_train.target.values)</span><br><span class="line">valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>]</span><br><span class="line">auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 循环运行0~4折</span></span><br><span class="line"><span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">run(fold_)</span><br></pre></td></tr></table></figure><p>请注意，我们并没有做很大的改动，所以我只显示了部分代码行，其中一些代码行有改动。</p><p>这就打印出了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">python -W ignore ohe_logres.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.7847865042255127</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.7853553605899214</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.7879321942914885</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.7870315929550808</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.7864668243125608</span></span><br></pre></td></tr></table></figure><p>请注意，我使用”-W ignore “忽略了所有警告。</p><p>我们看到，AUC 分数在所有褶皱中都相当稳定。平均 AUC 为 0.78631449527。对于我们的第一个模型来说相当不错！</p><p>很多人在遇到这种问题时会首先使用基于树的模型，比如随机森林。在这个数据集中应用随机森林时，我们可以使用标签编码（label encoding），将每一列中的每个特征都转换为整数，而不是之前讨论过的独热编码。</p><p>这种编码与独热编码并无太大区别。让我们来看看。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> ensemble</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/cat_train_folds.csv&quot;</span>)</span><br><span class="line">    features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;id&quot;</span>, <span class="string">&quot;target&quot;</span>, <span class="string">&quot;kfold&quot;</span>) ]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="comment"># 标签编码</span></span><br><span class="line">        lbl = preprocessing.LabelEncoder()</span><br><span class="line">    lbl.fit(df[col])</span><br><span class="line">df.loc[:, col] = lbl.transform(df[col])</span><br><span class="line">df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">x_train = df_train[features].values</span><br><span class="line">x_valid = df_valid[features].values</span><br><span class="line">    <span class="comment"># 随机森林模型</span></span><br><span class="line">model = ensemble.RandomForestClassifier(n_jobs=-<span class="number">1</span>)</span><br><span class="line">    model.fit(x_train, df_train.target.values)</span><br><span class="line">valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>]</span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"><span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">run(fold_)</span><br></pre></td></tr></table></figure><p>我们使用 scikit-learn 中的随机森林，并取消了独热编码。我们使用标签编码代替独热编码。得分如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python lbl_rf.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.7167390828113697</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.7165459672958506</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.7159709909587376</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.7161589664189556</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.7156020216155978</span></span><br></pre></td></tr></table></figure><p>哇 巨大的差异！ 随机森林模型在没有任何超参数调整的情况下，表现要比简单的逻辑回归差很多。</p><p>这就是为什么我们总是应该先从简单模型开始的原因。随机森林模型的粉丝会从这里开始，而忽略逻辑回归模型，认为这是一个非常简单的模型，不能带来比随机森林更好的价值。这种人将会犯下大错。在我们实现随机森林的过程中，与逻辑回归相比，折叠需要更长的时间才能完成。因此，我们不仅损失了 AUC，还需要更长的时间来完成训练。请注意，使用随机森林进行推理也很耗时，而且占用的空间也更大。</p><p>如果我们愿意，也可以尝试在稀疏的独热编码数据上运行随机森林，但这会耗费大量时间。我们还可以尝试使用奇异值分解来减少稀疏的独热编码矩阵。这是自然语言处理中提取主题的常用方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> sparse</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> decomposition</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> ensemble</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">df = pd.read_csv(<span class="string">&quot;../input/cat_train_folds.csv&quot;</span>)</span><br><span class="line">features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;id&quot;</span>, <span class="string">&quot;target&quot;</span>, <span class="string">&quot;kfold&quot;</span>)]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>)</span><br><span class="line">df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 独热编码</span></span><br><span class="line">ohe = preprocessing.OneHotEncoder()</span><br><span class="line">full_data = pd.concat([df_train[features], df_valid[features]], axis=<span class="number">0</span>)</span><br><span class="line">ohe.fit(full_data[features])</span><br><span class="line"></span><br><span class="line">x_train = ohe.transform(df_train[features])</span><br><span class="line">x_valid = ohe.transform(df_valid[features])</span><br><span class="line">    <span class="comment"># 奇异值分解</span></span><br><span class="line">svd = decomposition.TruncatedSVD(n_components=<span class="number">120</span>)</span><br><span class="line">    full_sparse = sparse.vstack((x_train, x_valid))</span><br><span class="line">    svd.fit(full_sparse)</span><br><span class="line">    x_train = svd.transform(x_train)</span><br><span class="line">    x_valid = svd.transform(x_valid)</span><br><span class="line">model = ensemble.RandomForestClassifier(n_jobs=-<span class="number">1</span>)</span><br><span class="line">    model.fit(x_train, df_train.target.values)</span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>]</span><br><span class="line">auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line"><span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">run(fold_)</span><br></pre></td></tr></table></figure><p>我们对全部数据进行独热编码，然后用训练数据和验证数据在稀疏矩阵上拟合 scikit-learn 的 TruncatedSVD。这样，我们将高维稀疏矩阵减少到 120 个特征，然后拟合随机森林分类器。</p><p>以下是该模型的输出结果：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python ohe_svd_rf.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.7064863038754249</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.706050102937374</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.7086069243167242</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.7066819080085971</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.7058154015055585</span></span><br></pre></td></tr></table></figure><p>我们发现情况更糟。看来，解决这个问题的最佳方法是使用逻辑回归和独热编码。随机森林似乎耗时太多。也许我们可以试试 XGBoost。如果你不知道 XGBoost，它是最流行的梯度提升算法之一。由于它是一种基于树的算法，我们将使用标签编码数据。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/cat_train_folds.csv&quot;</span>)</span><br><span class="line">    features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;id&quot;</span>, <span class="string">&quot;target&quot;</span>, <span class="string">&quot;kfold&quot;</span>) ]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="comment"># 标签编码</span></span><br><span class="line">        lbl = preprocessing.LabelEncoder()</span><br><span class="line">        lbl.fit(df[col])</span><br><span class="line">        df.loc[:, col] = lbl.transform(df[col])</span><br><span class="line"></span><br><span class="line">df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">x_train = df_train[features].values</span><br><span class="line">x_valid = df_valid[features].values</span><br><span class="line">    <span class="comment"># XGBoost模型</span></span><br><span class="line">model = xgb.XGBClassifier(</span><br><span class="line">        n_jobs=-<span class="number">1</span>,</span><br><span class="line">        max_depth=<span class="number">7</span>,</span><br><span class="line">        n_estimators=<span class="number">200</span>)</span><br><span class="line">    model.fit(x_train, df_train.target.values)</span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>]</span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">        <span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">            run(fold_)</span><br></pre></td></tr></table></figure><p>必须指出的是，在这段代码中，我对 xgboost 参数做了一些修改。xgboost 的默认最大深度（max_depth）是 3，我把它改成了 7，还把估计器数量（n_estimators）从 100 改成了 200。</p><p>该模型的 5 折交叉检验得分如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python lbl_xgb.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.7656768851999011</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.7633006564148015</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.7654277821434345</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.7663609758878182</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.764914671468069</span></span><br></pre></td></tr></table></figure><p>我们可以看到，在不做任何调整的情况下，我们的得分比普通随机森林要高得多。</p><p>您还可以尝试一些特征工程，放弃某些对模型没有任何价值的列等。但似乎我们能做的不多，无法证明模型的改进。让我们把数据集换成另一个有大量分类变量的数据集。另一个有名的数据集是<strong>美国成人人口普查数据（US adult census data）</strong>。这个数据集包含一些特征，而你的任务是预测工资等级。让我们来看看这个数据集。图 5 显示了该数据集中的一些列。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page119_image.png" alt=""></p><p align="center"><b>图 5：部分数据集展示</b> </p><p>该数据集有以下几列：</p><ul><li><p>年龄（age）</p></li><li><p>工作类别（workclass）</p></li><li>学历（fnlwgt）</li><li>教育程度（education）</li><li>教育程度（education.num）</li><li>婚姻状况（marital.status）</li><li>职业（occupation）</li><li>关系（relationship）</li><li>种族（race）</li><li>性别（sex）</li><li>资本收益（capital.gain）</li><li>资本损失（capital.loss）</li><li>每周小时数（hours.per.week）</li><li>原籍国（native.country）</li><li>收入（income）</li></ul><p>这些特征大多不言自明。那些不明白的，我们可以不考虑。让我们先尝试建立一个模型。</p><p>我们看到收入列是一个字符串。让我们对这一列进行数值统计。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [X]: <span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">In [X]: df = pd.read_csv(<span class="string">&quot;../input/adult.csv&quot;</span>)</span><br><span class="line">In [X]: df.income.value_counts()</span><br><span class="line">Out[X]:</span><br><span class="line">&lt;=50K   <span class="number">24720</span></span><br><span class="line">&gt;50K     <span class="number">7841</span></span><br></pre></td></tr></table></figure><p>我们可以看到，有 7841 个实例的收入超过 5 万美元。这占样本总数的 24%。因此，我们将保持与猫数据集相同的评估方法，即 AUC。 在开始建模之前，为了简单起见，我们将去掉几列特征，即</p><ul><li>学历（fnlwgt）</li><li>年龄（age）</li><li>资本收益（capital.gain）</li><li>资本损失（capital.loss）</li><li>每周小时数（hours.per.week）</li></ul><p>让我们试着用逻辑回归和独热编码器，看看会发生什么。第一步总是要进行交叉验证。我不会在这里展示这部分代码。留待读者练习。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/adult_folds.csv&quot;</span>)</span><br><span class="line">    <span class="comment"># 需要删除的列</span></span><br><span class="line">    num_cols = [</span><br><span class="line">        <span class="string">&quot;fnlwgt&quot;</span>,</span><br><span class="line">        <span class="string">&quot;age&quot;</span>,</span><br><span class="line">        <span class="string">&quot;capital.gain&quot;</span>,</span><br><span class="line">        <span class="string">&quot;capital.loss&quot;</span>,</span><br><span class="line">        <span class="string">&quot;hours.per.week&quot;</span></span><br><span class="line">    ]</span><br><span class="line">    df = df.drop(num_cols, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 映射</span></span><br><span class="line">    target_mapping = &#123;</span><br><span class="line">        <span class="string">&quot;&lt;=50K&quot;</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="string">&quot;&gt;50K&quot;</span>: <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 使用映射替换</span></span><br><span class="line">    df.loc[:, <span class="string">&quot;income&quot;</span>] = df.income.<span class="built_in">map</span>(target_mapping)</span><br><span class="line">    <span class="comment"># 取除&quot;kfold&quot;, &quot;income&quot;列的其他列名</span></span><br><span class="line">    features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;kfold&quot;</span>, <span class="string">&quot;income&quot;</span>) ]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="comment"># 将空值替换为&quot;NONE&quot;</span></span><br><span class="line">        df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>)</span><br><span class="line">    <span class="comment"># 取训练集（kfold列中不为fold的样本，重置索引）</span></span><br><span class="line">df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 取验证集（kfold列中为fold的样本，重置索引）</span></span><br><span class="line">df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 独热编码</span></span><br><span class="line">    ohe = preprocessing.OneHotEncoder()</span><br><span class="line">    <span class="comment"># 将训练集、测试集沿行合并</span></span><br><span class="line">full_data = pd.concat([df_train[features], df_valid[features]], axis=<span class="number">0</span>)</span><br><span class="line">ohe.fit(full_data[features])</span><br><span class="line">    <span class="comment"># 转换训练集</span></span><br><span class="line">x_train = ohe.transform(df_train[features])</span><br><span class="line">    <span class="comment"># 转换验证集</span></span><br><span class="line">x_valid = ohe.transform(df_valid[features])</span><br><span class="line">    <span class="comment"># 构建逻辑回归模型</span></span><br><span class="line">model = linear_model.LogisticRegression()</span><br><span class="line">    <span class="comment"># 使用训练集训练模型</span></span><br><span class="line">model.fit(x_train, df_train.income.values)</span><br><span class="line">    <span class="comment"># 使用验证集得到预测标签</span></span><br><span class="line">valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 计算auc指标</span></span><br><span class="line">auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 运行0~4折</span></span><br><span class="line">    <span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        run(fold_)</span><br></pre></td></tr></table></figure><p>当我们运行这段代码时，我们会得到</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python -W ignore ohe_logres.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.8794809708119079</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.8875785068274882</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.8852609687685753</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.8681236223251438</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.8728581541840037</span></span><br></pre></td></tr></table></figure><p>对于一个如此简单的模型来说，这是一个非常不错的 AUC！<br>现在，让我们在不调整任何超参数的情况下尝试一下标签编码的 xgboost。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/adult_folds.csv&quot;</span>)</span><br><span class="line">    num_cols = [ <span class="string">&quot;fnlwgt&quot;</span>,</span><br><span class="line">                <span class="string">&quot;age&quot;</span>,</span><br><span class="line">                <span class="string">&quot;capital.gain&quot;</span>,</span><br><span class="line">                <span class="string">&quot;capital.loss&quot;</span>,</span><br><span class="line">                <span class="string">&quot;hours.per.week&quot;</span></span><br><span class="line">               ]</span><br><span class="line">    df = df.drop(num_cols, axis=<span class="number">1</span>)</span><br><span class="line">    target_mapping = &#123;</span><br><span class="line">        <span class="string">&quot;&lt;=50K&quot;</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="string">&quot;&gt;50K&quot;</span>: <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">df.loc[:, <span class="string">&quot;income&quot;</span>] = df.income.<span class="built_in">map</span>(target_mapping)</span><br><span class="line">features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;kfold&quot;</span>, <span class="string">&quot;income&quot;</span>) ]</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">    df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="comment"># 标签编码</span></span><br><span class="line">lbl = preprocessing.LabelEncoder()</span><br><span class="line">    lbl.fit(df[col])</span><br><span class="line">    df.loc[:, col] = lbl.transform(df[col])</span><br><span class="line"></span><br><span class="line">df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">x_train = df_train[features].values</span><br><span class="line">x_valid = df_valid[features].values</span><br><span class="line">    <span class="comment"># XGBoost模型</span></span><br><span class="line">model = xgb.XGBClassifier(n_jobs=-<span class="number">1</span>)</span><br><span class="line">model.fit(x_train, df_train.income.values)</span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>]</span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 运行0~4折</span></span><br><span class="line"><span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">run(fold_)</span><br></pre></td></tr></table></figure><p>让我们运行上面代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python lbl_xgb.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.8800810634234078</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.886811884948154</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.8854421433318472</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.8676319549361007</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.8714450054900602</span></span><br></pre></td></tr></table></figure><p>这看起来已经相当不错了。让我们看看 <em>max_depth</em> 增加到 7 和 <em>n_estimators</em> 增加到 200 时的得分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python lbl_xgb.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.8764108944332032</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.8840708537662638</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.8816601162613102</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.8662335762581732</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.8698983461709926</span></span><br></pre></td></tr></table></figure><p>看起来并没有改善。</p><p>这表明，一个数据集的参数不能移植到另一个数据集。我们必须再次尝试调整参数，但我们将在接下来的章节中详细说明。</p><p>现在，让我们尝试在不调整参数的情况下将数值特征纳入 xgboost 模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/adult_folds.csv&quot;</span>)</span><br><span class="line">    <span class="comment"># 加入数值特征</span></span><br><span class="line">    num_cols = [</span><br><span class="line">        <span class="string">&quot;fnlwgt&quot;</span>,</span><br><span class="line">        <span class="string">&quot;age&quot;</span>,</span><br><span class="line">        <span class="string">&quot;capital.gain&quot;</span>,</span><br><span class="line">        <span class="string">&quot;capital.loss&quot;</span>,</span><br><span class="line">        <span class="string">&quot;hours.per.week&quot;</span></span><br><span class="line">    ]</span><br><span class="line">    target_mapping = &#123;</span><br><span class="line">        <span class="string">&quot;&lt;=50K&quot;</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="string">&quot;&gt;50K&quot;</span>: <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">    df.loc[:, <span class="string">&quot;income&quot;</span>] = df.income.<span class="built_in">map</span>(target_mapping)</span><br><span class="line">    features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;kfold&quot;</span>, <span class="string">&quot;income&quot;</span>) ]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> num_cols:</span><br><span class="line">            <span class="comment"># 将空值置为&quot;NONE&quot;</span></span><br><span class="line">            df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> num_cols:</span><br><span class="line">            <span class="comment"># 标签编码</span></span><br><span class="line">            lbl = preprocessing.LabelEncoder()</span><br><span class="line">            lbl.fit(df[col])</span><br><span class="line">            df.loc[:, col] = lbl.transform(df[col])</span><br><span class="line"></span><br><span class="line">df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">x_train = df_train[features].values</span><br><span class="line">x_valid = df_valid[features].values</span><br><span class="line">    <span class="comment"># XGBoost模型</span></span><br><span class="line">model = xgb.XGBClassifier(n_jobs=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    model.fit(x_train, df_train.income.values)</span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>]</span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        run(fold_)</span><br></pre></td></tr></table></figure><p>因此，我们保留数字列，只是不对其进行标签编码。这样，我们的最终特征矩阵就由数字列（原样）和编码分类列组成了。任何基于树的算法都能轻松处理这种混合。</p><p>请注意，在使用基于树的模型时，我们不需要对数据进行归一化处理。不过，这一点非常重要，在使用线性模型（如逻辑回归）时不容忽视。</p><p>现在让我们运行这个脚本！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python lbl_xgb_num.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.9209790185449889</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.9247157449144706</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.9269329887598243</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.9119349082169275</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.9166408030141667</span></span><br></pre></td></tr></table></figure><p>哇哦</p><p>这是一个很好的分数！</p><p>现在，我们可以尝试添加一些功能。我们将提取所有分类列，并创建所有二度组合。请看下面代码段中的 feature_engineering 函数，了解如何实现这一点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">feature_engineering</span>(<span class="params">df, cat_cols</span>):</span><br><span class="line">    <span class="comment"># 生成两个特征的组合</span></span><br><span class="line">    combi = <span class="built_in">list</span>(itertools.combinations(cat_cols, <span class="number">2</span>))</span><br><span class="line">    <span class="keyword">for</span> c1, c2 <span class="keyword">in</span> combi:</span><br><span class="line">        df.loc[:, c1 + <span class="string">&quot;_&quot;</span> + c2] = df[c1].astype(<span class="built_in">str</span>) + <span class="string">&quot;_&quot;</span> + df[c2].astype(<span class="built_in">str</span>)</span><br><span class="line">    <span class="keyword">return</span> df</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/adult_folds.csv&quot;</span>)</span><br><span class="line">    num_cols = [ <span class="string">&quot;fnlwgt&quot;</span>,</span><br><span class="line">                <span class="string">&quot;age&quot;</span>,</span><br><span class="line">                <span class="string">&quot;capital.gain&quot;</span>,</span><br><span class="line">                <span class="string">&quot;capital.loss&quot;</span>,</span><br><span class="line">                <span class="string">&quot;hours.per.week&quot;</span></span><br><span class="line">               ]</span><br><span class="line">    target_mapping = &#123;</span><br><span class="line">        <span class="string">&quot;&lt;=50K&quot;</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="string">&quot;&gt;50K&quot;</span>: <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">df.loc[:, <span class="string">&quot;income&quot;</span>] = df.income.<span class="built_in">map</span>(target_mapping)</span><br><span class="line">cat_cols = [c <span class="keyword">for</span> c <span class="keyword">in</span> df.columns <span class="keyword">if</span> c <span class="keyword">not</span> <span class="keyword">in</span> num_cols <span class="keyword">and</span> c <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;kfold&quot;</span>, <span class="string">&quot;income&quot;</span>)]</span><br><span class="line">    <span class="comment"># 特征工程</span></span><br><span class="line">    df = feature_engineering(df, cat_cols)</span><br><span class="line">    features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;kfold&quot;</span>, <span class="string">&quot;income&quot;</span>)]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> num_cols:</span><br><span class="line">            df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> num_cols:</span><br><span class="line">            lbl = preprocessing.LabelEncoder()</span><br><span class="line">            lbl.fit(df[col])</span><br><span class="line">            df.loc[:, col] = lbl.transform(df[col])</span><br><span class="line"></span><br><span class="line">df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">x_train = df_train[features].values</span><br><span class="line">x_valid = df_valid[features].values</span><br><span class="line">model = xgb.XGBClassifier(n_jobs=-<span class="number">1</span>)</span><br><span class="line">model.fit(x_train, df_train.income.values)</span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>]</span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        run(fold_)</span><br></pre></td></tr></table></figure><p>这是从分类列中创建特征的一种非常幼稚的方法。我们应该仔细研究数据，看看哪些组合最合理。如果使用这种方法，最终可能会创建大量特征，在这种情况下，就需要使用某种特征选择来选出最佳特征。稍后我们将详细介绍特征选择。现在让我们来看看分数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python lbl_xgb_num_feat.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.9211483465031423</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.9251499446866125</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.9262344766486692</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.9114264068794995</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.9177914453099201</span></span><br></pre></td></tr></table></figure><p>看来，即使不改变任何超参数，只增加一些特征，我们也能提高一些折叠得分。让我们看看将 <em>max_depth</em> 增加到 7 是否有帮助。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python lbl_xgb_num_feat.py</span><br><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.9286668430204137</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.9329340656165378</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.9319817543218744</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.919046187194538</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.9245692057162671</span></span><br></pre></td></tr></table></figure><p>我们再次改进了我们的模型。</p><p>请注意，我们还没有使用稀有值、二值化、独热编码和标签编码特征的组合以及其他几种方法。</p><p>从分类特征中进行特征工程的另一种方法是使用<strong>目标编码</strong>。但是，您必须非常小心，因为这可能会使您的模型过度拟合。目标编码是一种将给定特征中的每个类别映射到其平均目标值的技术，但必须始终以交叉验证的方式进行。这意味着首先要创建折叠，然后使用这些折叠为数据的不同列创建目标编码特征，方法与在折叠上拟合和预测模型的方法相同。因此，如果您创建了 5 个折叠，您就必须创建 5 次目标编码，这样最终，您就可以为每个折叠中的变量创建编码，而这些变量并非来自同一个折叠。然后在拟合模型时，必须再次使用相同的折叠。未见测试数据的目标编码可以来自全部训练数据，也可以是所有 5 个折叠的平均值。</p><p>让我们看看如何在同一个成人数据集上使用目标编码，以便进行比较。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mean_target_encoding</span>(<span class="params">data</span>):</span><br><span class="line">    df = copy.deepcopy(data)</span><br><span class="line">    num_cols = [ <span class="string">&quot;fnlwgt&quot;</span>,</span><br><span class="line">                <span class="string">&quot;age&quot;</span>,</span><br><span class="line">                <span class="string">&quot;capital.gain&quot;</span>,</span><br><span class="line">                <span class="string">&quot;capital.loss&quot;</span>,</span><br><span class="line">                <span class="string">&quot;hours.per.week&quot;</span>]</span><br><span class="line">    target_mapping = &#123;</span><br><span class="line">        <span class="string">&quot;&lt;=50K&quot;</span>: <span class="number">0</span>,</span><br><span class="line">        <span class="string">&quot;&gt;50K&quot;</span>: <span class="number">1</span></span><br><span class="line">    &#125;</span><br><span class="line">    df.loc[:, <span class="string">&quot;income&quot;</span>] = df.income.<span class="built_in">map</span>(target_mapping)</span><br><span class="line">    features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;kfold&quot;</span>, <span class="string">&quot;income&quot;</span>) <span class="keyword">and</span> f <span class="keyword">not</span> <span class="keyword">in</span> num_cols]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> num_cols:</span><br><span class="line">            df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        <span class="keyword">if</span> col <span class="keyword">not</span> <span class="keyword">in</span> num_cols:</span><br><span class="line">            <span class="comment"># 标签编码</span></span><br><span class="line">            lbl = preprocessing.LabelEncoder()</span><br><span class="line">            lbl.fit(df[col])</span><br><span class="line">            df.loc[:, col] = lbl.transform(df[col])</span><br><span class="line"></span><br><span class="line">encoded_dfs = []</span><br><span class="line">    <span class="keyword">for</span> fold <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">        df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">for</span> column <span class="keyword">in</span> features:</span><br><span class="line">            <span class="comment"># 目标编码</span></span><br><span class="line">            mapping_dict = <span class="built_in">dict</span>(df_train.groupby(column)[<span class="string">&quot;income&quot;</span>].mean() )</span><br><span class="line">            df_valid.loc[:, column + <span class="string">&quot;_enc&quot;</span>] = df_valid[column].<span class="built_in">map</span>(mapping_dict)</span><br><span class="line">        encoded_dfs.append(df_valid)</span><br><span class="line">encoded_df = pd.concat(encoded_dfs, axis=<span class="number">0</span>)</span><br><span class="line"><span class="keyword">return</span> encoded_df</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">df, fold</span>):</span><br><span class="line">    df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;kfold&quot;</span>, <span class="string">&quot;income&quot;</span>) ]</span><br><span class="line">    x_train = df_train[features].values</span><br><span class="line">    x_valid = df_valid[features].values</span><br><span class="line">    model = xgb.XGBClassifier( n_jobs=-<span class="number">1</span>, max_depth=<span class="number">7</span>)</span><br><span class="line">    model.fit(x_train, df_train.income.values)</span><br><span class="line">    valid_preds = model.predict_proba(x_valid)[:, <span class="number">1</span>]</span><br><span class="line">    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold = <span class="subst">&#123;fold&#125;</span>, AUC = <span class="subst">&#123;auc&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/adult_folds.csv&quot;</span>)</span><br><span class="line">    df = mean_target_encoding(df)</span><br><span class="line">    <span class="keyword">for</span> fold_ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">        run(df, fold_)</span><br></pre></td></tr></table></figure><p>必须指出的是，在上述片段中，我在进行目标编码时并没有删除分类列。我保留了所有特征，并在此基础上添加了目标编码特征。此外，我还使用了平均值。您可以使用平均值、中位数、标准偏差或目标的任何其他函数。</p><p>让我们看看结果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Fold = <span class="number">0</span>, AUC = <span class="number">0.9332240662017529</span></span><br><span class="line">Fold = <span class="number">1</span>, AUC = <span class="number">0.9363551625140347</span></span><br><span class="line">Fold = <span class="number">2</span>, AUC = <span class="number">0.9375013544556173</span></span><br><span class="line">Fold = <span class="number">3</span>, AUC = <span class="number">0.92237621307625</span></span><br><span class="line">Fold = <span class="number">4</span>, AUC = <span class="number">0.9292131180445478</span></span><br></pre></td></tr></table></figure><p>不错！看来我们又有进步了。不过，使用目标编码时必须非常小心，因为它太容易出现过度拟合。当我们使用目标编码时，最好使用某种平滑方法或在编码值中添加噪声。 Scikit-learn 的贡献库中有带平滑的目标编码，你也可以创建自己的平滑。平滑会引入某种正则化，有助于避免模型过度拟合。这并不难。</p><p>处理分类特征是一项复杂的任务。许多资源中都有大量信息。本章应该能帮助你开始解决分类变量的任何问题。不过，对于大多数问题来说，除了独热编码和标签编码之外，你不需要更多的东西。 要进一步改进模型，你可能需要更多！</p><p>在本章的最后，我们不能不在这些数据上使用神经网络。因此，让我们来看看一种称为<strong>实体嵌入</strong>的技术。在实体嵌入中，类别用向量表示。在二值化和独热编码方法中，我们都是用向量来表示类别的。 但是，如果我们有数以万计的类别怎么办？这将会产生巨大的矩阵，我们将需要很长时间来训练复杂的模型。因此，我们可以用带有浮点值的向量来表示它们。</p><p>这个想法非常简单。每个分类特征都有一个嵌入层。因此，一列中的每个类别现在都可以映射到一个嵌入层（就像在自然语言处理中将单词映射到嵌入层一样）。然后，根据其维度重塑这些嵌入层，使其扁平化，然后将所有扁平化的输入嵌入层连接起来。然后添加一堆密集层和一个输出层，就大功告成了。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page136_image.png" alt=""></p><p align="center"><b>图 6：类别转换为浮点或嵌入向量</b> </p><p>出于某种原因，我发现使用 TF/Keras 可以非常容易地做到这一点。因此，让我们来看看如何使用 TF/Keras 实现它。此外，这是本书中唯一一个使用 TF/Keras 的示例，将其转换为 PyTorch（使用 cat-in-the-dat-ii 数据集）也非常容易</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics, preprocessing</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> optimizers</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.models <span class="keyword">import</span> Model, load_model</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> callbacks</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> utils</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_model</span>(<span class="params">data, catcols</span>):</span><br><span class="line">    <span class="comment"># 创建空的输入列表和输出列表，用于存储模型的输入和输出</span></span><br><span class="line">    inputs = []</span><br><span class="line">    outputs = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历分类特征列表中的每个特征</span></span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> catcols:</span><br><span class="line">        <span class="comment"># 计算特征中唯一值的数量</span></span><br><span class="line">        num_unique_values = <span class="built_in">int</span>(data[c].nunique())</span><br><span class="line">        <span class="comment"># 计算嵌入维度，最大不超过50</span></span><br><span class="line">        embed_dim = <span class="built_in">int</span>(<span class="built_in">min</span>(np.ceil((num_unique_values) / <span class="number">2</span>), <span class="number">50</span>))</span><br><span class="line">        <span class="comment"># 创建模型的输入层，每个特征对应一个输入</span></span><br><span class="line">        inp = layers.Input(shape=(<span class="number">1</span>,))</span><br><span class="line">        <span class="comment"># 创建嵌入层，将分类特征映射到低维度的连续向量</span></span><br><span class="line">        out = layers.Embedding(num_unique_values + <span class="number">1</span>, embed_dim, name=c)(inp)</span><br><span class="line">        <span class="comment"># 对嵌入层进行空间丢弃（Dropout）</span></span><br><span class="line">        out = layers.SpatialDropout1D(<span class="number">0.3</span>)(out)</span><br><span class="line">        <span class="comment"># 将嵌入层的形状重新调整为一维</span></span><br><span class="line">        out = layers.Reshape(target_shape=(embed_dim,))(out)</span><br><span class="line">        <span class="comment"># 将输入和输出添加到对应的列表中</span></span><br><span class="line">        inputs.append(inp)</span><br><span class="line">        outputs.append(out)</span><br><span class="line">    <span class="comment"># 使用Concatenate层将所有的嵌入层输出连接在一起</span></span><br><span class="line">    x = layers.Concatenate()(outputs)</span><br><span class="line">    <span class="comment"># 对连接后的数据进行批量归一化</span></span><br><span class="line">    x = layers.BatchNormalization()(x)</span><br><span class="line">    <span class="comment"># 添加一个具有300个神经元的密集层，并使用ReLU激活函数</span></span><br><span class="line">    x = layers.Dense(<span class="number">300</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># 对该层的输出进行Dropout</span></span><br><span class="line">    x = layers.Dropout(<span class="number">0.3</span>)(x)</span><br><span class="line">    <span class="comment"># 再次进行批量归一化</span></span><br><span class="line">    x = layers.BatchNormalization()(x)</span><br><span class="line">    <span class="comment"># 添加另一个具有300个神经元的密集层，并使用ReLU激活函数</span></span><br><span class="line">    x = layers.Dense(<span class="number">300</span>, activation=<span class="string">&quot;relu&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># 对该层的输出进行Dropout</span></span><br><span class="line">    x = layers.Dropout(<span class="number">0.3</span>)(x)</span><br><span class="line">    <span class="comment"># 再次进行批量归一化</span></span><br><span class="line">    x = layers.BatchNormalization()(x)</span><br><span class="line">    <span class="comment"># 输出层，具有2个神经元（用于二进制分类），并使用softmax激活函数</span></span><br><span class="line">    y = layers.Dense(<span class="number">2</span>, activation=<span class="string">&quot;softmax&quot;</span>)(x)</span><br><span class="line">    <span class="comment"># 创建模型，将输入和输出传递给Model构造函数</span></span><br><span class="line">    model = Model(inputs=inputs, outputs=y)</span><br><span class="line">    <span class="comment"># 编译模型，指定损失函数和优化器</span></span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>, optimizer=<span class="string">&#x27;adam&#x27;</span>)</span><br><span class="line">    <span class="comment"># 返回创建的模型</span></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/cat_train_folds.csv&quot;</span>)</span><br><span class="line">    features = [f <span class="keyword">for</span> f <span class="keyword">in</span> df.columns <span class="keyword">if</span> f <span class="keyword">not</span> <span class="keyword">in</span> (<span class="string">&quot;id&quot;</span>, <span class="string">&quot;target&quot;</span>, <span class="string">&quot;kfold&quot;</span>) ]</span><br><span class="line">    <span class="keyword">for</span> col <span class="keyword">in</span> features:</span><br><span class="line">        df.loc[:, col] = df[col].astype(<span class="built_in">str</span>).fillna(<span class="string">&quot;NONE&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> feat <span class="keyword">in</span> features:</span><br><span class="line">        lbl_enc = preprocessing.LabelEncoder()</span><br><span class="line">        df.loc[:, feat] = lbl_enc.fit_transform(df[feat].values)</span><br><span class="line"></span><br><span class="line">    df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    model = create_model(df, features)</span><br><span class="line">    xtrain = [df_train[features].values[:, k] <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(features))]</span><br><span class="line">    xvalid = [df_valid[features].values[:, k] <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(features)) ]</span><br><span class="line">    ytrain = df_train.target.values</span><br><span class="line">    yvalid = df_valid.target.values</span><br><span class="line">    ytrain_cat = utils.to_categorical(ytrain)</span><br><span class="line">    yvalid_cat = utils.to_categorical(yvalid)</span><br><span class="line">    model.fit(xtrain,</span><br><span class="line">              ytrain_cat,</span><br><span class="line">              validation_data=(xvalid, yvalid_cat),</span><br><span class="line">              verbose=<span class="number">1</span>,</span><br><span class="line">              batch_size=<span class="number">1024</span>,</span><br><span class="line">              epochs=<span class="number">3</span></span><br><span class="line">             )</span><br><span class="line">    valid_preds = model.predict(xvalid)[:, <span class="number">1</span>]</span><br><span class="line">    <span class="built_in">print</span>(metrics.roc_auc_score(yvalid, valid_preds))</span><br><span class="line">    K.clear_session()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">run(<span class="number">0</span>)</span><br><span class="line">run(<span class="number">1</span>)</span><br><span class="line">run(<span class="number">2</span>)</span><br><span class="line">run(<span class="number">3</span>)</span><br><span class="line">run(<span class="number">4</span>)</span><br></pre></td></tr></table></figure><p>你会发现这种方法效果最好，而且如果你有 GPU，速度也超快！这种方法还可以进一步改进，而且你无需担心特征工程，因为神经网络会自行处理。在处理大量分类特征数据集时，这绝对值得一试。当嵌入大小与唯一类别的数量相同时，我们就可以使用独热编码（one-hot-encoding）。</p><p>本章基本上都是关于特征工程的。让我们在下一章中看看如何在数字特征和不同类型特征的组合方面进行更多的特征工程。</p>]]></content>
      
      
      <categories>
          
          <category> AAAMLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>特征工程</title>
      <link href="/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"/>
      <url>/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h1><p>特征工程是构建良好机器学习模型的最关键部分之一。如果我们拥有有用的特征，模型就会表现得更好。在许多情况下，您可以避免使用大型复杂模型，而使用具有关键工程特征的简单模型。我们必须牢记，只有当你对问题的领域有一定的了解，并且在很大程度上取决于相关数据时，才能以最佳方式完成特征工程。不过，您可以尝试使用一些通用技术，从几乎所有类型的数值变量和分类变量中创建特征。特征工程不仅仅是从数据中创建新特征，还包括不同类型的归一化和转换。</p><p>在有关分类特征的章节中，我们已经了解了结合不同分类变量的方法、如何将分类变量转换为计数、标签编码和使用嵌入。这些几乎都是利用分类变量设计特征的方法。因此，在本章中，我们的重点将仅限于数值变量以及数值变量和分类变量的组合。</p><p>让我们从最简单但应用最广泛的特征工程技术开始。假设你正在处理日期和时间数据。因此，我们有一个带有日期类型列的 pandas 数据帧。利用这一列，我们可以创建以下特征：</p><ul><li>年</li><li>年中的周</li><li>月</li><li>星期</li><li>周末</li><li>小时</li><li>还有更多</li></ul><p>而使用 pandas 就可以非常容易地做到这一点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加&#x27;year&#x27;列，将 &#x27;datetime_column&#x27; 中的年份提取出来</span></span><br><span class="line">df.loc[:, <span class="string">&#x27;year&#x27;</span>] = df[<span class="string">&#x27;datetime_column&#x27;</span>].dt.year</span><br><span class="line"><span class="comment"># 添加&#x27;weekofyear&#x27;列，将 &#x27;datetime_column&#x27; 中的周数提取出来</span></span><br><span class="line">df.loc[:, <span class="string">&#x27;weekofyear&#x27;</span>] = df[<span class="string">&#x27;datetime_column&#x27;</span>].dt.weekofyear</span><br><span class="line"><span class="comment"># 添加&#x27;month&#x27;列，将 &#x27;datetime_column&#x27; 中的月份提取出来</span></span><br><span class="line">df.loc[:, <span class="string">&#x27;month&#x27;</span>] = df[<span class="string">&#x27;datetime_column&#x27;</span>].dt.month</span><br><span class="line"><span class="comment"># 添加&#x27;dayofweek&#x27;列，将 &#x27;datetime_column&#x27; 中的星期几提取出来</span></span><br><span class="line">df.loc[:, <span class="string">&#x27;dayofweek&#x27;</span>] = df[<span class="string">&#x27;datetime_column&#x27;</span>].dt.dayofweek</span><br><span class="line"><span class="comment"># 添加&#x27;weekend&#x27;列，判断当天是否为周末</span></span><br><span class="line">df.loc[:, <span class="string">&#x27;weekend&#x27;</span>] = (df.datetime_column.dt.weekday &gt;=<span class="number">5</span>).astype(<span class="built_in">int</span>)</span><br><span class="line"><span class="comment"># 添加 &#x27;hour&#x27; 列，将 &#x27;datetime_column&#x27; 中的小时提取出来</span></span><br><span class="line">df.loc[:, <span class="string">&#x27;hour&#x27;</span>] = df[<span class="string">&#x27;datetime_column&#x27;</span>].dt.hour</span><br></pre></td></tr></table></figure><p>因此，我们将使用日期时间列创建一系列新列。让我们来看看可以创建的一些示例功能。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 创建日期时间序列，包含了从 &#x27;2020-01-06&#x27; 到 &#x27;2020-01-10&#x27; 的日期时间点，时间间隔为10小时</span></span><br><span class="line">s = pd.date_range(<span class="string">&#x27;2020-01-06&#x27;</span>, <span class="string">&#x27;2020-01-10&#x27;</span>, freq=<span class="string">&#x27;10H&#x27;</span>).to_series()</span><br><span class="line"><span class="comment"># 提取对应时间特征</span></span><br><span class="line">features = &#123;</span><br><span class="line">    <span class="string">&quot;dayofweek&quot;</span>: s.dt.dayofweek.values,</span><br><span class="line">    <span class="string">&quot;dayofyear&quot;</span>: s.dt.dayofyear.values,</span><br><span class="line">    <span class="string">&quot;hour&quot;</span>: s.dt.hour.values,</span><br><span class="line">    <span class="string">&quot;is_leap_year&quot;</span>: s.dt.is_leap_year.values,</span><br><span class="line">    <span class="string">&quot;quarter&quot;</span>: s.dt.quarter.values,</span><br><span class="line">    <span class="string">&quot;weekofyear&quot;</span>: s.dt.weekofyear.values</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这将从给定系列中生成一个特征字典。您可以将此应用于 pandas 数据中的任何日期时间列。这些是 pandas 提供的众多日期时间特征中的一部分。在处理时间序列数据时，日期时间特征非常重要，例如，在预测一家商店的销售额时，如果想在聚合特征上使用 xgboost 等模型，日期时间特征就非常重要。</p><p>假设我们有一个如下所示的数据：</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page142_image.png" alt=""></p><p align="center"><b>图 1：包含分类和日期特征的样本数据</b> </p><p>在图 1 中，我们可以看到有一个日期列，从中可以轻松提取年、月、季度等特征。然后，我们有一个 customer_id 列，该列有多个条目，因此一个客户会被看到很多次（截图中看不到）。每个日期和客户 ID 都有三个分类特征和一个数字特征。我们可以从中创建大量特征：</p><ul><li>客户最活跃的月份是几月</li><li>某个客户的 cat1、cat2、cat3 的计数是多少</li><li>某年某月某周某客户的 cat1、cat2、cat3 数量是多少？</li><li>某个客户的 num1 平均值是多少？</li><li>等等。</li></ul><p>使用 pandas 中的聚合，可以很容易地创建类似的功能。让我们来看看如何实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">generate_features</span>(<span class="params">df</span>):</span><br><span class="line">    df.loc[:, <span class="string">&#x27;year&#x27;</span>] = df[<span class="string">&#x27;date&#x27;</span>].dt.year</span><br><span class="line">    df.loc[:, <span class="string">&#x27;weekofyear&#x27;</span>] = df[<span class="string">&#x27;date&#x27;</span>].dt.weekofyear</span><br><span class="line">    df.loc[:, <span class="string">&#x27;month&#x27;</span>] = df[<span class="string">&#x27;date&#x27;</span>].dt.month</span><br><span class="line">    df.loc[:, <span class="string">&#x27;dayofweek&#x27;</span>] = df[<span class="string">&#x27;date&#x27;</span>].dt.dayofweek</span><br><span class="line">    df.loc[:, <span class="string">&#x27;weekend&#x27;</span>] = (df[<span class="string">&#x27;date&#x27;</span>].dt.weekday &gt;=<span class="number">5</span>).astype(<span class="built_in">int</span>)</span><br><span class="line">    aggs = &#123;&#125;</span><br><span class="line">    <span class="comment"># 对 &#x27;month&#x27; 列进行 nunique 和 mean 聚合</span></span><br><span class="line">    aggs[<span class="string">&#x27;month&#x27;</span>] = [<span class="string">&#x27;nunique&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>]</span><br><span class="line">    <span class="comment"># 对 &#x27;weekofyear&#x27; 列进行 nunique 和 mean 聚合</span></span><br><span class="line">    aggs[<span class="string">&#x27;weekofyear&#x27;</span>] = [<span class="string">&#x27;nunique&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>]</span><br><span class="line">    <span class="comment"># 对 &#x27;num1&#x27; 列进行 sum、max、min、mean 聚合</span></span><br><span class="line">    aggs[<span class="string">&#x27;num1&#x27;</span>] = [<span class="string">&#x27;sum&#x27;</span>,<span class="string">&#x27;max&#x27;</span>,<span class="string">&#x27;min&#x27;</span>,<span class="string">&#x27;mean&#x27;</span>]</span><br><span class="line">    <span class="comment"># 对 &#x27;customer_id&#x27; 列进行 size 聚合</span></span><br><span class="line">    aggs[<span class="string">&#x27;customer_id&#x27;</span>] = [<span class="string">&#x27;size&#x27;</span>]</span><br><span class="line">    <span class="comment"># 对 &#x27;customer_id&#x27; 列进行 nunique 聚合</span></span><br><span class="line">    aggs[<span class="string">&#x27;customer_id&#x27;</span>] = [<span class="string">&#x27;nunique&#x27;</span>]</span><br><span class="line">    <span class="comment"># 对数据应用不同的聚合函数</span></span><br><span class="line">    agg_df = df.groupby(<span class="string">&#x27;customer_id&#x27;</span>).agg(aggs)</span><br><span class="line">    <span class="comment"># 重置索引</span></span><br><span class="line">    agg_df = agg_df.reset_index()</span><br><span class="line"><span class="keyword">return</span> agg_df</span><br></pre></td></tr></table></figure><p>请注意，在上述函数中，我们跳过了分类变量，但您可以像使用其他聚合变量一样使用它们。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page144_image.png" alt=""></p><p align="center"><b>图 2：总体特征和其他特征</b> </p><p>现在，我们可以将图 2 中的数据与带有 customer_id 列的原始数据帧连接起来，开始训练模型。在这里，我们并不是要预测什么；我们只是在创建通用特征。不过，如果我们试图在这里预测什么，创建特征会更容易。</p><p>例如，有时在处理时间序列问题时，您可能需要的特征不是单个值，而是一系列值。 例如，客户在特定时间段内的交易。在这种情况下，我们会创建不同类型的特征，例如：使用数值特征时，在对分类列进行分组时，会得到类似于时间分布值列表的特征。在这种情况下，您可以创建一系列统计特征，例如</p><ul><li>平均值</li><li>最大值</li><li>最小值</li><li>独特性</li><li>偏斜</li><li>峰度</li><li>Kstat</li><li>百分位数</li><li>定量</li><li>峰值到峰值</li><li>以及更多</li></ul><p>这些可以使用简单的 numpy 函数创建，如下面的 python 代码段所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 创建字典，用于存储不同的统计特征</span></span><br><span class="line">feature_dict = &#123;&#125;</span><br><span class="line"><span class="comment"># 计算 x 中元素的平均值，并将结果存储在 feature_dict 中的 &#x27;mean&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;mean&#x27;</span>] = np.mean(x)</span><br><span class="line"><span class="comment"># 计算 x 中元素的最大值，并将结果存储在 feature_dict 中的 &#x27;max&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;max&#x27;</span>] = np.<span class="built_in">max</span>(x)</span><br><span class="line"><span class="comment"># 计算 x 中元素的最小值，并将结果存储在 feature_dict 中的 &#x27;min&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;min&#x27;</span>] = np.<span class="built_in">min</span>(x)</span><br><span class="line"><span class="comment"># 计算 x 中元素的标准差，并将结果存储在 feature_dict 中的 &#x27;std&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;std&#x27;</span>] = np.std(x)</span><br><span class="line"><span class="comment"># 计算 x 中元素的方差，并将结果存储在 feature_dict 中的 &#x27;var&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;var&#x27;</span>] = np.var(x)</span><br><span class="line"><span class="comment"># 计算 x 中元素的差值，并将结果存储在 feature_dict 中的 &#x27;ptp&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;ptp&#x27;</span>] = np.ptp(x)</span><br><span class="line"><span class="comment"># 计算 x 中元素的第10百分位数（即百分之10分位数），并将结果存储在 feature_dict 中的 &#x27;percentile_10&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;percentile_10&#x27;</span>] = np.percentile(x, <span class="number">10</span>)</span><br><span class="line"><span class="comment"># 计算 x 中元素的第60百分位数，将结果存储在 feature_dict 中的 &#x27;percentile_60&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;percentile_60&#x27;</span>] = np.percentile(x, <span class="number">60</span>)</span><br><span class="line"><span class="comment"># 计算 x 中元素的第90百分位数，将结果存储在 feature_dict 中的 &#x27;percentile_90&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;percentile_90&#x27;</span>] = np.percentile(x, <span class="number">90</span>)</span><br><span class="line"><span class="comment"># 计算 x 中元素的5%分位数（即0.05分位数），将结果存储在 feature_dict 中的 &#x27;quantile_5&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;quantile_5&#x27;</span>] = np.quantile(x, <span class="number">0.05</span>)</span><br><span class="line"><span class="comment"># 计算 x 中元素的95%分位数（即0.95分位数），将结果存储在 feature_dict 中的 &#x27;quantile_95&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;quantile_95&#x27;</span>] = np.quantile(x, <span class="number">0.95</span>)</span><br><span class="line"><span class="comment"># 计算 x 中元素的99%分位数（即0.99分位数），将结果存储在 feature_dict 中的 &#x27;quantile_99&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;quantile_99&#x27;</span>] = np.quantile(x, <span class="number">0.99</span>)</span><br></pre></td></tr></table></figure><p>时间序列数据（数值列表）可以转换成许多特征。在这种情况下，一个名为 tsfresh 的 python 库非常有用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tsfresh.feature_extraction <span class="keyword">import</span> feature_calculators <span class="keyword">as</span> fc</span><br><span class="line"><span class="comment"># 计算 x 数列的绝对能量（abs_energy），并将结果存储在 feature_dict 字典中的 &#x27;abs_energy&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;abs_energy&#x27;</span>] = fc.abs_energy(x)</span><br><span class="line"><span class="comment"># 计算 x 数列中高于均值的数据点数量，将结果存储在 feature_dict 字典中的 &#x27;count_above_mean&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;count_above_mean&#x27;</span>] = fc.count_above_mean(x)</span><br><span class="line"><span class="comment"># 计算 x 数列中低于均值的数据点数量，将结果存储在 feature_dict 字典中的 &#x27;count_below_mean&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;count_below_mean&#x27;</span>] = fc.count_below_mean(x)</span><br><span class="line"><span class="comment"># 计算 x 数列的均值绝对变化（mean_abs_change），并将结果存储在 feature_dict 字典中的 &#x27;mean_abs_change&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;mean_abs_change&#x27;</span>] = fc.mean_abs_change(x)</span><br><span class="line"><span class="comment"># 计算 x 数列的均值变化率（mean_change），并将结果存储在 feature_dict 字典中的 &#x27;mean_change&#x27; 键下</span></span><br><span class="line">feature_dict[<span class="string">&#x27;mean_change&#x27;</span>] = fc.mean_change(x)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>这还不是全部；tsfresh 提供了数百种特征和数十种不同特征的变体，你可以将它们用于基于时间序列（值列表）的特征。在上面的例子中，x 是一个值列表。但这还不是全部。您还可以为包含或不包含分类数据的数值数据创建许多其他特征。生成许多特征的一个简单方法就是创建一堆多项式特征。例如，从两个特征 “a “和 “b “生成的二级多项式特征包括 “a”、”b”、”ab”、”a^2 “和 “b^2”。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">df = pd.DataFrame(</span><br><span class="line">np.random.rand(<span class="number">100</span>, <span class="number">2</span>),</span><br><span class="line">columns=[<span class="string">f&quot;f_<span class="subst">&#123;i&#125;</span>&quot;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">3</span>)])</span><br></pre></td></tr></table></figure><p>如图 3 所示，它给出了一个数据表。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page146_image.png" alt=""></p><p align="center"><b>图 3：包含两个数字特征的随机数据表</b> </p><p>我们可以使用 scikit-learn 的 PolynomialFeatures 创建两次多项式特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"><span class="comment"># 指定多项式的次数为 2，不仅考虑交互项，不包括偏差（include_bias=False）</span></span><br><span class="line">pf = preprocessing.PolynomialFeatures(degree=<span class="number">2</span>,</span><br><span class="line">                                      interaction_only=<span class="literal">False</span>,</span><br><span class="line">                                      include_bias=<span class="literal">False</span></span><br><span class="line">                                     )</span><br><span class="line"><span class="comment"># 拟合，创建多项式特征</span></span><br><span class="line">pf.fit(df)</span><br><span class="line"><span class="comment"># 转换数据</span></span><br><span class="line">poly_feats = pf.transform(df)</span><br><span class="line"><span class="comment"># 获取生成的多项式特征的数量</span></span><br><span class="line">num_feats = poly_feats.shape[<span class="number">1</span>]</span><br><span class="line"><span class="comment"># 为新生成的特征命名</span></span><br><span class="line">df_transformed = pd.DataFrame(poly_feats,columns=[<span class="string">f&quot;f_<span class="subst">&#123;i&#125;</span>&quot;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, num_feats + <span class="number">1</span>)] )</span><br></pre></td></tr></table></figure><p>这样就得到了一个数据表，如图 4 所示。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page147_image.png" alt=""></p><p align="center"><b>图 4：带有多项式特征的样本数据表</b> </p><p>现在，我们创建了一些多项式特征。如果创建的是三次多项式特征，最终总共会有九个特征。特征的数量越多，多项式特征的数量也就越多，而且你还必须记住，如果数据集中有很多样本，那么创建这类特征就需要花费一些时间。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page148_image.png" alt=""></p><p align="center"><b>图 5：数字特征列的直方图</b> </p><p>另一个有趣的功能是将数字转换为类别。这就是所谓的<strong>分箱</strong>。让我们看一下图 5，它显示了一个随机数字特征的样本直方图。我们在该图中使用了 10 个分箱，可以看到我们可以将数据分为 10 个部分。这可以使用 pandas 的 cat 函数来实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建10个分箱</span></span><br><span class="line">df[<span class="string">&quot;f_bin_10&quot;</span>] = pd.cut(df[<span class="string">&quot;f_1&quot;</span>], bins=<span class="number">10</span>, labels=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 创建100个分箱</span></span><br><span class="line">df[<span class="string">&quot;f_bin_100&quot;</span>] = pd.cut(df[<span class="string">&quot;f_1&quot;</span>], bins=<span class="number">100</span>, labels=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>如图 6 所示，这将在数据帧中生成两个新特征。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page148_image_1.png" alt=""></p><p align="center"><b>图 6：数值特征分箱</b> </p><p>当你进行分类时，可以同时使用分箱和原始特征。我们将在本章后半部分学习更多关于选择特征的知识。分箱还可以将数字特征视为分类特征。</p><p>另一种可以从数值特征中创建的有趣特征类型是对数变换。请看图 7 中的特征 f_3。</p><p>与其他方差较小的特征相比（假设如此），f_3 是一种方差非常大的特殊特征。因此，我们希望降低这一列的方差，这可以通过对数变换来实现。</p><p>f_3 列的值范围为 0 到 10000，直方图如图 8 所示。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page149_image_2.png" alt=""></p><p align="center"><b>图 8：特征 f_3 的直方图</b> </p><p>我们可以对这一列应用 log(1 + x) 来减少其方差。图 9 显示了应用对数变换后直方图的变化。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page150_image.png" alt=""></p><p align="center"><b>图 9：应用对数变换后的 f_3 直方图</b> </p><p>让我们来看看不使用对数变换和使用对数变换的方差。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [X]: df.f_3.var()</span><br><span class="line">Out[X]: <span class="number">8077265.875858586</span></span><br><span class="line">In [X]: df.f_3.apply(<span class="keyword">lambda</span> x: np.log(<span class="number">1</span> + x)).var()</span><br><span class="line">Out[X]: <span class="number">0.6058771732119975</span></span><br></pre></td></tr></table></figure><p>有时，也可以用指数来代替对数。一种非常有趣的情况是，您使用基于对数的评估指标，例如 RMSLE。在这种情况下，您可以在对数变换的目标上进行训练，然后在预测时使用指数值转换回原始值。这将有助于针对指标优化模型。</p><p>大多数情况下，这类数字特征都是基于直觉创建的。没有公式可循。如果您从事的是某一行业，您将创建特定行业的特征。</p><p>在处理分类变量和数值变量时，可能会遇到缺失值。在上一章中，我们介绍了一些处理分类特征中缺失值的方法，但还有更多方法可以处理缺失值/NaN 值。这也被视为特征工程。</p><p>如果在分类特征中遇到缺失值，就将其视为一个新的类别！这样做虽然简单，但（几乎）总是有效的！</p><p>在数值数据中填补缺失值的一种方法是选择一个在特定特征中没有出现的值，然后用它来填补。例如，假设特征中没有 0。这是其中一种方法，但可能不是最有效的。对于数值数据来说，比填充 0 更有效的方法之一是使用平均值进行填充。您也可以尝试使用该特征所有值的中位数来填充，或者使用最常见的值来填充缺失值。这样做的方法有很多。</p><p>填补缺失值的一种高级方法是使用 <strong>K 近邻法</strong>。 您可以选择一个有缺失值的样本，然后利用某种距离度量（例如欧氏距离）找到最近的邻居。然后取所有近邻的平均值来填补缺失值。您可以使用 KNN 来填补这样的缺失值。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page151_image.png" alt=""></p><p align="center"><b>图 10：有缺失值的二维数组</b> </p><p>让我们看看 KNN 是如何处理图 10 所示的缺失值矩阵的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> impute</span><br><span class="line"><span class="comment"># 生成维度为 (10, 6) 的随机整数矩阵 X，数值范围在 1 到 14 之间</span></span><br><span class="line">X = np.random.randint(<span class="number">1</span>, <span class="number">15</span>, (<span class="number">10</span>, <span class="number">6</span>))</span><br><span class="line"><span class="comment"># 数据类型转换为 float</span></span><br><span class="line">X = X.astype(<span class="built_in">float</span>)</span><br><span class="line"><span class="comment"># 在矩阵 X 中随机选择 10 个位置，将这些位置的元素设置为 NaN（缺失值）</span></span><br><span class="line">X.ravel()[np.random.choice(X.size, <span class="number">10</span>, replace=<span class="literal">False</span>)] = np.nan</span><br><span class="line"><span class="comment"># 创建一个 KNNImputer 对象 knn_imputer，指定邻居数量为 2</span></span><br><span class="line">knn_imputer = impute.KNNImputer(n_neighbors=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># # 使用 knn_imputer 对矩阵 X 进行拟合和转换，用 K-最近邻方法填补缺失值</span></span><br><span class="line">knn_imputer.fit_transform(X)</span><br></pre></td></tr></table></figure><p>如图 11 所示，它填充了上述矩阵。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page152_image.png" alt=""></p><p align="center"><b>图 11：KNN估算的数值</b> </p><p>另一种弥补列缺失值的方法是训练回归模型，试图根据其他列预测某列的缺失值。因此，您可以从有缺失值的一列开始，将这一列作为无缺失值回归模型的目标列。现在，您可以使用所有其他列，对相关列中没有缺失值的样本进行模型训练，然后尝试预测之前删除的样本的目标列（同一列）。这样，基于模型的估算就会更加稳健。</p><p>请务必记住，对于基于树的模型，没有必要进行数值归一化，因为它们可以自行处理。</p><p>到目前为止，我所展示的只是创建一般特征的一些方法。现在，假设您正在处理一个预测不同商品（每周或每月）商店销售额的问题。您有商品，也有商店 ID。因此，您可以创建每个商店的商品等特征。现在，这是上文没有讨论的特征之一。这类特征不能一概而论，完全来自于领域、数据和业务知识。查看数据，找出适合的特征，然后创建相应的特征。如果您使用的是逻辑回归等线性模型或 SVM 等模型，请务必记住对特征进行缩放或归一化处理。基于树的模型无需对特征进行任何归一化处理即可正常工作。</p>]]></content>
      
      
      <categories>
          
          <category> AAAMLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>特征选择</title>
      <link href="/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/"/>
      <url>/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9/</url>
      
        <content type="html"><![CDATA[<h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><p>当你创建了成千上万个特征后，就该从中挑选出几个了。但是，我们绝不应该创建成百上千个无用的特征。特征过多会带来一个众所周知的问题，即 “维度诅咒”。如果你有很多特征，你也必须有很多训练样本来捕捉所有特征。什么是 “大量 “并没有正确的定义，这需要您通过正确验证您的模型和检查训练模型所需的时间来确定。</p><p>选择特征的最简单方法是<strong>删除方差非常小的特征</strong>。如果特征的方差非常小（即非常接近于 0），它们就接近于常量，因此根本不会给任何模型增加任何价值。最好的办法就是去掉它们，从而降低复杂度。请注意，方差也取决于数据的缩放。 Scikit-learn 的 VarianceThreshold 实现了这一点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line">data = ...</span><br><span class="line"><span class="comment"># 创建 VarianceThreshold 对象 var_thresh，指定方差阈值为 0.1</span></span><br><span class="line">var_thresh = VarianceThreshold(threshold=<span class="number">0.1</span>)</span><br><span class="line"><span class="comment"># 使用 var_thresh 对数据 data 进行拟合和变换，将方差低于阈值的特征移除</span></span><br><span class="line">transformed_data = var_thresh.fit_transform(data)</span><br></pre></td></tr></table></figure><p>我们还可以删除相关性较高的特征。要计算不同数字特征之间的相关性，可以使用皮尔逊相关性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_california_housing</span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">data = fetch_california_housing()</span><br><span class="line"><span class="comment"># 从数据集中提取特征矩阵 X</span></span><br><span class="line">X = data[<span class="string">&quot;data&quot;</span>]</span><br><span class="line"><span class="comment"># 从数据集中提取特征的列名</span></span><br><span class="line">col_names = data[<span class="string">&quot;feature_names&quot;</span>]</span><br><span class="line"><span class="comment"># 从数据集中提取目标变量 y</span></span><br><span class="line">y = data[<span class="string">&quot;target&quot;</span>]</span><br><span class="line">df = pd.DataFrame(X, columns=col_names)</span><br><span class="line"><span class="comment"># 添加 MedInc_Sqrt 列，是 MedInc 列中每个元素进行平方根运算的结果</span></span><br><span class="line">df.loc[:, <span class="string">&quot;MedInc_Sqrt&quot;</span>] = df.MedInc.apply(np.sqrt)</span><br><span class="line"><span class="comment"># 计算皮尔逊相关性矩阵</span></span><br><span class="line">df.corr()</span><br></pre></td></tr></table></figure><p>得出相关矩阵，如图 1 所示。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page155_image.png" alt=""></p><p align="center"><b>图 1：皮尔逊相关矩阵样本</b> </p><p>我们看到，MedInc_Sqrt 与 MedInc 的相关性非常高。因此，我们可以删除其中一个特征。</p><p>现在我们可以转向一些<strong>单变量特征选择方法</strong>。单变量特征选择只不过是针对给定目标对每个特征进行评分。<strong>互信息</strong>、<strong>方差分析 F 检验和 chi2</strong> 是一些最常用的单变量特征选择方法。在 scikit- learn 中，有两种方法可以使用这些方法。</p><ul><li>SelectKBest：保留得分最高的 k 个特征</li><li>SelectPercentile：保留用户指定百分比内的顶级特征。</li></ul><p>必须注意的是，只有非负数据才能使用 chi2。在自然语言处理中，当我们有一些单词或基于 tf-idf 的特征时，这是一种特别有用的特征选择技术。最好为单变量特征选择创建一个包装器，几乎可以用于任何新问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> chi2</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> f_classif</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> f_regression</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> mutual_info_classif</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> mutual_info_regression</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectKBest</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectPercentile</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">UnivariateFeatureSelction</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_features, problem_type, scoring</span>):</span><br><span class="line">        <span class="comment"># 若问题类型是分类问题</span></span><br><span class="line">        <span class="keyword">if</span> problem_type == <span class="string">&quot;classification&quot;</span>:</span><br><span class="line">            <span class="comment"># 创建字典 valid_scoring ，包含各种特征重要性衡量方式</span></span><br><span class="line">            valid_scoring = &#123;</span><br><span class="line">                <span class="string">&quot;f_classif&quot;</span>: f_classif,</span><br><span class="line">                <span class="string">&quot;chi2&quot;</span>: chi2,</span><br><span class="line">                <span class="string">&quot;mutual_info_classif&quot;</span>: mutual_info_classif</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="comment"># 若问题类型是回归问题</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 创建字典 valid_scoring，包含各种特征重要性衡量方式</span></span><br><span class="line">            valid_scoring = &#123;</span><br><span class="line">                <span class="string">&quot;f_regression&quot;</span>: f_regression,</span><br><span class="line">                <span class="string">&quot;mutual_info_regression&quot;</span>: mutual_info_regression</span><br><span class="line">            &#125;</span><br><span class="line">        <span class="comment"># 检查特征重要性方式是否在字典中</span></span><br><span class="line"><span class="keyword">if</span> scoring <span class="keyword">not</span> <span class="keyword">in</span> valid_scoring:</span><br><span class="line">            <span class="keyword">raise</span> Exception(<span class="string">&quot;Invalid scoring function&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 检查 n_features 的类型，如果是整数，则使用 SelectKBest 进行特征选择</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">isinstance</span>(n_features, <span class="built_in">int</span>):</span><br><span class="line">            self.selection = SelectKBest(</span><br><span class="line">                valid_scoring[scoring],</span><br><span class="line">                k=n_features</span><br><span class="line">            )</span><br><span class="line">        <span class="comment"># 如果 n_features 是浮点数，则使用 SelectPercentile 进行特征选择</span></span><br><span class="line"><span class="keyword">elif</span> <span class="built_in">isinstance</span>(n_features, <span class="built_in">float</span>):</span><br><span class="line">self.selection = SelectPercentile(</span><br><span class="line">                valid_scoring[scoring],</span><br><span class="line">                percentile=<span class="built_in">int</span>(n_features * <span class="number">100</span>)</span><br><span class="line">            )</span><br><span class="line">        <span class="comment"># 如果 n_features 类型无效，引发异常</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line"><span class="keyword">raise</span> Exception(<span class="string">&quot;Invalid type of feature&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义 fit 方法，用于拟合特征选择器</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">self, X, y</span>):</span><br><span class="line"><span class="keyword">return</span> self.selection.fit(X, y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义 transform 方法，用于对数据进行特征选择转换</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">transform</span>(<span class="params">self, X</span>):</span><br><span class="line"><span class="keyword">return</span> self.selection.transform(X)</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 定义 fit_transform 方法，用于拟合特征选择器并同时进行特征选择转换</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fit_transform</span>(<span class="params">self, X, y</span>):</span><br><span class="line"><span class="keyword">return</span> self.selection.fit_transform(X, y)</span><br></pre></td></tr></table></figure><p>使用该类非常简单。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实例化特征选择器，保留前10%的特征，回归问题，使用f_regression衡量特征重要性</span></span><br><span class="line">ufs = UnivariateFeatureSelction(n_features=<span class="number">0.1</span>,</span><br><span class="line">                                problem_type=<span class="string">&quot;regression&quot;</span>,</span><br><span class="line">                                scoring=<span class="string">&quot;f_regression&quot;</span></span><br><span class="line">                               )</span><br><span class="line"><span class="comment"># 拟合特征选择器</span></span><br><span class="line">ufs.fit(X, y)</span><br><span class="line"><span class="comment"># 特征转换</span></span><br><span class="line">X_transformed = ufs.transform(X)</span><br></pre></td></tr></table></figure><p>这样就能满足大部分单变量特征选择的需求。请注意，创建较少而重要的特征通常比创建数以百计的特征要好。单变量特征选择不一定总是表现良好。大多数情况下，人们更喜欢使用机器学习模型进行特征选择。让我们来看看如何做到这一点。</p><p>使用模型进行特征选择的最简单形式被称为贪婪特征选择。在贪婪特征选择中，第一步是选择一个模型。第二步是选择损失/评分函数。第三步也是最后一步是反复评估每个特征，如果能提高损失/评分，就将其添加到 “好 “特征列表中。没有比这更简单的了。但你必须记住，这被称为贪婪特征选择是有原因的。这种特征选择过程在每次评估特征时都会适合给定的模型。这种方法的计算成本非常高。完成这种特征选择也需要大量时间。如果不正确使用这种特征选择，甚至会导致模型过度拟合。</p><p>让我们来看看它是如何实现的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_classification</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GreedyFeatureSelection</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义评估分数的方法，用于评估模型性能</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">evaluate_score</span>(<span class="params">self, X, y</span>):</span><br><span class="line">        <span class="comment"># 逻辑回归模型</span></span><br><span class="line">        model = linear_model.LogisticRegression()</span><br><span class="line">        <span class="comment"># 训练模型</span></span><br><span class="line">        model.fit(X, y)</span><br><span class="line">        <span class="comment"># 预测概率值</span></span><br><span class="line">        predictions = model.predict_proba(X)[:, <span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 计算 AUC 分数</span></span><br><span class="line">        auc = metrics.roc_auc_score(y, predictions)</span><br><span class="line">        <span class="keyword">return</span> auc</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 特征选择函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_feature_selection</span>(<span class="params">self, X, y</span>):</span><br><span class="line">        <span class="comment"># 初始化空列表，用于存储最佳特征和最佳分数</span></span><br><span class="line">        good_features = []</span><br><span class="line">        best_scores = []</span><br><span class="line">        <span class="comment"># 获取特征数量</span></span><br><span class="line">        num_features = X.shape[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 开始特征选择的循环</span></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            this_feature = <span class="literal">None</span></span><br><span class="line">            best_score = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 遍历每个特征</span></span><br><span class="line">            <span class="keyword">for</span> feature <span class="keyword">in</span> <span class="built_in">range</span>(num_features):</span><br><span class="line">                <span class="keyword">if</span> feature <span class="keyword">in</span> good_features:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                selected_features = good_features + [feature]</span><br><span class="line">                xtrain = X[:, selected_features]</span><br><span class="line">                score = self.evaluate_score(xtrain, y)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 如果当前特征的得分优于之前的最佳得分，则更新</span></span><br><span class="line">                <span class="keyword">if</span> score &gt; best_score:</span><br><span class="line">                    this_feature = feature</span><br><span class="line">                    best_score = score</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 若找到了新的最佳特征</span></span><br><span class="line">            <span class="keyword">if</span> this_feature != <span class="literal">None</span>:</span><br><span class="line">                <span class="comment"># 特征添加到 good_features 列表</span></span><br><span class="line">                good_features.append(this_feature)</span><br><span class="line">                <span class="comment"># 得分添加到 best_scores 列表</span></span><br><span class="line">                best_scores.append(best_score)</span><br><span class="line">            <span class="comment"># 如果 best_scores 列表长度大于2，并且最后两个得分相比较差，则结束循环</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(best_scores) &gt; <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">if</span> best_scores[-<span class="number">1</span>] &lt; best_scores[-<span class="number">2</span>]:</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># 返回最佳特征的得分列表和最佳特征列表</span></span><br><span class="line"><span class="keyword">return</span> best_scores[:-<span class="number">1</span>], good_features[:-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义类的调用方法，用于执行特征选择</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, X, y</span>):</span><br><span class="line">        scores, features = self._feature_selection(X, y)</span><br><span class="line">        <span class="keyword">return</span> X[:, features], scores</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 生成一个示例的分类数据集 X 和标签 y</span></span><br><span class="line">    X, y = make_classification(n_samples=<span class="number">1000</span>, n_features=<span class="number">100</span>)</span><br><span class="line">    <span class="comment"># 实例化 GreedyFeatureSelection 类，并使用 __call__ 方法进行特征选择</span></span><br><span class="line">    X_transformed, scores = GreedyFeatureSelection()(X, y)</span><br></pre></td></tr></table></figure><p>这种贪婪特征选择方法会返回分数和特征索引列表。图 2 显示了在每次迭代中增加一个新特征后，分数是如何提高的。我们可以看到，在某一点之后，我们就无法提高分数了，这就是我们停止的地方。</p><p>另一种贪婪的方法被称为递归特征消除法（RFE）。在前一种方法中，我们从一个特征开始，然后不断添加新的特征，但在 RFE 中，我们从所有特征开始，在每次迭代中不断去除一个对给定模型提供最小值的特征。但我们如何知道哪个特征的价值最小呢？如果我们使用线性支持向量机（SVM）或逻辑回归等模型，我们会为每个特征得到一个系数，该系数决定了特征的重要性。而对于任何基于树的模型，我们得到的是特征重要性，而不是系数。在每次迭代中，我们都可以剔除最不重要的特征，直到达到所需的特征数量为止。因此，我们可以决定要保留多少特征。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page161_image.png" alt=""></p><p align="center"><b>图 2：增加新特征后，贪婪特征选择的 AUC 分数如何变化</b> </p><p>当我们进行递归特征剔除时，在每次迭代中，我们都会剔除特征重要性较高的特征或系数接近 0 的特征。请记住，当你使用逻辑回归这样的模型进行二元分类时，如果特征对正分类很重要，其系数就会更正，而如果特征对负分类很重要，其系数就会更负。修改我们的贪婪特征选择类，创建一个新的递归特征消除类非常容易，但 scikit-learn 也提供了 RFE。下面的示例展示了一个简单的用法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFE</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> fetch_california_housing</span><br><span class="line">data = fetch_california_housing()</span><br><span class="line">X = data[<span class="string">&quot;data&quot;</span>]</span><br><span class="line">col_names = data[<span class="string">&quot;feature_names&quot;</span>]</span><br><span class="line">y = data[<span class="string">&quot;target&quot;</span>]</span><br><span class="line">model = LinearRegression()</span><br><span class="line"><span class="comment"># 创建 RFE（递归特征消除），指定模型为线性回归模型，要选择的特征数量为 3</span></span><br><span class="line">rfe = RFE(</span><br><span class="line">    estimator=model,</span><br><span class="line">    n_features_to_select=<span class="number">3</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">rfe.fit(X, y)</span><br><span class="line"><span class="comment"># 使用 RFE 选择的特征进行数据转换</span></span><br><span class="line">X_transformed = rfe.transform(X)</span><br></pre></td></tr></table></figure><p>我们看到了从模型中选择特征的两种不同的贪婪方法。但也可以根据数据拟合模型，然后通过特征系数或特征的重要性从模型中选择特征。如果使用系数，则可以选择一个阈值，如果系数高于该阈值，则可以保留该特征，否则将其剔除。</p><p>让我们看看如何从随机森林这样的模型中获取特征重要性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_diabetes</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line">data = load_diabetes()</span><br><span class="line">X = data[<span class="string">&quot;data&quot;</span>]</span><br><span class="line">col_names = data[<span class="string">&quot;feature_names&quot;</span>]</span><br><span class="line">y = data[<span class="string">&quot;target&quot;</span>]</span><br><span class="line"><span class="comment"># 实例化随机森林模型</span></span><br><span class="line">model = RandomForestRegressor()</span><br><span class="line"><span class="comment"># 拟合模型</span></span><br><span class="line">model.fit(X, y)</span><br></pre></td></tr></table></figure><p>随机森林（或任何模型）的特征重要性可按如下方式绘制。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取特征重要性</span></span><br><span class="line">importances = model.feature_importances_</span><br><span class="line"><span class="comment"># 降序排列</span></span><br><span class="line">idxs = np.argsort(importances)</span><br><span class="line"><span class="comment"># 设定标题</span></span><br><span class="line">plt.title(<span class="string">&#x27;Feature Importances&#x27;</span>)</span><br><span class="line"><span class="comment"># 创建直方图</span></span><br><span class="line">plt.barh(<span class="built_in">range</span>(<span class="built_in">len</span>(idxs)), importances[idxs], align=<span class="string">&#x27;center&#x27;</span>)</span><br><span class="line"><span class="comment"># y轴标签</span></span><br><span class="line">plt.yticks(<span class="built_in">range</span>(<span class="built_in">len</span>(idxs)), [col_names[i] <span class="keyword">for</span> i <span class="keyword">in</span> idxs])</span><br><span class="line"><span class="comment"># x轴标签</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Random Forest Feature Importance&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p>结果如图 3 所示。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page163_image.png" alt=""></p><p align="center"><b>图 3：特征重要性图</b> </p><p>从模型中选择最佳特征并不是什么新鲜事。您可以从一个模型中选择特征，然后使用另一个模型进行训练。例如，你可以使用逻辑回归系数来选择特征，然后使用随机森林（Random Forest）对所选特征进行模型训练。Scikit-learn 还提供了 SelectFromModel 类，可以帮助你直接从给定的模型中选择特征。您还可以根据需要指定系数或特征重要性的阈值，以及要选择的特征的最大数量。</p><p>请看下面的代码段，我们使用 SelectFromModel 中的默认参数来选择特征。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_diabetes</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> SelectFromModel</span><br><span class="line">data = load_diabetes()</span><br><span class="line">X = data[<span class="string">&quot;data&quot;</span>]</span><br><span class="line">col_names = data[<span class="string">&quot;feature_names&quot;</span>]</span><br><span class="line">y = data[<span class="string">&quot;target&quot;</span>]</span><br><span class="line"><span class="comment"># 创建随机森林模型回归模型</span></span><br><span class="line">model = RandomForestRegressor()</span><br><span class="line"><span class="comment"># 创建 SelectFromModel 对象 sfm，使用随机森林模型作为估算器</span></span><br><span class="line">sfm = SelectFromModel(estimator=model)</span><br><span class="line"><span class="comment"># 使用 sfm 对特征矩阵 X 和目标变量 y 进行特征选择</span></span><br><span class="line">X_transformed = sfm.fit_transform(X, y)</span><br><span class="line"><span class="comment"># 获取经过特征选择后的特征掩码（True 表示特征被选择，False 表示特征未被选择）</span></span><br><span class="line">support = sfm.get_support()</span><br><span class="line"><span class="comment"># 打印被选择的特征列名</span></span><br><span class="line"><span class="built_in">print</span>([x <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(col_names, support) <span class="keyword">if</span> y == <span class="literal">True</span> ])</span><br></pre></td></tr></table></figure><p>上面程序打印结果： [‘bmi’，’s5’]。我们再看图 3，就会发现这是最重要的两个特征。因此，我们也可以直接从随机森林提供的特征重要性中进行选择。我们还缺少一件事，那就是使用 <strong>L1（Lasso）惩罚模型</strong>进行特征选择。当我们使用 L1 惩罚进行正则化时，大部分系数都将为 0（或接近 0），因此我们要选择系数不为 0 的特征。只需将模型选择片段中的随机森林替换为支持 L1 惩罚的模型（如 lasso 回归）即可。所有基于树的模型都提供特征重要性，因此本章中展示的所有基于模型的片段都可用于 XGBoost、LightGBM 或 CatBoost。特征重要性函数的名称可能不同，产生结果的格式也可能不同，但用法是一样的。最后，在进行特征选择时必须小心谨慎。在训练数据上选择特征，并在验证数据上验证模型，以便在不过度拟合模型的情况下正确选择特征。</p>]]></content>
      
      
      <categories>
          
          <category> AAAMLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>组织机器学习项目</title>
      <link href="/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E7%BB%84%E7%BB%87%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE/"/>
      <url>/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E7%BB%84%E7%BB%87%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE/</url>
      
        <content type="html"><![CDATA[<h1 id="组织机器学习项目"><a href="#组织机器学习项目" class="headerlink" title="组织机器学习项目"></a>组织机器学习项目</h1><p>终于，我们可以开始构建第一个机器学习模型了。</p><p>是这样吗？</p><p>在开始之前，我们必须注意几件事。请记住，我们将在集成开发环境/文本编辑器中工作，而不是在 jupyter notebook 中。你也可以在 jupyter notebook 中工作，这完全取决于你。不过，我将只使用 jupyter notebook 来探索数据、绘制图表和图形。我们将以这样一种方式构建分类框架，即插即用。您无需对代码做太多改动就能训练模型，而且当您改进模型时，还能使用 git 对其进行跟踪。</p><p>我们首先来看看文件的结构。对于你正在做的任何项目，都要创建一个新文件夹。在本例中，我将项目命名为 “project”。</p><p>项目文件夹内部应该如下所示。</p><ul><li>input<ul><li>train.csv</li><li>test.csv</li></ul></li><li>src<ul><li>create_folds.py</li><li>train.py</li><li>inference.py</li><li>models.py</li><li>config.py</li><li>model_dispatcher.py</li></ul></li><li>models<ul><li>model_rf.bin</li><li>model_et.bin</li></ul></li><li>notebooks<ul><li>exploration.ipynb</li><li>check_data.ipynb</li></ul></li><li>README.md</li><li>LICENSE</li></ul><p>让我们来看看这些文件夹和文件的内容。</p><p><em>input/</em>：该文件夹包含机器学习项目的所有输入文件和数据。如果您正在开发 NLP 项目，您可以将 embeddings 放在这里。如果是图像项目，所有图像都放在该文件夹下的子文件夹中。</p><p><em>src/</em>：我们将在这里保存与项目相关的所有 python 脚本。如果我说的是一个 python 脚本，即任何 *.py 文件，它都存储在 src 文件夹中。</p><p><em>models/</em>：该文件夹保存所有训练过的模型。</p><p><em>notebook/</em>：所有 jupyter notebook（即任何 *.ipynb 文件）都存储在笔记本 文件夹中。</p><p><em>README.md</em>：这是一个标记符文件，您可以在其中描述您的项目，并写明如何训练模型或在生产环境中使用。</p><p><em>LICENSE</em>：这是一个简单的文本文件，包含项目的许可证，如 MIT、Apache 等。关于许可证的详细介绍超出了本书的范围。</p><p>假设你正在建立一个模型来对 MNIST 数据集（几乎每本机器学习书籍都会用到的数据集）进行分类。如果你还记得，我们在交叉检验一章中也提到过 MNIST 数据集。所以，我就不解释这个数据集是什么样子了。网上有许多不同格式的 MNIST 数据集，但我们将使用 CSV 格式的数据集。</p><p>在这种格式的数据集中，CSV 的每一行都包含图像的标签和 784 个像素值，像素值范围从 0 到 255。数据集包含 60000 张这种格式的图像。</p><p>我们可以使用 pandas 轻松读取这种数据格式。</p><p>请注意，尽管图 1 显示所有像素值均为零，但事实并非如此。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page74_image.png" alt=""></p><p align="center"><b>图 1：CSV格式的 MNIST 数据集</b> </p><p>让我们来看看这个数据集中标签列的计数。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page74_image_1.png" alt=""></p><p align="center"><b>图 2：MNIST 数据集中的标签计数</b> </p><p>我们不需要对这个数据集进行更多的探索。我们已经知道了我们所拥有的数据，没有必要再对不同的像素值进行绘图。从图 2 中可以清楚地看出，标签的分布相当均匀。因此，我们可以使用准确率/F1 作为衡量标准。这就是处理机器学习问题的第一步：确定衡量标准！</p><p>现在，我们可以编写一些代码了。我们需要创建 <em>src/</em> 文件夹和一些 python 脚本。</p><p>请注意，训练 CSV 文件位于 <em>input/</em> 文件夹中，名为 <em>mnist_train.csv</em>。</p><p>对于这样一个项目，这些文件应该是什么样的呢？</p><p>首先要创建的脚本是 <strong>create_folds.py</strong>。</p><p>这将在 <em>input/</em> 文件夹中创建一个名为 <em>mnist_train_folds.csv</em> 的新文件，与 <em>mnist_train.csv</em> 相同。唯一不同的是，这个 CSV 文件经过了随机排序，并新增了一列名为 <em>kfold</em> 的内容。</p><p>一旦我们决定了要使用哪种评估指标并创建了折叠，就可以开始创建基本模型了。这可以在 train.py 中完成。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    <span class="comment"># 读取数据文件</span></span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/mnist_train_folds.csv&quot;</span>)</span><br><span class="line">    <span class="comment"># 选取df中kfold列不等于fold</span></span><br><span class="line">    df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 选取df中kfold列等于fold</span></span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 训练集输入，删除label列</span></span><br><span class="line">    x_train = df_train.drop(<span class="string">&quot;label&quot;</span>, axis=<span class="number">1</span>).values</span><br><span class="line">    <span class="comment"># 训练集输出，取label列</span></span><br><span class="line">    y_train = df_train.label.values</span><br><span class="line">    <span class="comment"># 验证集输入，删除label列</span></span><br><span class="line">    x_valid = df_valid.drop(<span class="string">&quot;label&quot;</span>, axis=<span class="number">1</span>).values</span><br><span class="line">    <span class="comment"># 验证集输出，取label列</span></span><br><span class="line">    y_valid = df_valid.label.values</span><br><span class="line">    <span class="comment"># 实例化决策树模型</span></span><br><span class="line">    clf = tree.DecisionTreeClassifier()</span><br><span class="line">    <span class="comment"># 使用训练集训练模型</span></span><br><span class="line">    clf.fit(x_train, y_train)</span><br><span class="line">    <span class="comment"># 使用验证集输入得到预测结果</span></span><br><span class="line">    preds = clf.predict(x_valid)</span><br><span class="line">    <span class="comment"># 计算验证集准确率</span></span><br><span class="line">    accuracy = metrics.accuracy_score(y_valid, preds)</span><br><span class="line">    <span class="comment"># 打印fold信息和准确率</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold=<span class="subst">&#123;fold&#125;</span>, Accuracy=<span class="subst">&#123;accuracy&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="comment"># 保存模型</span></span><br><span class="line">    joblib.dump(clf, <span class="string">f&quot;../models/dt_<span class="subst">&#123;fold&#125;</span>.bin&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 运行每个折叠</span></span><br><span class="line">run(fold=<span class="number">0</span>)</span><br><span class="line">run(fold=<span class="number">1</span>)</span><br><span class="line">run(fold=<span class="number">2</span>)</span><br><span class="line">run(fold=<span class="number">3</span>)</span><br><span class="line">run(fold=<span class="number">4</span>)</span><br></pre></td></tr></table></figure><p>您可以在控制台调用 python train.py 运行该脚本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ python train.py</span><br><span class="line">Fold=<span class="number">0</span>, Accuracy=<span class="number">0.8680833333333333</span></span><br><span class="line">Fold=<span class="number">1</span>, Accuracy=<span class="number">0.8685</span></span><br><span class="line">Fold=<span class="number">2</span>, Accuracy=<span class="number">0.8674166666666666</span></span><br><span class="line">Fold=<span class="number">3</span>, Accuracy=<span class="number">0.8703333333333333</span></span><br><span class="line">Fold=<span class="number">4</span>, Accuracy=<span class="number">0.8699166666666667</span></span><br></pre></td></tr></table></figure><p>查看训练脚本时，您会发现还有一些内容是硬编码的，例如折叠数、训练文件和输出文件夹。</p><p>因此，我们可以创建一个包含所有这些信息的配置文件：<strong>config.py</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">TRAINING_FILE = <span class="string">&quot;../input/mnist_train_folds.csv&quot;</span></span><br><span class="line">MODEL_OUTPUT = <span class="string">&quot;../models/&quot;</span></span><br></pre></td></tr></table></figure><p>我们还对训练脚本进行了一些修改。训练文件现在使用配置文件。这样，更改数据或模型输出就更容易了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> config</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold</span>):</span><br><span class="line">    <span class="comment"># 使用config中的路径读取数据</span></span><br><span class="line">    df = pd.read_csv(config.TRAINING_FILE)</span><br><span class="line">    df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    x_train = df_train.drop(<span class="string">&quot;label&quot;</span>, axis=<span class="number">1</span>).values</span><br><span class="line">    y_train = df_train.label.values</span><br><span class="line">    x_valid = df_valid.drop(<span class="string">&quot;label&quot;</span>, axis=<span class="number">1</span>).values</span><br><span class="line">    y_valid = df_valid.label.values</span><br><span class="line">    clf = tree.DecisionTreeClassifier()</span><br><span class="line">    clf.fit(x_train, y_train)</span><br><span class="line">    preds = clf.predict(x_valid)</span><br><span class="line">    accuracy = metrics.accuracy_score(y_valid, preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold=<span class="subst">&#123;fold&#125;</span>, Accuracy=<span class="subst">&#123;accuracy&#125;</span>&quot;</span>)</span><br><span class="line">    joblib.dump(clf,os.path.join(config.MODEL_OUTPUT, <span class="string">f&quot;dt_<span class="subst">&#123;fold&#125;</span>.bin&quot;</span>) )</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 运行每个折叠</span></span><br><span class="line">run(fold=<span class="number">0</span>)</span><br><span class="line">run(fold=<span class="number">1</span>)</span><br><span class="line">run(fold=<span class="number">2</span>)</span><br><span class="line">run(fold=<span class="number">3</span>)</span><br><span class="line">run(fold=<span class="number">4</span>)</span><br></pre></td></tr></table></figure><p>请注意，我并没有展示这个培训脚本与之前脚本的区别。请仔细阅读这两个脚本，自己找出不同之处。区别并不多。</p><p>与训练脚本相关的还有一点可以改进。正如你所看到的，我们为每个折叠多次调用运行函数。有时，在同一个脚本中运行多个折叠并不可取，因为内存消耗可能会不断增加，程序可能会崩溃。为了解决这个问题，我们可以向训练脚本传递参数。我喜欢使用 argparse。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 实例化参数环境</span></span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    <span class="comment"># fold参数</span></span><br><span class="line">    parser.add_argument( <span class="string">&quot;--fold&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">    <span class="comment"># 读取参数</span></span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    run(fold=args.fold)</span><br></pre></td></tr></table></figure><p>现在，我们可以再次运行 python 脚本，但仅限于给定的折叠。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">❯ python train.py --fold <span class="number">0</span></span><br><span class="line">Fold=<span class="number">0</span>, Accuracy=<span class="number">0.8656666666666667</span></span><br></pre></td></tr></table></figure><p>仔细观察，我们的第 0 折得分与之前有些不同。这是因为模型中存在随机性。我们将在后面的章节中讨论如何处理随机性。</p><p>现在，如果你愿意，可以创建一个 <strong>shell 脚本</strong>，针对不同的折叠使用不同的命令，然后一起运行，如下图所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python train.py --fold <span class="number">0</span></span><br><span class="line">python train.py --fold <span class="number">1</span></span><br><span class="line">python train.py --fold <span class="number">2</span></span><br><span class="line">python train.py --fold <span class="number">3</span></span><br><span class="line">python train.py --fold <span class="number">4</span></span><br></pre></td></tr></table></figure><p>您可以通过以下命令运行它。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ sh run.sh</span><br><span class="line">Fold=<span class="number">0</span>, Accuracy=<span class="number">0.8675</span></span><br><span class="line">Fold=<span class="number">1</span>, Accuracy=<span class="number">0.8693333333333333</span></span><br><span class="line">Fold=<span class="number">2</span>, Accuracy=<span class="number">0.8683333333333333</span></span><br><span class="line">Fold=<span class="number">3</span>, Accuracy=<span class="number">0.8704166666666666</span></span><br><span class="line">Fold=<span class="number">4</span>, Accuracy=<span class="number">0.8685</span></span><br></pre></td></tr></table></figure><p>我们现在已经取得了一些进展，但如果我们看一下我们的训练脚本，我们仍然受到一些东西的限制，例如模型。模型是硬编码在训练脚本中的，只有修改脚本才能改变它。因此，我们将创建一个新的 python 脚本，名为 <strong>model_dispatcher.py</strong>。model_dispatcher.py，顾名思义，将调度我们的模型到训练脚本中。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line">models = &#123;</span><br><span class="line">    <span class="comment"># 以gini系数度量的决策树</span></span><br><span class="line">    <span class="string">&quot;decision_tree_gini&quot;</span>: tree.DecisionTreeClassifier(</span><br><span class="line">        criterion=<span class="string">&quot;gini&quot;</span></span><br><span class="line">    ),</span><br><span class="line">    <span class="comment"># 以entropy系数度量的决策树</span></span><br><span class="line">    <span class="string">&quot;decision_tree_entropy&quot;</span>: tree.DecisionTreeClassifier(</span><br><span class="line">        criterion=<span class="string">&quot;entropy&quot;</span></span><br><span class="line">    ),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>model_dispatcher.py 从 scikit-learn 中导入了 tree，并定义了一个字典，其中键是模型的名称，值是模型本身。在这里，我们定义了两种不同的决策树，一种使用基尼标准，另一种使用熵标准。要使用 py，我们需要对训练脚本做一些修改。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> joblib</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">import</span> config</span><br><span class="line"><span class="keyword">import</span> model_dispatcher</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">fold, model</span>):</span><br><span class="line">    df = pd.read_csv(config.TRAINING_FILE)</span><br><span class="line">    df_train = df[df.kfold != fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">    df_valid = df[df.kfold == fold].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">x_train = df_train.drop(<span class="string">&quot;label&quot;</span>, axis=<span class="number">1</span>).values</span><br><span class="line">y_train = df_train.label.values</span><br><span class="line">    x_valid = df_valid.drop(<span class="string">&quot;label&quot;</span>, axis=<span class="number">1</span>).values</span><br><span class="line">y_valid = df_valid.label.values</span><br><span class="line">    <span class="comment"># 根据model参数选择模型</span></span><br><span class="line">clf = model_dispatcher.models[model]</span><br><span class="line">    clf.fit(x_train, y_train)</span><br><span class="line">preds = clf.predict(x_valid)</span><br><span class="line">    accuracy = metrics.accuracy_score(y_valid, preds)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Fold=<span class="subst">&#123;fold&#125;</span>, Accuracy=<span class="subst">&#123;accuracy&#125;</span>&quot;</span>)</span><br><span class="line">    joblib.dump( clf,os.path.join(config.MODEL_OUTPUT, <span class="string">f&quot;dt_<span class="subst">&#123;fold&#125;</span>.bin&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">    <span class="comment"># fold参数</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--fold&quot;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>)</span><br><span class="line">    <span class="comment"># model参数</span></span><br><span class="line">parser.add_argument(<span class="string">&quot;--model&quot;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    run(fold=args.fold, model=args.model)</span><br></pre></td></tr></table></figure><p>train.py 有几处重大改动：</p><ul><li>导入<em>model_dispatcher</em></li><li>为 ArgumentParser 添加 —model 参数</li><li>为 run() 函数添加 model 参数</li><li>使用调度程序获取指定名称的模型</li></ul><p>现在，我们可以使用以下命令运行脚本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">❯ python train.py --fold <span class="number">0</span> --model decision_tree_gini</span><br><span class="line">Fold=<span class="number">0</span>, Accuracy=<span class="number">0.8665833333333334</span></span><br></pre></td></tr></table></figure><p>或执行以下命令</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">❯ python train.py --fold <span class="number">0</span> --model decision_tree_entropy</span><br><span class="line">Fold=<span class="number">0</span>, Accuracy=<span class="number">0.8705833333333334</span></span><br></pre></td></tr></table></figure><p>现在，如果要添加新模型，只需修改 <em>model_dispatcher.py</em>。让我们尝试添加随机森林，看看准确率会有什么变化。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> ensemble</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree</span><br><span class="line">models = &#123;</span><br><span class="line">    <span class="string">&quot;decision_tree_gini&quot;</span>: tree.DecisionTreeClassifier(</span><br><span class="line">        criterion=<span class="string">&quot;gini&quot;</span></span><br><span class="line">    ),</span><br><span class="line">    <span class="string">&quot;decision_tree_entropy&quot;</span>: tree.DecisionTreeClassifier(</span><br><span class="line">        criterion=<span class="string">&quot;entropy&quot;</span></span><br><span class="line">    ),</span><br><span class="line">    <span class="comment"># 随机森林模型</span></span><br><span class="line">    <span class="string">&quot;rf&quot;</span>: ensemble.RandomForestClassifier(),</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>让我们运行这段代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">❯ python train.py --fold <span class="number">0</span> --model rf</span><br><span class="line">Fold=<span class="number">0</span>, Accuracy=<span class="number">0.9670833333333333</span></span><br></pre></td></tr></table></figure><p>哇，一个简单的改动就能让分数有如此大的提升！现在，让我们使用 <em>run.sh</em> 脚本运行 5 个折叠！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python train.py --fold <span class="number">0</span> --model rf</span><br><span class="line">python train.py --fold <span class="number">1</span> --model rf</span><br><span class="line">python train.py --fold <span class="number">2</span> --model rf</span><br><span class="line">python train.py --fold <span class="number">3</span> --model rf</span><br><span class="line">python train.py --fold <span class="number">4</span> --model rf</span><br></pre></td></tr></table></figure><p>得分情况如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">❯ sh run.sh</span><br><span class="line">Fold=<span class="number">0</span>, Accuracy=<span class="number">0.9674166666666667</span></span><br><span class="line">Fold=<span class="number">1</span>, Accuracy=<span class="number">0.9698333333333333</span></span><br><span class="line">Fold=<span class="number">2</span>, Accuracy=<span class="number">0.96575</span></span><br><span class="line">Fold=<span class="number">3</span>, Accuracy=<span class="number">0.9684166666666667</span></span><br><span class="line">Fold=<span class="number">4</span>, Accuracy=<span class="number">0.9666666666666667</span></span><br></pre></td></tr></table></figure><p>MNIST 几乎是每本书和每篇博客都会讨论的问题。但我试图将这个问题转换得更有趣，并向你展示如何为你正在做的或计划在不久的将来做的几乎所有机器学习项目编写一个基本框架。有许多不同的方法可以改进这个 MNIST 模型和这个框架，我们将在以后的章节中看到。</p><p>我使用了一些脚本，如 <em>model_dispatcher.py</em> 和 <em>config.py</em>，并将它们导入到我的训练脚本中。请注意，我没有导入 <em>，你也不应该导入。如果我导入了 </em>，你就永远不会知道模型字典是从哪里来的。编写优秀、易懂的代码是一个人必须具备的基本素质，但许多数据科学家却忽视了这一点。如果你所做的项目能让其他人理解并使用，而无需咨询你的意见，那么你就节省了他们的时间和自己的时间，可以将这些时间投入到改进你的项目或开发新项目中去。</p>]]></content>
      
      
      <categories>
          
          <category> AAAMLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>超参数优化</title>
      <link href="/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/"/>
      <url>/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/</url>
      
        <content type="html"><![CDATA[<h1 id="超参数优化"><a href="#超参数优化" class="headerlink" title="超参数优化"></a>超参数优化</h1><p>有了优秀的模型，就有了优化超参数以获得最佳得分模型的难题。那么，什么是超参数优化呢？假设您的机器学习项目有一个简单的流程。有一个数据集，你直接应用一个模型，然后得到结果。模型在这里的参数被称为超参数，即控制模型训练/拟合过程的参数。如果我们用 SGD 训练线性回归，模型的参数是斜率和偏差，超参数是学习率。你会发现我在本章和本书中交替使用这些术语。假设模型中有三个参数 a、b、c，所有这些参数都可以是 1 到 10 之间的整数。这些参数的 “正确 “组合将为您提供最佳结果。因此，这就有点像一个装有三拨密码锁的手提箱。不过，三拨密码锁只有一个正确答案。而模型有很多正确答案。那么，如何找到最佳参数呢？一种方法是对所有组合进行评估，看哪种组合能提高指标。让我们看看如何做到这一点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化最佳准确度</span></span><br><span class="line">best_accuracy = <span class="number">0</span></span><br><span class="line"><span class="comment"># 初始化最佳参数的字典</span></span><br><span class="line">best_parameters = &#123;<span class="string">&quot;a&quot;</span>: <span class="number">0</span>, <span class="string">&quot;b&quot;</span>: <span class="number">0</span>, <span class="string">&quot;c&quot;</span>: <span class="number">0</span>&#125;</span><br><span class="line"><span class="comment"># 循环遍历 a 的取值范围 1~10</span></span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>):</span><br><span class="line">    <span class="comment"># 循环遍历 b 的取值范围 1~10</span></span><br><span class="line"><span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>):</span><br><span class="line">        <span class="comment"># 循环遍历 c 的取值范围 1~10</span></span><br><span class="line"><span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">11</span>):</span><br><span class="line">            <span class="comment"># 创建模型，使用 a、b、c 参数</span></span><br><span class="line">            model = MODEL(a, b, c)</span><br><span class="line">            <span class="comment"># 使用训练数据拟合模型</span></span><br><span class="line">            model.fit(training_data)</span><br><span class="line">            <span class="comment"># 使用模型对验证数据进行预测</span></span><br><span class="line">            preds = model.predict(validation_data)</span><br><span class="line">            <span class="comment"># 计算预测的准确度</span></span><br><span class="line">            accuracy = metrics.accuracy_score(targets, preds)</span><br><span class="line">             <span class="comment"># 如果当前准确度优于之前的最佳准确度，则更新最佳准确度和最佳参数</span></span><br><span class="line">            <span class="keyword">if</span> accuracy &gt; best_accuracy:</span><br><span class="line">                best_accuracy = accuracy</span><br><span class="line">                best_parameters[<span class="string">&quot;a&quot;</span>] = a</span><br><span class="line">                best_parameters[<span class="string">&quot;b&quot;</span>] = b</span><br><span class="line">best_parameters[<span class="string">&quot;c&quot;</span>] = c</span><br></pre></td></tr></table></figure><p>在上述代码中，我们从 1 到 10 对所有参数进行了拟合。因此，我们总共要对模型进行 1000 次（10 x 10 x 10）拟合。这可能会很昂贵，因为模型的训练需要很长时间。不过，在这种情况下应该没问题，但在现实世界中，并不是只有三个参数，每个参数也不是只有十个值。 大多数模型参数都是实数，不同参数的组合可以是无限的。</p><p>让我们看看 scikit-learn 的随机森林模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">RandomForestClassifier(</span><br><span class="line">    n_estimators=<span class="number">100</span>,</span><br><span class="line">criterion=<span class="string">&#x27;gini&#x27;</span>,</span><br><span class="line">max_depth=<span class="literal">None</span>,</span><br><span class="line">min_samples_split=<span class="number">2</span>,</span><br><span class="line">min_samples_leaf=<span class="number">1</span>,</span><br><span class="line">min_weight_fraction_leaf=<span class="number">0.0</span>,</span><br><span class="line">max_features=<span class="string">&#x27;auto&#x27;</span>,</span><br><span class="line">max_leaf_nodes=<span class="literal">None</span>,</span><br><span class="line">min_impurity_decrease=<span class="number">0.0</span>,</span><br><span class="line">min_impurity_split=<span class="literal">None</span>,</span><br><span class="line">bootstrap=<span class="literal">True</span>,</span><br><span class="line">oob_score=<span class="literal">False</span>,</span><br><span class="line">n_jobs=<span class="literal">None</span>,</span><br><span class="line">random_state=<span class="literal">None</span>,</span><br><span class="line">verbose=<span class="number">0</span>,</span><br><span class="line">warm_start=<span class="literal">False</span>,</span><br><span class="line">class_weight=<span class="literal">None</span>,</span><br><span class="line">ccp_alpha=<span class="number">0.0</span>,</span><br><span class="line">max_samples=<span class="literal">None</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>有 19 个参数，而所有这些参数的所有组合，以及它们可以承担的所有值，都将是无穷无尽的。通常情况下，我们没有足够的资源和时间来做这件事。因此，我们指定了一个参数网格。在这个网格上寻找最佳参数组合的搜索称为网格搜索。我们可以说，n_estimators 可以是 100、200、250、300、400、500；max_depth 可以是 1、2、5、7、11、15；criterion 可以是 gini 或 entropy。这些参数看起来并不多，但如果数据集过大，计算起来会耗费大量时间。我们可以像之前一样创建三个 for 循环，并在验证集上计算得分，这样就能实现网格搜索。还必须注意的是，如果要进行 k 折交叉验证，则需要更多的循环，这意味着需要更多的时间来找到完美的参数。因此，网格搜索并不流行。让我们以根据<strong>手机配置预测手机价格范围</strong>数据集为例，看看它是如何实现的。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page168_image.png" alt=""></p><p align="center"><b>图 1：手机配置预测手机价格范围数据集展示</b> </p><p>训练集中只有 2000 个样本。我们可以轻松地使用分层 kfold 和准确率作为评估指标。我们将使用具有上述参数范围的随机森林模型，并在下面的示例中了解如何进行网格搜索。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rf_grid_search.py</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> ensemble</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 读取数据</span></span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/mobile_train.csv&quot;</span>)</span><br><span class="line">    <span class="comment"># 删除 price_range 列</span></span><br><span class="line">X = df.drop(<span class="string">&quot;price_range&quot;</span>, axis=<span class="number">1</span>).values</span><br><span class="line">    <span class="comment"># 取目标变量 y（&quot;price_range&quot;列）</span></span><br><span class="line">y = df.price_range.values</span><br><span class="line">    <span class="comment"># 创建随机森林分类器，使用所有可用的 CPU 核心进行训练</span></span><br><span class="line">classifier = ensemble.RandomForestClassifier(n_jobs=-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 定义要进行网格搜索的参数网格</span></span><br><span class="line">param_grid = &#123;</span><br><span class="line">        <span class="string">&quot;n_estimators&quot;</span>: [<span class="number">100</span>, <span class="number">200</span>, <span class="number">250</span>, <span class="number">300</span>, <span class="number">400</span>, <span class="number">500</span>],</span><br><span class="line">        <span class="string">&quot;max_depth&quot;</span>: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">11</span>, <span class="number">15</span>],</span><br><span class="line">        <span class="string">&quot;criterion&quot;</span>: [<span class="string">&quot;gini&quot;</span>, <span class="string">&quot;entropy&quot;</span>]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 创建 GridSearchCV 对象 model，用于在参数网格上进行网格搜索</span></span><br><span class="line">model = model_selection.GridSearchCV(</span><br><span class="line">        estimator=classifier,</span><br><span class="line">        param_grid=param_grid,</span><br><span class="line">        scoring=<span class="string">&quot;accuracy&quot;</span>,</span><br><span class="line">        verbose=<span class="number">10</span>,</span><br><span class="line">        n_jobs=<span class="number">1</span>,</span><br><span class="line">        cv=<span class="number">5</span></span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 使用网格搜索对象 model 拟合数据，寻找最佳参数组合</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line">    <span class="comment"># 打印出最佳模型的最佳准确度分数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Best score: <span class="subst">&#123;model.best_score_&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="comment"># 打印最佳参数集合</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best parameters set:&quot;</span>)</span><br><span class="line">best_parameters = model.best_estimator_.get_params()</span><br><span class="line"><span class="keyword">for</span> param_name <span class="keyword">in</span> <span class="built_in">sorted</span>(param_grid.keys()):</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;param_name&#125;</span>: <span class="subst">&#123;best_parameters[param_name]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>这里打印了很多内容，让我们看看最后几行。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[CV]  criterion=entropy, max_depth=<span class="number">15</span>, n_estimators=<span class="number">500</span>, score=<span class="number">0.895</span>,</span><br><span class="line">total=  <span class="number">1.0</span>s</span><br><span class="line">[CV] criterion=entropy, max_depth=<span class="number">15</span>, n_estimators=<span class="number">500</span> ...............</span><br><span class="line">[CV]  criterion=entropy, max_depth=<span class="number">15</span>, n_estimators=<span class="number">500</span>, score=<span class="number">0.890</span>,</span><br><span class="line">total=  <span class="number">1.1</span>s</span><br><span class="line">[CV] criterion=entropy, max_depth=<span class="number">15</span>, n_estimators=<span class="number">500</span> ...............</span><br><span class="line">[CV]  criterion=entropy, max_depth=<span class="number">15</span>, n_estimators=<span class="number">500</span>, score=<span class="number">0.910</span>,</span><br><span class="line">total=  <span class="number">1.1</span>s</span><br><span class="line">[CV] criterion=entropy, max_depth=<span class="number">15</span>, n_estimators=<span class="number">500</span> ...............</span><br><span class="line">[CV]  criterion=entropy, max_depth=<span class="number">15</span>, n_estimators=<span class="number">500</span>, score=<span class="number">0.880</span>,</span><br><span class="line">total=  <span class="number">1.1</span>s</span><br><span class="line">[CV] criterion=entropy, max_depth=<span class="number">15</span>, n_estimators=<span class="number">500</span> ...............</span><br><span class="line">[CV]  criterion=entropy, max_depth=<span class="number">15</span>, n_estimators=<span class="number">500</span>, score=<span class="number">0.870</span>,</span><br><span class="line">total=  <span class="number">1.1</span>s</span><br><span class="line">[Parallel(n_jobs=<span class="number">1</span>)]: Done <span class="number">360</span> out of <span class="number">360</span> | elapsed: <span class="number">3.7</span><span class="built_in">min</span> finished</span><br><span class="line">Best score: <span class="number">0.889</span></span><br><span class="line">Best parameters <span class="built_in">set</span>:</span><br><span class="line">criterion: <span class="string">&#x27;entropy&#x27;</span></span><br><span class="line">max_depth: <span class="number">15</span></span><br><span class="line">n_estimators: <span class="number">500</span></span><br></pre></td></tr></table></figure><p>最后，我们可以看到，5 折交叉检验最佳得分是 0.889，我们的网格搜索得到了最佳参数。我们可以使用的下一个最佳方法是<strong>随机搜索</strong>。在随机搜索中，我们随机选择一个参数组合，然后计算交叉验证得分。这里消耗的时间比网格搜索少，因为我们不对所有不同的参数组合进行评估。我们选择要对模型进行多少次评估，这就决定了搜索所需的时间。代码与上面的差别不大。除 GridSearchCV 外，我们使用 RandomizedSearchCV。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">classifier = ensemble.RandomForestClassifier(n_jobs=-<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 更改搜索空间</span></span><br><span class="line">    param_grid = &#123;</span><br><span class="line">        <span class="string">&quot;n_estimators&quot;</span>: np.arange(<span class="number">100</span>, <span class="number">1500</span>, <span class="number">100</span>),</span><br><span class="line">        <span class="string">&quot;max_depth&quot;</span>: np.arange(<span class="number">1</span>, <span class="number">31</span>),</span><br><span class="line">        <span class="string">&quot;criterion&quot;</span>: [<span class="string">&quot;gini&quot;</span>, <span class="string">&quot;entropy&quot;</span>]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment"># 随机参数搜索</span></span><br><span class="line">model = model_selection.RandomizedSearchCV(</span><br><span class="line">        estimator=classifier,</span><br><span class="line">    param_distributions=param_grid,</span><br><span class="line">    n_iter=<span class="number">20</span>,</span><br><span class="line">    scoring=<span class="string">&quot;accuracy&quot;</span>,</span><br><span class="line">    verbose=<span class="number">10</span>,</span><br><span class="line">    n_jobs=<span class="number">1</span>,</span><br><span class="line">    cv=<span class="number">5</span></span><br><span class="line">)</span><br><span class="line">    <span class="comment"># 使用网格搜索对象 model 拟合数据，寻找最佳参数组合</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Best score: <span class="subst">&#123;model.best_score_&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best parameters set:&quot;</span>)</span><br><span class="line">best_parameters = model.best_estimator_.get_params()</span><br><span class="line"><span class="keyword">for</span> param_name <span class="keyword">in</span> <span class="built_in">sorted</span>(param_grid.keys()):</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\t<span class="subst">&#123;param_name&#125;</span>: <span class="subst">&#123;best_parameters[param_name]&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p>我们更改了随机搜索的参数网格，结果似乎有了些许改进。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Best score: <span class="number">0.8905</span></span><br><span class="line">Best parameters <span class="built_in">set</span>:</span><br><span class="line">    criterion: entropy</span><br><span class="line">max_depth: <span class="number">25</span></span><br><span class="line">n_estimators: <span class="number">300</span></span><br></pre></td></tr></table></figure><p>如果迭代次数较少，随机搜索比网格搜索更快。使用这两种方法，你可以为各种模型找到最优参数，只要它们有拟合和预测功能，这也是 scikit-learn 的标准。有时，你可能想使用管道。例如，假设我们正在处理一个多类分类问题。在这个问题中，训练数据由两列文本组成，你需要建立一个模型来预测类别。让我们假设你选择的管道是首先以半监督的方式应用 tf-idf，然后使用 SVD 和 SVM 分类器。现在的问题是，我们必须选择 SVD 的成分，还需要调整 SVM 的参数。下面的代码段展示了如何做到这一点。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> pipeline</span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> TruncatedSVD</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line"><span class="comment"># 计算加权二次 Kappa 分数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">quadratic_weighted_kappa</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="keyword">return</span> metrics.cohen_kappa_score(</span><br><span class="line">        y_true,</span><br><span class="line">        y_pred,</span><br><span class="line">        weights=<span class="string">&quot;quadratic&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 读取训练集</span></span><br><span class="line">    train = pd.read_csv(<span class="string">&#x27;../input/train.csv&#x27;</span>)</span><br><span class="line">    <span class="comment"># 从测试数据中提取 id 列的值，并将其转换为整数类型，存储在变量 idx 中</span></span><br><span class="line">    idx = test.<span class="built_in">id</span>.values.astype(<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从训练数据中删除 &#x27;id&#x27; 列</span></span><br><span class="line">    train = train.drop(<span class="string">&#x27;id&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 从测试数据中删除 &#x27;id&#x27; 列</span></span><br><span class="line">    test = test.drop(<span class="string">&#x27;id&#x27;</span>, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># 从训练数据中提取目标变量 &#x27;relevance&#x27; ，存储在变量 y 中</span></span><br><span class="line">    y = train.relevance.values</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将训练数据中的文本特征 &#x27;text1&#x27; 和 &#x27;text2&#x27; 合并成一个新的特征列，并存储在列表 traindata 中</span></span><br><span class="line">    traindata = <span class="built_in">list</span>(train.apply(<span class="keyword">lambda</span> x:<span class="string">&#x27;%s %s&#x27;</span> % (x[<span class="string">&#x27;text1&#x27;</span>], x[<span class="string">&#x27;text2&#x27;</span>]),axis=<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 将测试数据中的文本特征 &#x27;text1&#x27; 和 &#x27;text2&#x27; 合并成一个新的特征列，并存储在列表 testdata 中</span></span><br><span class="line">    testdata = <span class="built_in">list</span>(test.apply(<span class="keyword">lambda</span> x:<span class="string">&#x27;%s %s&#x27;</span> % (x[<span class="string">&#x27;text1&#x27;</span>], x[<span class="string">&#x27;text2&#x27;</span>]),axis=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一个 TfidfVectorizer 对象 tfv，用于将文本数据转换为 TF-IDF 特征</span></span><br><span class="line">    tfv = TfidfVectorizer(</span><br><span class="line">        min_df=<span class="number">3</span>,</span><br><span class="line">        max_features=<span class="literal">None</span>,</span><br><span class="line">        strip_accents=<span class="string">&#x27;unicode&#x27;</span>,</span><br><span class="line">        analyzer=<span class="string">&#x27;word&#x27;</span>,</span><br><span class="line">        token_pattern=<span class="string">r&#x27;\w&#123;1,&#125;&#x27;</span>,</span><br><span class="line">        ngram_range=(<span class="number">1</span>, <span class="number">3</span>),</span><br><span class="line">        use_idf=<span class="number">1</span>,</span><br><span class="line">        smooth_idf=<span class="number">1</span>,</span><br><span class="line">        sublinear_tf=<span class="number">1</span>,</span><br><span class="line">        stop_words=<span class="string">&#x27;english&#x27;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用训练数据拟合 TfidfVectorizer，将文本特征转换为 TF-IDF 特征</span></span><br><span class="line">tfv.fit(traindata)</span><br><span class="line">    <span class="comment"># 将训练数据中的文本特征转换为 TF-IDF 特征矩阵 X</span></span><br><span class="line">X =  tfv.transform(traindata)</span><br><span class="line">    <span class="comment"># 将测试数据中的文本特征转换为 TF-IDF 特征矩阵 X_test</span></span><br><span class="line">X_test = tfv.transform(testdata)</span><br><span class="line">    <span class="comment"># 创建 TruncatedSVD 对象 svd，用于进行奇异值分解</span></span><br><span class="line">svd = TruncatedSVD()</span><br><span class="line">    <span class="comment"># 创建 StandardScaler 对象 scl，用于进行特征缩放</span></span><br><span class="line">scl = StandardScaler()</span><br><span class="line">    <span class="comment"># 创建支持向量机分类器对象 svm_model</span></span><br><span class="line">svm_model = SVC()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建机器学习管道 clf，包含奇异值分解、特征缩放和支持向量机分类器</span></span><br><span class="line">    clf = pipeline.Pipeline(</span><br><span class="line">        [</span><br><span class="line">            (<span class="string">&#x27;svd&#x27;</span>, svd),</span><br><span class="line">            (<span class="string">&#x27;scl&#x27;</span>, scl),</span><br><span class="line">            (<span class="string">&#x27;svm&#x27;</span>, svm_model)</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义要进行网格搜索的参数网格 param_grid</span></span><br><span class="line">param_grid = &#123;</span><br><span class="line">        <span class="string">&#x27;svd__n_components&#x27;</span> : [<span class="number">200</span>, <span class="number">300</span>],</span><br><span class="line">        <span class="string">&#x27;svm__C&#x27;</span>: [<span class="number">10</span>, <span class="number">12</span>]</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建自定义的评分函数 kappa_scorer，用于评估模型性能</span></span><br><span class="line">kappa_scorer = metrics.make_scorer(</span><br><span class="line">        quadratic_weighted_kappa,</span><br><span class="line">        greater_is_better=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建 GridSearchCV 对象 model，用于在参数网格上进行网格搜索，寻找最佳参数组合</span></span><br><span class="line">    model = model_selection.GridSearchCV(</span><br><span class="line">        estimator=clf,</span><br><span class="line">        param_grid=param_grid,</span><br><span class="line">        scoring=kappa_scorer,</span><br><span class="line">        verbose=<span class="number">10</span>,</span><br><span class="line">        n_jobs=-<span class="number">1</span>,</span><br><span class="line">        refit=<span class="literal">True</span>,</span><br><span class="line">        cv=<span class="number">5</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">     <span class="comment"># 使用 GridSearchCV 对象 model 拟合数据，寻找最佳参数组合</span></span><br><span class="line">model.fit(X, y)</span><br><span class="line">    <span class="comment"># 打印出最佳模型的最佳准确度分数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best score: %0.3f&quot;</span> % model.best_score_)</span><br><span class="line">    <span class="comment"># 打印最佳参数集合</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Best parameters set:&quot;</span>)</span><br><span class="line">best_parameters = model.best_estimator_.get_params()</span><br><span class="line"><span class="keyword">for</span> param_name <span class="keyword">in</span> <span class="built_in">sorted</span>(param_grid.keys()):</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\t%s: %r&quot;</span> % (param_name, best_parameters[param_name]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取最佳模型</span></span><br><span class="line">best_model = model.best_estimator_</span><br><span class="line">    best_model.fit(X, y)</span><br><span class="line">    <span class="comment"># 使用最佳模型进行预测</span></span><br><span class="line">    preds = best_model.predict(...)</span><br></pre></td></tr></table></figure><p>这里显示的管道包括 SVD（奇异值分解）、标准缩放和 SVM（支持向量机）模型。请注意，由于没有训练数据，您无法按原样运行上述代码。当我们进入高级超参数优化技术时，我们可以使用不同类型的<strong>最小化算法</strong>来研究函数的最小化。这可以通过使用多种最小化函数来实现，如下坡单纯形算法、内尔德-梅德优化算法、使用贝叶斯技术和高斯过程寻找最优参数或使用遗传算法。我将在 “集合与堆叠（ensembling and stacking） “一章中详细介绍下坡单纯形算法和 Nelder-Mead 算法的应用。首先，让我们看看高斯过程如何用于超参数优化。这类算法需要一个可以优化的函数。大多数情况下，都是最小化这个函数，就像我们最小化损失一样。</p><p>因此，比方说，你想找到最佳参数以获得最佳准确度，显然，准确度越高越好。现在，我们不能最小化精确度，但我们可以将精确度乘以-1。这样，我们是在最小化精确度的负值，但事实上，我们是在最大化精确度。 在高斯过程中使用贝叶斯优化，可以使用 scikit-optimize (skopt) 库中的 gp_minimize 函数。让我们看看如何使用该函数调整随机森林模型的参数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> ensemble</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> skopt <span class="keyword">import</span> gp_minimize</span><br><span class="line"><span class="keyword">from</span> skopt <span class="keyword">import</span> space</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">optimize</span>(<span class="params">params, param_names, x, y</span>):</span><br><span class="line">    <span class="comment"># 将参数名称和对应的值打包成字典</span></span><br><span class="line">    params = <span class="built_in">dict</span>(<span class="built_in">zip</span>(param_names, params))</span><br><span class="line">    <span class="comment"># 创建随机森林分类器模型，使用传入的参数配置</span></span><br><span class="line">    model = ensemble.RandomForestClassifier(**params)</span><br><span class="line">    <span class="comment"># 创建 StratifiedKFold 交叉验证对象，将数据分为 5 折</span></span><br><span class="line">    kf = model_selection.StratifiedKFold(n_splits=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化用于存储每个折叠的准确度的列表</span></span><br><span class="line">    accuracies = []</span><br><span class="line"></span><br><span class="line">     <span class="comment"># 循环遍历每个折叠的训练和测试数据</span></span><br><span class="line">    <span class="keyword">for</span> idx <span class="keyword">in</span> kf.split(X=x, y=y):</span><br><span class="line">        train_idx, test_idx = idx[<span class="number">0</span>], idx[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">        xtrain = x[train_idx]</span><br><span class="line">        ytrain = y[train_idx]</span><br><span class="line"></span><br><span class="line">        xtest = x[test_idx]</span><br><span class="line">        ytest = y[test_idx]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 在训练数据上拟合模型</span></span><br><span class="line">        model.fit(xtrain, ytrain)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用模型对测试数据进行预测</span></span><br><span class="line">        preds = model.predict(xtest)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计算折叠的准确度</span></span><br><span class="line">        fold_accuracy = metrics.accuracy_score(ytest, preds)</span><br><span class="line">        accuracies.append(fold_accuracy)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回平均准确度的负数（因为 skopt 使用负数来最小化目标函数）</span></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span> * np.mean(accuracies)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># 读取数据</span></span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/mobile_train.csv&quot;</span>)</span><br><span class="line">    <span class="comment"># 取特征矩阵 X（去掉&quot;price_range&quot;列）</span></span><br><span class="line">    X = df.drop(<span class="string">&quot;price_range&quot;</span>, axis=<span class="number">1</span>).values</span><br><span class="line">    <span class="comment"># 目标变量 y（&quot;price_range&quot;列）</span></span><br><span class="line">    y = df.price_range.values</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义超参数搜索空间 param_space</span></span><br><span class="line">    param_space = [</span><br><span class="line">space.Integer(<span class="number">3</span>, <span class="number">15</span>, name=<span class="string">&quot;max_depth&quot;</span>),</span><br><span class="line">        space.Integer(<span class="number">100</span>, <span class="number">1500</span>, name=<span class="string">&quot;n_estimators&quot;</span>),</span><br><span class="line">        space.Categorical([<span class="string">&quot;gini&quot;</span>, <span class="string">&quot;entropy&quot;</span>], name=<span class="string">&quot;criterion&quot;</span>),</span><br><span class="line">        space.Real(<span class="number">0.01</span>, <span class="number">1</span>, prior=<span class="string">&quot;uniform&quot;</span>, name=<span class="string">&quot;max_features&quot;</span>)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义超参数的名称列表 param_names</span></span><br><span class="line">    param_names = [</span><br><span class="line">        <span class="string">&quot;max_depth&quot;</span>,</span><br><span class="line">        <span class="string">&quot;n_estimators&quot;</span>,</span><br><span class="line">        <span class="string">&quot;criterion&quot;</span>,</span><br><span class="line">        <span class="string">&quot;max_features&quot;</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建函数 optimization_function，用于传递给 gp_minimize</span></span><br><span class="line">optimization_function = partial(</span><br><span class="line">        optimize,</span><br><span class="line">        param_names=param_names,</span><br><span class="line">        x=X,</span><br><span class="line">        y=y</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用 Bayesian Optimization（基于贝叶斯优化）来搜索最佳超参数</span></span><br><span class="line">    result = gp_minimize(</span><br><span class="line">        optimization_function,</span><br><span class="line">        dimensions=param_space,</span><br><span class="line">        n_calls=<span class="number">15</span>,</span><br><span class="line">        n_random_starts=<span class="number">10</span>,</span><br><span class="line">        verbose=<span class="number">10</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取最佳超参数的字典</span></span><br><span class="line">best_params = <span class="built_in">dict</span>(</span><br><span class="line">        <span class="built_in">zip</span>(</span><br><span class="line">            param_names,</span><br><span class="line">            result.x</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    <span class="comment"># 打印出找到的最佳超参数</span></span><br><span class="line"><span class="built_in">print</span>(best_params)</span><br></pre></td></tr></table></figure><p>这同样会产生大量输出，最后一部分如下所示。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Iteration No: <span class="number">14</span> started. Searching <span class="keyword">for</span> the <span class="built_in">next</span> optimal point.</span><br><span class="line">Iteration No: <span class="number">14</span> ended. Search finished <span class="keyword">for</span> the <span class="built_in">next</span> optimal point.</span><br><span class="line">Time taken: <span class="number">4.7793</span></span><br><span class="line">Function value obtained: -<span class="number">0.9075</span></span><br><span class="line">Current minimum: -<span class="number">0.9075</span></span><br><span class="line">Iteration No: <span class="number">15</span> started. Searching <span class="keyword">for</span> the <span class="built_in">next</span> optimal point.</span><br><span class="line">Iteration No: <span class="number">15</span> ended. Search finished <span class="keyword">for</span> the <span class="built_in">next</span> optimal point.</span><br><span class="line">Time taken: <span class="number">49.4186</span></span><br><span class="line">Function value obtained: -<span class="number">0.9075</span></span><br><span class="line">Current minimum: -<span class="number">0.9075</span></span><br><span class="line">&#123;<span class="string">&#x27;max_depth&#x27;</span>: <span class="number">12</span>, <span class="string">&#x27;n_estimators&#x27;</span>: <span class="number">100</span>, <span class="string">&#x27;criterion&#x27;</span>: <span class="string">&#x27;entropy&#x27;</span>,</span><br><span class="line"><span class="string">&#x27;max_features&#x27;</span>: <span class="number">1.0</span>&#125;</span><br></pre></td></tr></table></figure><p>看来我们已经成功突破了 0.90 的准确率。这真是太神奇了！<br>我们还可以通过以下代码段查看（绘制）我们是如何实现收敛的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skopt.plots <span class="keyword">import</span> plot_convergence</span><br><span class="line">plot_convergence(result)</span><br></pre></td></tr></table></figure><p>收敛图如图 2 所示。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page179_image.png" alt=""></p><p align="center"><b>图 2：随机森林参数优化的收敛图</b> </p><p>Scikit- optimize 就是这样一个库。 hyperopt 使用树状结构贝叶斯估计器（TPE）来找到最优参数。请看下面的代码片段，我在使用 hyperopt 时对之前的代码做了最小的改动。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> ensemble</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> model_selection</span><br><span class="line"><span class="keyword">from</span> hyperopt <span class="keyword">import</span> hp, fmin, tpe, Trials</span><br><span class="line"><span class="keyword">from</span> hyperopt.pyll.base <span class="keyword">import</span> scope</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">optimize</span>(<span class="params">params, x, y</span>):</span><br><span class="line">    model = ensemble.RandomForestClassifier(**params)</span><br><span class="line">    kf = model_selection.StratifiedKFold(n_splits=<span class="number">5</span>)</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span> * np.mean(accuracies)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    df = pd.read_csv(<span class="string">&quot;../input/mobile_train.csv&quot;</span>)</span><br><span class="line">    X = df.drop(<span class="string">&quot;price_range&quot;</span>, axis=<span class="number">1</span>).values</span><br><span class="line">    y = df.price_range.values</span><br><span class="line">    <span class="comment"># 定义搜索空间（整型、浮点数型、选择型）</span></span><br><span class="line">    param_space = &#123;</span><br><span class="line">        <span class="string">&quot;max_depth&quot;</span>: scope.<span class="built_in">int</span>(hp.quniform(<span class="string">&quot;max_depth&quot;</span>, <span class="number">1</span>, <span class="number">15</span>, <span class="number">1</span>)),</span><br><span class="line">        <span class="string">&quot;n_estimators&quot;</span>: scope.<span class="built_in">int</span>(</span><br><span class="line">            hp.quniform(<span class="string">&quot;n_estimators&quot;</span>, <span class="number">100</span>, <span class="number">1500</span>, <span class="number">1</span>)</span><br><span class="line">        ),</span><br><span class="line">        <span class="string">&quot;criterion&quot;</span>: hp.choice(<span class="string">&quot;criterion&quot;</span>, [<span class="string">&quot;gini&quot;</span>, <span class="string">&quot;entropy&quot;</span>]),</span><br><span class="line">        <span class="string">&quot;max_features&quot;</span>: hp.uniform(<span class="string">&quot;max_features&quot;</span>, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 包装函数</span></span><br><span class="line">    optimization_function = partial(</span><br><span class="line">        optimize,</span><br><span class="line">        x=X,</span><br><span class="line">        y=y</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开始训练</span></span><br><span class="line">    trials = Trials()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 最小化目标值</span></span><br><span class="line">    hopt = fmin(</span><br><span class="line">        fn=optimization_function,</span><br><span class="line">        space=param_space,</span><br><span class="line">        algo=tpe.suggest,</span><br><span class="line">        max_evals=<span class="number">15</span>,</span><br><span class="line">        trials=trials</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">#打印最佳参数</span></span><br><span class="line">    <span class="built_in">print</span>(hopt)</span><br></pre></td></tr></table></figure><p>正如你所看到的，这与之前的代码并无太大区别。你必须以不同的格式定义参数空间，还需要改变实际优化部分，用 hyperopt 代替 gp_minimize。结果相当不错！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">❯ python rf_hyperopt.py</span><br><span class="line"><span class="number">100</span>%|██████████████████| <span class="number">15</span>/<span class="number">15</span> [04:<span class="number">38</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">18.57</span>s/trial, best loss: -</span><br><span class="line"><span class="number">0.9095000000000001</span>]</span><br><span class="line">&#123;<span class="string">&#x27;criterion&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;max_depth&#x27;</span>: <span class="number">11.0</span>, <span class="string">&#x27;max_features&#x27;</span>: <span class="number">0.821163568049807</span>,</span><br><span class="line"><span class="string">&#x27;n_estimators&#x27;</span>: <span class="number">806.0</span>&#125;</span><br></pre></td></tr></table></figure><p>我们得到了比以前更好的准确度和一组可以使用的参数。请注意，最终结果中的标准是 1。这意味着选择了 1，即熵。 上述调整超参数的方法是最常见的，几乎适用于所有模型：线性回归、逻辑回归、基于树的方法、梯度提升模型（如 xgboost、lightgbm），甚至神经网络！</p><p>虽然这些方法已经存在，但学习时必须从手动调整超参数开始，即手工调整。手动调整可以帮助你学习基础知识，例如，在梯度提升中，当你增加深度时，你应该降低学习率。如果使用自动工具，就无法学习到这一点。请参考下表，了解应如何调整。RS* 表示随机搜索应该更好。</p><p>一旦你能更好地手动调整参数，你甚至可能不需要任何自动超参数调整。创建大型模型或引入大量特征时，也容易造成训练数据的过度拟合。为避免过度拟合，需要在训练数据特征中引入噪声或对代价函数进行惩罚。这种惩罚称为<strong>正则化</strong>，有助于泛化模型。在线性模型中，最常见的正则化类型是 L1 和 L2。L1 也称为 Lasso 回归，L2 称为 Ridge 回归。说到神经网络，我们会使用 dropout、添加增强、噪声等方法对模型进行正则化。利用超参数优化，还可以找到正确的惩罚方法。</p><div class="table-container"><table><thead><tr><th>Model</th><th>Optimize</th><th>Range of values</th></tr></thead><tbody><tr><td>Linear Regression</td><td>- fit_intercept<br /> - normalize</td><td>- True/False<br /> - True/False</td></tr><tr><td>Ridge</td><td>- alpha<br /> - fit_intercept<br /> - normalize</td><td>- 0.01, 0.1, 1.0, 10, 100<br /> - True/False<br /> - True/False</td></tr><tr><td>k-neighbors</td><td>- n_neighbors<br /> - p</td><td>- 2, 4, 8, 16, …<br /> - 2, 3, …</td></tr><tr><td>SVM</td><td>- C<br /> - gamma<br /> - class_weight</td><td>- 0.001, 0.01, …,10, 100, 1000<br /> - ‘auto’, RS*<br /> - ‘balanced’, None</td></tr><tr><td>Logistic Regression</td><td>- Penalyt<br /> - C</td><td>- L1 or L2<br /> - 0.001, 0.01, …, 10, …, 100</td></tr><tr><td>Lasso</td><td>- Alpha<br /> - Normalize</td><td>- 0.1, 1.0, 10<br /> - True/False</td></tr><tr><td>Random Forest</td><td>- n_estimators<br/> - max_depth<br/> - min_samples_split <br/> - min_samples_leaf <br/> - max features</td><td>- 120, 300, 500, 800, 1200<br /> - 5, 8, 15, 25, 30, None<br /> - 1, 2, 5, 10, 15, 100<br /> - log2, sqrt, None</td></tr><tr><td>XGBoost</td><td>- eta<br/> - gamma<br/> - max_depth<br/> - min_child_weight<br/> - subsample<br/> - colsample_bytree<br/> - lambda<br/> - alpha</td><td>- 0.01, 0.015, 0.025, 0.05, 0.1<br /> - 0.05, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0<br /> - 3, 5, 7, 9, 12, 15, 17, 25<br /> - 1, 3, 5, 7<br /> - 0.6, 0.7, 0.8, 0.9, 1.0<br /> - 0.6, 0.7, 0.8, 0.9, 1.0<br /> - 0.01, 0.1, 1.0, RS<em><br /> - 0, 0.1, 0.5, 1.0, RS</em></td></tr></tbody></table></div>]]></content>
      
      
      <categories>
          
          <category> AAAMLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>评估指标</title>
      <link href="/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/"/>
      <url>/AAAMLP/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/AAAMLprob/%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</url>
      
        <content type="html"><![CDATA[<h1 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h1><p>说到机器学习问题，你会在现实世界中遇到很多不同类型的指标。有时，人们甚至会根据业务问题创建度量标准。逐一介绍和解释每一种度量类型超出了本书的范围。相反，我们将介绍一些最常见的度量标准，供你在最初的几个项目中使用。</p><p>在本书的开头，我们介绍了监督学习和非监督学习。虽然无监督学习可以使用一些指标，但我们将只关注有监督学习。这是因为有监督问题比无监督问题多，而且对无监督方法的评估相当主观。</p><p>如果我们谈论分类问题，最常用的指标是：</p><ul><li>准确率（Accuracy）</li><li>精确率（P）</li><li>召回率（R）</li><li>F1 分数（F1）</li><li>AUC（AUC）</li><li>对数损失（Log loss）</li><li>k 精确率（P@k）</li><li>k 平均精率（AP@k）</li><li>k 均值平均精确率（MAP@k）</li></ul><p>说到回归，最常用的评价指标是</p><ul><li>平均绝对误差 （MAE）</li><li>均方误差 （MSE）</li><li>均方根误差 （RMSE）</li><li>均方根对数误差 （RMSLE）</li><li>平均百分比误差 （MPE）</li><li>平均绝对百分比误差 （MAPE）</li><li>R2</li></ul><p>了解上述指标的工作原理并不是我们必须了解的唯一事情。我们还必须知道何时使用哪些指标，而这取决于你有什么样的数据和目标。我认为这与目标有关，而与数据无关。</p><p>要进一步了解这些指标，让我们从一个简单的问题开始。假设我们有一个<strong>二元分类</strong>问题，即只有两个目标的问题，假设这是一个胸部 X 光图像分类问题。有的胸部 X 光图像没有问题，而有的胸部 X 光图像有肺塌陷，也就是所谓的气胸。因此，我们的任务是建立一个分类器，在给定胸部 X 光图像的情况下，它能检测出图像是否有气胸。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page30_image.png" alt=""></p><p align="center"><b>图 1：气胸肺部图像</b> </p><p>我们还假设有相同数量的气胸和非气胸胸部 X 光图像，比如各 100 张。因此，我们有 100 张阳性样本和 100 张阴性样本，共计 200 张图像。</p><p>第一步是将上述数据分为两组，每组 100 张图像，即训练集和验证集。在这两个集合中，我们都有 50 个正样本和 50 个负样本。</p><p>在二元分类指标中，当正负样本数量相等时，我们通常使用准确率、精确率、召回率和 F1。</p><p><strong>准确率</strong>：这是机器学习中最直接的指标之一。它定义了模型的准确度。对于上述问题，如果你建立的模型能准确分类 90 张图片，那么你的准确率就是 90% 或 0.90。如果只有 83 幅图像被正确分类，那么模型的准确率就是 83% 或 0.83。</p><p>计算准确率的 Python 代码也非常简单。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 为正确预测数初始化一个简单计数器</span></span><br><span class="line">    correct_counter = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历y_true，y_pred中所有元素</span></span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="keyword">if</span> yt == yp:</span><br><span class="line">            <span class="comment"># 如果预测标签与真实标签相同，则增加计数器</span></span><br><span class="line">            correct_counter += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 返回正确率，正确标签数/总标签数</span></span><br><span class="line">    <span class="keyword">return</span> correct_counter / <span class="built_in">len</span>(y_true)</span><br></pre></td></tr></table></figure><p>我们还可以使用 scikit-learn 计算准确率。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">In [X]: <span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">   ...: l1 = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">   ...: l2 = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">   ...: metrics.accuracy_score(l1, l2)</span><br><span class="line">Out[X]: <span class="number">0.625</span></span><br></pre></td></tr></table></figure><p>现在，假设我们把数据集稍微改动一下，有 180 张没有气胸的胸部 X 光图像，只有 20 张有气胸。即使在这种情况下，我们也要创建正负（气胸与非气胸）目标比例相同的训练集和验证集。在每一组中，我们有 90 张非气胸图像和 10 张气胸图像。如果说验证集中的所有图像都是非气胸图像，那么您的准确率会是多少呢？让我们来看看；您对 90% 的图像进行了正确分类。因此，您的准确率是 90%。</p><p>但请再看一遍。</p><p>你甚至没有建立一个模型，就得到了 90% 的准确率。这似乎有点没用。如果我们仔细观察，就会发现数据集是偏斜的，也就是说，一个类别中的样本数量比另一个类别中的样本数量多很多。在这种情况下，使用准确率作为评估指标是不可取的，因为它不能代表数据。因此，您可能会获得很高的准确率，但您的模型在实际样本中的表现可能并不理想，而且您也无法向经理解释原因。</p><p>在这种情况下，最好还是看看<strong>精确率</strong>等其他指标。</p><p>在学习精确率之前，我们需要了解一些术语。在这里，我们假设有气胸的胸部 X 光图像为正类 (1)，没有气胸的为负类 (0)。</p><p><strong>真阳性 （TP）</strong>： 给定一幅图像，如果您的模型预测该图像有气胸，而该图像的实际目标有气胸，则视为真阳性。</p><p><strong>真阴性 （TN）</strong>： 给定一幅图像，如果您的模型预测该图像没有气胸，而实际目标显示该图像没有气胸，则视为真阴性。</p><p>简单地说，如果您的模型正确预测了阳性类别，它就是真阳性；如果您的模型准确预测了阴性类别，它就是真阴性。</p><p><strong>假阳性 （FP）</strong>：给定一张图像，如果您的模型预测为气胸，而该图像的实际目标是非气胸，则为假阳性。</p><p><strong>假阴性 （FN）</strong>： 给定一幅图像，如果您的模型预测为非气胸，而该图像的实际目标是气胸，则为假阴性。</p><p>简单地说，如果您的模型错误地（或虚假地）预测了阳性类，那么它就是假阳性。如果模型错误地（或虚假地）预测了阴性类别，则是假阴性。</p><p>让我们逐一看看这些实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">true_positive</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 初始化真阳性样本计数器</span></span><br><span class="line">    tp = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历y_true，y_pred中所有元素</span></span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="comment"># 若真实标签为正类且预测标签也为正类，计数器增加</span></span><br><span class="line">        <span class="keyword">if</span> yt == <span class="number">1</span> <span class="keyword">and</span> yp == <span class="number">1</span>:</span><br><span class="line">            tp += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 返回真阳性样本数</span></span><br><span class="line">    <span class="keyword">return</span> tp</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">true_negative</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 初始化真阴性样本计数器</span></span><br><span class="line">    tn = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历y_true，y_pred中所有元素</span></span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">         <span class="comment"># 若真实标签为负类且预测标签也为负类，计数器增加</span></span><br><span class="line">        <span class="keyword">if</span> yt == <span class="number">0</span> <span class="keyword">and</span> yp == <span class="number">0</span>:</span><br><span class="line">            tn += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 返回真阴性样本数</span></span><br><span class="line">    <span class="keyword">return</span> tn</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">false_positive</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 初始化假阳性计数器</span></span><br><span class="line">    fp = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历y_true，y_pred中所有元素</span></span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="comment"># 若真实标签为负类而预测标签为正类，计数器增加</span></span><br><span class="line">        <span class="keyword">if</span> yt == <span class="number">0</span> <span class="keyword">and</span> yp == <span class="number">1</span>:</span><br><span class="line">            fp += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 返回假阳性样本数</span></span><br><span class="line">    <span class="keyword">return</span> fp</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">false_negative</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 初始化假阴性计数器</span></span><br><span class="line">    fn = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历y_true，y_pred中所有元素</span></span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="comment"># 若真实标签为正类而预测标签为负类，计数器增加</span></span><br><span class="line">        <span class="keyword">if</span> yt == <span class="number">1</span> <span class="keyword">and</span> yp == <span class="number">0</span>:</span><br><span class="line">            fn += <span class="number">1</span></span><br><span class="line">    <span class="comment"># 返回假阴性数</span></span><br><span class="line"><span class="keyword">return</span> fn</span><br></pre></td></tr></table></figure><p>我在这里实现这些功能的方法非常简单，而且只适用于二元分类。让我们检查一下这些函数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">In [X]: l1 = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">   ...: l2 = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">In [X]: true_positive(l1, l2)</span><br><span class="line">Out[X]: <span class="number">2</span></span><br><span class="line">In [X]: false_positive(l1, l2)</span><br><span class="line">Out[X]: <span class="number">1</span></span><br><span class="line">In [X]: false_negative(l1, l2)</span><br><span class="line">Out[X]: <span class="number">2</span></span><br><span class="line">In [X]: true_negative(l1, l2)</span><br><span class="line">Out[X]: <span class="number">3</span></span><br></pre></td></tr></table></figure><p>如果我们必须用上述术语来定义精确率，我们可以写为：</p><script type="math/tex; mode=display">Accuracy Score = (TP + TN)/(TP + TN + FP +FN)</script><p>现在，我们可以在 python 中使用 TP、TN、FP 和 FN 快速实现准确度得分。我们将其称为 accuracy_v2。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy_v2</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 真阳性样本数</span></span><br><span class="line">    tp = true_positive(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 假阳性样本数</span></span><br><span class="line">    fp = false_positive(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 假阴性样本数</span></span><br><span class="line">    fn = false_negative(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 真阴性样本数</span></span><br><span class="line">    tn = true_negative(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 准确率</span></span><br><span class="line">    accuracy_score = (tp + tn) / (tp + tn + fp + fn)</span><br><span class="line"><span class="keyword">return</span> accuracy_score</span><br></pre></td></tr></table></figure><p>我们可以通过与之前的实现和 scikit-learn 版本进行比较，快速检查该函数的正确性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [X]: l1 = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">   ...: l2 = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">In [X]: accuracy(l1, l2)</span><br><span class="line">Out[X]: <span class="number">0.625</span></span><br><span class="line">In [X]: accuracy_v2(l1, l2)</span><br><span class="line">Out[X]: <span class="number">0.625</span></span><br><span class="line">In [X]: metrics.accuracy_score(l1, l2)</span><br><span class="line">Out[X]: <span class="number">0.625</span></span><br></pre></td></tr></table></figure><p>请注意，在这段代码中，metrics.accuracy_score 来自 scikit-learn。</p><p>很好。所有值都匹配。这说明我们在实现过程中没有犯任何错误。</p><p>现在，我们可以转向其他重要指标。</p><p>首先是精确率。精确率的定义是</p><script type="math/tex; mode=display">Precision = TP/(TP + FP)</script><p>假设我们在新的偏斜数据集上建立了一个新模型，我们的模型正确识别了 90 张图像中的 80 张非气胸图像和 10 张图像中的 8 张气胸图像。因此，我们成功识别了 100 张图像中的 88 张。因此，准确率为 0.88 或 88%。</p><p>但是，在这 100 张样本中，有 10 张非气胸图像被误判为气胸，2 张气胸图像被误判为非气胸。</p><p>因此，我们有</p><ul><li>TP : 8</li><li>TN: 80</li><li>FP: 10</li><li>FN: 2</li></ul><p>精确率为 8 / (8 + 10) = 0.444。这意味着我们的模型在识别阳性样本（气胸）时有 44.4% 的正确率。</p><p>现在，既然我们已经实现了 TP、TN、FP 和 FN，我们就可以很容易地在 python 中实现精确率了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">precision</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 真阳性样本数</span></span><br><span class="line">    tp = true_positive(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 假阳性样本数</span></span><br><span class="line">    fp = false_positive(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 精确率</span></span><br><span class="line">    precision = tp / (tp + fp)</span><br><span class="line">    <span class="keyword">return</span> precision</span><br></pre></td></tr></table></figure><p>让我们试试这种精确率的实现方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [X]: l1 = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">   ...: l2 = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">In [X]: precision(l1, l2)</span><br><span class="line">Out[X]: <span class="number">0.6666666666666666</span></span><br></pre></td></tr></table></figure><p>这似乎没有问题。 接下来，我们来看<strong>召回率</strong>。召回率的定义是：</p><script type="math/tex; mode=display">Recall = TP/(TP + FN)</script><p>在上述情况下，召回率为 8 / (8 + 2) = 0.80。这意味着我们的模型正确识别了 80% 的阳性样本。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">recall</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 真阳性样本数</span></span><br><span class="line">    tp = true_positive(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 假阴性样本数</span></span><br><span class="line">    fn = false_negative(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 召回率</span></span><br><span class="line">    recall = tp / (tp + fn)</span><br><span class="line">    <span class="keyword">return</span> recall</span><br></pre></td></tr></table></figure><p>就我们的两个小列表而言，召回率应该是 0.5。让我们检查一下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">In [X]: l1 = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line">   ...: l2 = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>]</span><br><span class="line">In [X]: recall(l1, l2)</span><br><span class="line">Out[X]: <span class="number">0.5</span></span><br></pre></td></tr></table></figure><p>这与我们的计算值相符！</p><p>对于一个 “好 “模型来说，精确率和召回值都应该很高。我们看到，在上面的例子中，召回值相当高。但是，精确率却很低！我们的模型产生了大量的误报，但误报较少。在这类问题中，假阴性较少是好事，因为你不想在病人有气胸的情况下却说他们没有气胸。这样做会造成更大的伤害。但我们也有很多假阳性结果，这也不是好事。</p><p>大多数模型都会预测一个概率，当我们预测时，通常会将这个阈值选为 0.5。这个阈值并不总是理想的，根据这个阈值，精确率和召回率的值可能会发生很大的变化。如果我们选择的每个阈值都能计算出精确率和召回率，那么我们就可以在这些值之间绘制出曲线图。这幅图或曲线被称为 “精确率-召回率曲线”。</p><p>在研究精确率-调用曲线之前，我们先假设有两个列表。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">In [X]: y_true = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">   ...:          <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">In [X]: y_pred = [<span class="number">0.02638412</span>, <span class="number">0.11114267</span>, <span class="number">0.31620708</span>,</span><br><span class="line">   ...:          <span class="number">0.0490937</span>, <span class="number">0.0191491</span>, <span class="number">0.17554844</span>,</span><br><span class="line">   ...:          <span class="number">0.15952202</span>, <span class="number">0.03819563</span>, <span class="number">0.11639273</span>,</span><br><span class="line">   ...:          <span class="number">0.079377</span>,  <span class="number">0.08584789</span>, <span class="number">0.39095342</span>,</span><br><span class="line">   ...:          <span class="number">0.27259048</span>, <span class="number">0.03447096</span>, <span class="number">0.04644807</span>,</span><br><span class="line">   ...:          <span class="number">0.03543574</span>, <span class="number">0.18521942</span>, <span class="number">0.05934905</span>,</span><br><span class="line">   ...:          <span class="number">0.61977213</span>, <span class="number">0.33056815</span>]</span><br></pre></td></tr></table></figure><p>因此，y_true 是我们的目标值，而 y_pred 是样本被赋值为 1 的概率值。因此，现在我们要看的是预测中的概率，而不是预测值（大多数情况下，预测值的计算阈值为 0.5）。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">precisions = []</span><br><span class="line">recalls = []</span><br><span class="line">thresholds = [<span class="number">0.0490937</span> , <span class="number">0.05934905</span>, <span class="number">0.079377</span>,</span><br><span class="line">              <span class="number">0.08584789</span>, <span class="number">0.11114267</span>, <span class="number">0.11639273</span>,</span><br><span class="line">              <span class="number">0.15952202</span>, <span class="number">0.17554844</span>, <span class="number">0.18521942</span>,</span><br><span class="line">              <span class="number">0.27259048</span>, <span class="number">0.31620708</span>, <span class="number">0.33056815</span>,</span><br><span class="line">              <span class="number">0.39095342</span>, <span class="number">0.61977213</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历预测阈值</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> thresholds:</span><br><span class="line">    <span class="comment"># 若样本为正类（1）的概率大于阈值，为1，否则为0</span></span><br><span class="line">    temp_prediction = [<span class="number">1</span> <span class="keyword">if</span> x &gt;= i <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> y_pred]</span><br><span class="line">    <span class="comment"># 计算精确率</span></span><br><span class="line">    p = precision(y_true, temp_prediction)</span><br><span class="line">    <span class="comment"># 计算召回率</span></span><br><span class="line">    r = recall(y_true, temp_prediction)</span><br><span class="line">    <span class="comment"># 加入精确率列表</span></span><br><span class="line">    precisions.append(p)</span><br><span class="line">    <span class="comment"># 加入召回率列表</span></span><br><span class="line">    recalls.append(r)</span><br></pre></td></tr></table></figure><p>现在，我们可以绘制精确率-召回率曲线。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建画布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line"><span class="comment"># x轴为召回率，y轴为精确率</span></span><br><span class="line">plt.plot(recalls, precisions)</span><br><span class="line"><span class="comment"># 添加x轴标签，字体大小为15</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Recall&#x27;</span>, fontsize=<span class="number">15</span>)</span><br><span class="line"><span class="comment"># 添加y轴标签，字条大小为15</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Precision&#x27;</span>, fontsize=<span class="number">15</span>)</span><br></pre></td></tr></table></figure><p>图 2 显示了我们通过这种方法得到的精确率-召回率曲线。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page39_image.png" alt=""></p><p align="center"><b>图 2：精确率-召回率曲线</b> </p><p>这条<strong>精确率-召回率曲线</strong>与您在互联网上看到的曲线截然不同。这是因为我们只有 20 个样本，其中只有 3 个是阳性样本。但这没什么好担心的。这还是那条精确率-召回曲线。</p><p>你会发现，选择一个既能提供良好精确率又能提供召回值的阈值是很有挑战性的。如果阈值过高，真阳性的数量就会减少，而假阴性的数量就会增加。这会降低召回率，但精确率得分会很高。如果将阈值降得太低，则误报会大量增加，精确率也会降低。</p><p>精确率和召回率的范围都是从 0 到 1，越接近 1 越好。</p><p>F1 分数是精确率和召回率的综合指标。它被定义为精确率和召回率的简单加权平均值（调和平均值）。如果我们用 P 表示精确率，用 R 表示召回率，那么 F1 分数可以表示为：</p><script type="math/tex; mode=display">F1 = 2PR/(P + R)</script><p>根据 TP、FP 和 FN，稍加数学计算就能得出以下 F1 等式：</p><script type="math/tex; mode=display">F1 = 2TP/(2TP + FP + FN)</script><p>Python 实现很简单，因为我们已经实现了这些</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">f1</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 计算精确率</span></span><br><span class="line">    p = precision(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 计算召回率</span></span><br><span class="line">    r = recall(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 计算f1值</span></span><br><span class="line">    score = <span class="number">2</span> * p * r / (p + r)</span><br><span class="line">    <span class="keyword">return</span> score</span><br></pre></td></tr></table></figure><p>让我们看看其结果，并与 scikit-learn 进行比较。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">In [X]: y_true = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">   ...:          <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">In [X]: y_pred = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</span><br><span class="line">   ...:          <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]</span><br><span class="line">In [X]: f1(y_true, y_pred)</span><br><span class="line">Out[X]: <span class="number">0.5714285714285715</span></span><br></pre></td></tr></table></figure><p>通过 scikit learn，我们可以得到相同的列表：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">In [X]: <span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">In [X]: metrics.f1_score(y_true, y_pred)</span><br><span class="line">Out[X]: <span class="number">0.5714285714285715</span></span><br></pre></td></tr></table></figure><p>与其单独看精确率和召回率，您还可以只看 F1 分数。与精确率、召回率和准确度一样，F1 分数的范围也是从 0 到 1，完美预测模型的 F1 分数为 1。</p><p>此外，我们还应该了解其他一些关键术语。</p><p>第一个术语是 TPR 或真阳性率（True Positive Rate），它与召回率相同。</p><script type="math/tex; mode=display">TPR = TP/(TP + FN)</script><p>尽管它与召回率相同，但我们将为它创建一个 python 函数，以便今后使用这个名称。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">tpr</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 真阳性率（TPR），与召回率计算公式一致</span></span><br><span class="line"><span class="keyword">return</span> recall(y_true, y_pred)</span><br></pre></td></tr></table></figure><p>TPR 或召回率也被称为灵敏度。</p><p>而 FPR 或假阳性率（False Positive Rate）的定义是：</p><script type="math/tex; mode=display">FPR = FP / (TN + FP)</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fpr</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 假阳性样本数</span></span><br><span class="line">    fp = false_positive(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 真阴性样本数</span></span><br><span class="line">    tn = true_negative(y_true, y_pred)</span><br><span class="line"><span class="comment"># 返回假阳性率（FPR）</span></span><br><span class="line"><span class="keyword">return</span> fp / (tn + fp)</span><br></pre></td></tr></table></figure><p>1 - FPR 被称为特异性或真阴性率或 TNR。这些术语很多，但其中最重要的只有 TPR 和 FPR。假设我们只有 15 个样本，其目标值为二元：</p><p>Actual targets : [0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1]</p><p>我们训练一个类似随机森林的模型，就能得到样本呈阳性的概率。</p><p>Predicted probabilities for 1: [0.1, 0.3, 0.2, 0.6, 0.8, 0.05, 0.9, 0.5, 0.3, 0.66, 0.3, 0.2, 0.85, 0.15, 0.99]</p><p>对于 &gt;= 0.5 的典型阈值，我们可以评估上述所有精确率、召回率/TPR、F1 和 FPR 值。但是，如果我们将阈值选为 0.4 或 0.6，也可以做到这一点。事实上，我们可以选择 0 到 1 之间的任何值，并计算上述所有指标。</p><p>不过，我们只计算两个值： TPR 和 FPR。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化真阳性率列表</span></span><br><span class="line">tpr_list = []</span><br><span class="line"><span class="comment"># 初始化假阳性率列表</span></span><br><span class="line">fpr_list = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 真实样本标签</span></span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>,</span><br><span class="line">          <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测样本为正类（1）的概率</span></span><br><span class="line">y_pred = [<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.8</span>, <span class="number">0.05</span>,</span><br><span class="line">          <span class="number">0.9</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.66</span>, <span class="number">0.3</span>, <span class="number">0.2</span>,</span><br><span class="line">          <span class="number">0.85</span>, <span class="number">0.15</span>, <span class="number">0.99</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测阈值</span></span><br><span class="line">thresholds = [<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>,</span><br><span class="line">              <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.85</span>, <span class="number">0.9</span>, <span class="number">0.99</span>, <span class="number">1.0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历预测阈值</span></span><br><span class="line"><span class="keyword">for</span> thresh <span class="keyword">in</span> thresholds:</span><br><span class="line">    <span class="comment"># 若样本为正类（1）的概率大于阈值，为1，否则为0</span></span><br><span class="line">    temp_pred = [<span class="number">1</span> <span class="keyword">if</span> x &gt;= thresh <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> y_pred]</span><br><span class="line">    <span class="comment"># 真阳性率</span></span><br><span class="line">    temp_tpr = tpr(y_true, temp_pred)</span><br><span class="line">    <span class="comment"># 假阳性率</span></span><br><span class="line">    temp_fpr = fpr(y_true, temp_pred)</span><br><span class="line">    <span class="comment"># 将真阳性率加入列表</span></span><br><span class="line">    tpr_list.append(temp_tpr)</span><br><span class="line">    <span class="comment"># 将假阳性率加入列表</span></span><br><span class="line">    fpr_list.append(temp_fpr)</span><br></pre></td></tr></table></figure><p>因此，我们可以得到每个阈值的 TPR 值和 FPR 值。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page43_image.png" alt=""></p><p align="center"><b>图 3：阈值、TPR 和 FPR 值表</b> </p><p>如果我们绘制如图 3 所示的表格，即以 TPR 为 Y 轴，FPR 为 X 轴，就会得到如图 4 所示的曲线。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page44_image.png" alt=""></p><p align="center"><b>图 4：ROC曲线</b> </p><p>这条曲线也被称为 ROC 曲线。如果我们计算这条 ROC 曲线下的面积，就是在计算另一个指标，当数据集的二元目标偏斜时，这个指标就会非常常用。</p><p>这个指标被称为 ROC 曲线下面积或曲线下面积，简称 AUC。计算 ROC 曲线下面积的方法有很多。在此，我们将采用 scikit- learn 的奇妙实现方法。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In [X]: <span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">In [X]: y_true = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>,</span><br><span class="line">   ...:          <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">In [X]: y_pred = [<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.8</span>, <span class="number">0.05</span>,</span><br><span class="line">   ...:          <span class="number">0.9</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.66</span>, <span class="number">0.3</span>, <span class="number">0.2</span>,</span><br><span class="line">   ...:          <span class="number">0.85</span>, <span class="number">0.15</span>, <span class="number">0.99</span>]</span><br><span class="line">In [X]: metrics.roc_auc_score(y_true, y_pred)</span><br><span class="line">Out[X]: <span class="number">0.8300000000000001</span></span><br></pre></td></tr></table></figure><p>AUC 值从 0 到 1 不等。</p><ul><li>AUC = 1 意味着您拥有一个完美的模型。大多数情况下，这意味着你在验证时犯了一些错误，应该重新审视数据处理和验证流程。如果你没有犯任何错误，那么恭喜你，你已经拥有了针对数据集建立的最佳模型。</li><li>AUC = 0 意味着您的模型非常糟糕（或非常好！）。试着反转预测的概率，例如，如果您预测正类的概率是 p，试着用 1-p 代替它。这种 AUC 也可能意味着您的验证或数据处理存在问题。</li><li>AUC = 0.5 意味着你的预测是随机的。因此，对于任何二元分类问题，如果我将所有目标都预测为 0.5，我将得到 0.5 的 AUC。</li></ul><p>AUC 值介于 0 和 0.5 之间，意味着你的模型比随机模型更差。大多数情况下，这是因为你颠倒了类别。 如果您尝试反转预测，您的 AUC 值可能会超过 0.5。接近 1 的 AUC 值被认为是好值。</p><p>但 AUC 对我们的模型有什么影响呢？</p><p>假设您建立了一个从胸部 X 光图像中检测气胸的模型，其 AUC 值为 0.85。这意味着，如果您从数据集中随机选择一张有气胸的图像（阳性样本）和另一张没有气胸的图像（阴性样本），那么气胸图像的排名将高于非气胸图像，概率为 0.85。</p><p>计算概率和 AUC 后，您需要对测试集进行预测。根据问题和使用情况，您可能需要概率或实际类别。如果你想要概率，这并不难。如果您想要类别，则需要选择一个阈值。在二元分类的情况下，您可以采用类似下面的方法。</p><script type="math/tex; mode=display">Prediction = Probability >= Threshold</script><p>也就是说，预测是一个只包含二元变量的新列表。如果概率大于或等于给定的阈值，则预测中的一项为 1，否则为 0。</p><p>你猜怎么着，你可以使用 ROC 曲线来选择这个阈值！ROC 曲线会告诉您阈值对假阳性率和真阳性率的影响，进而影响假阳性和真阳性。您应该选择最适合您的问题和数据集的阈值。</p><p>例如，如果您不希望有太多的误报，那么阈值就应该高一些。不过，这也会带来更多的误报。注意权衡利弊，选择最佳阈值。让我们看看这些阈值如何影响真阳性和假阳性值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 真阳性样本数列表</span></span><br><span class="line">tp_list = []</span><br><span class="line"><span class="comment"># 假阳性样本数列表</span></span><br><span class="line">fp_list = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 真实标签</span></span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>,</span><br><span class="line">          <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测样本为正类（1）的概率</span></span><br><span class="line">y_pred = [<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.8</span>, <span class="number">0.05</span>,</span><br><span class="line">          <span class="number">0.9</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.66</span>, <span class="number">0.3</span>, <span class="number">0.2</span>,</span><br><span class="line">          <span class="number">0.85</span>, <span class="number">0.15</span>, <span class="number">0.99</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测阈值</span></span><br><span class="line">thresholds = [<span class="number">0</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>, <span class="number">0.4</span>, <span class="number">0.5</span>,</span><br><span class="line">              <span class="number">0.6</span>, <span class="number">0.7</span>, <span class="number">0.8</span>, <span class="number">0.85</span>, <span class="number">0.9</span>, <span class="number">0.99</span>, <span class="number">1.0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历预测阈值</span></span><br><span class="line"><span class="keyword">for</span> thresh <span class="keyword">in</span> thresholds:</span><br><span class="line">    <span class="comment"># 若样本为正类（1）的概率大于阈值，为1，否则为0</span></span><br><span class="line">    temp_pred = [<span class="number">1</span> <span class="keyword">if</span> x &gt;= thresh <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> x <span class="keyword">in</span> y_pred]</span><br><span class="line">    <span class="comment"># 真阳性样本数</span></span><br><span class="line">    temp_tp = true_positive(y_true, temp_pred)</span><br><span class="line">    <span class="comment"># 假阳性样本数</span></span><br><span class="line">    temp_fp = false_positive(y_true, temp_pred)</span><br><span class="line">    <span class="comment"># 加入真阳性样本数列表</span></span><br><span class="line">    tp_list.append(temp_tp)</span><br><span class="line">    <span class="comment"># 加入假阳性样本数列表</span></span><br><span class="line">    fp_list.append(temp_fp)</span><br></pre></td></tr></table></figure><p>利用这一点，我们可以创建一个表格，如图 5 所示。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page47_image.png" alt=""></p><p align="center"><b>图 5：不同阈值的 TP 值和 FP 值</b> </p><p>如图 6 所示，大多数情况下，ROC 曲线左上角的值应该是一个相当不错的阈值。</p><p>对比表格和 ROC 曲线，我们可以发现，0.6 左右的阈值相当不错，既不会丢失大量的真阳性结果，也不会出现大量的假阳性结果。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page48_image.png" alt=""></p><p align="center"><b>图 6：从 ROC 曲线最左侧的顶点选择最佳阈值</b> </p><p>AUC 是业内广泛应用于偏斜二元分类任务的指标，也是每个人都应该了解的指标。一旦理解了 AUC 背后的理念（如上文所述），也就很容易向业界可能会评估您的模型的非技术人员解释它了。</p><p>学习 AUC 后，你应该学习的另一个重要指标是对数损失。对于二元分类问题，我们将对数损失定义为：</p><script type="math/tex; mode=display">LogLoss = -1.0 \times (target \times log(prediction) + (1-target) \times log(1-prediction))</script><p>其中，目标值为 0 或 1，预测值为样本属于类别 1 的概率。</p><p>对于数据集中的多个样本，所有样本的对数损失只是所有单个对数损失的平均值。需要记住的一点是，对数损失会对不正确或偏差较大的预测进行相当高的惩罚，也就是说，对数损失会对非常确定和非常错误的预测进行惩罚。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">log_loss</span>(<span class="params">y_true, y_proba</span>):</span><br><span class="line">    <span class="comment"># 极小值，防止0做分母</span></span><br><span class="line">    epsilon = <span class="number">1e-15</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对数损失列表</span></span><br><span class="line">    loss = []</span><br><span class="line">    <span class="comment"># 遍历y_true，y_pred中所有元素</span></span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_proba):</span><br><span class="line">        <span class="comment"># 限制yp范围，最小为epsilon，最大为1-epsilon</span></span><br><span class="line">        yp = np.clip(yp, epsilon, <span class="number">1</span> - epsilon)</span><br><span class="line">        <span class="comment"># 计算对数损失</span></span><br><span class="line">        temp_loss = - <span class="number">1.0</span> * (yt * np.log(yp)+ (<span class="number">1</span> - yt) * np.log(<span class="number">1</span> - yp))</span><br><span class="line">        <span class="comment"># 加入对数损失列表</span></span><br><span class="line">        loss.append(temp_loss)</span><br><span class="line"><span class="keyword">return</span> np.mean(loss)</span><br></pre></td></tr></table></figure><p>让我们测试一下函数执行情况：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [X]: y_true = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>,</span><br><span class="line">   ...:          <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">In [X]: y_proba = [<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.2</span>, <span class="number">0.6</span>, <span class="number">0.8</span>, <span class="number">0.05</span>,</span><br><span class="line">   ...:          <span class="number">0.9</span>, <span class="number">0.5</span>, <span class="number">0.3</span>, <span class="number">0.66</span>, <span class="number">0.3</span>, <span class="number">0.2</span>,</span><br><span class="line">   ...:          <span class="number">0.85</span>, <span class="number">0.15</span>, <span class="number">0.99</span>]</span><br><span class="line">In [X]: log_loss(y_true, y_proba)</span><br><span class="line">Out[X]: <span class="number">0.49882711861432294</span></span><br></pre></td></tr></table></figure><p>我们可以将其与 scikit-learn 进行比较：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">In [X]: <span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">In [X]: metrics.log_loss(y_true, y_proba)</span><br><span class="line">Out[X]: <span class="number">0.49882711861432294</span></span><br></pre></td></tr></table></figure><p>因此，我们的实现是正确的。 对数损失的实现很容易。解释起来似乎有点困难。你必须记住，对数损失的惩罚要比其他指标大得多。</p><p>例如，如果您有 51% 的把握认为样本属于第 1 类，那么对数损失就是：</p><script type="math/tex; mode=display">-1.0 \times (1 \times log(0.51) + (1 - 1) \times log(1 - 0.51))=0.67</script><p>如果你对属于 0 类的样本有 49% 的把握，对数损失就是：</p><script type="math/tex; mode=display">-1.0 \times (1 \times log(0.49) + (1 - 1) \times log(1 - 0.49))=0.67</script><p>因此，即使我们可以选择 0.5 的截断值并得到完美的预测结果，我们仍然会有非常高的对数损失。因此，在处理对数损失时，你需要非常小心；任何不确定的预测都会产生非常高的对数损失。</p><p>我们之前讨论过的大多数指标都可以转换成多类版本。这个想法很简单。以精确率和召回率为例。我们可以计算多类分类问题中每一类的精确率和召回率。</p><p>有三种不同的计算方法，有时可能会令人困惑。假设我们首先对精确率感兴趣。我们知道，精确率取决于真阳性和假阳性。</p><ul><li><strong>宏观平均精确率</strong>（Macro averaged precision）：分别计算所有类别的精确率然后求平均值</li><li><strong>微观平均精确率</strong>（Micro averaged precision）：按类计算真阳性和假阳性，然后用其计算总体精确率。然后以此计算总体精确率</li><li><strong>加权精确率</strong>（Weighted precision）：与宏观精确率相同，但这里是加权平均精确率 取决于每个类别中的项目数</li></ul><p>这看似复杂，但在 python 实现中很容易理解。让我们看看宏观平均精确率是如何实现的。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">macro_precision</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 种类数</span></span><br><span class="line">    num_classes = <span class="built_in">len</span>(np.unique(y_true))</span><br><span class="line">    <span class="comment"># 初始化精确率</span></span><br><span class="line">    precision = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历0~（种类数-1）</span></span><br><span class="line">    <span class="keyword">for</span> class_ <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">        <span class="comment"># 若真实标签为class_为1，否则为0</span></span><br><span class="line">        temp_true = [<span class="number">1</span> <span class="keyword">if</span> p == class_ <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> p <span class="keyword">in</span> y_true]</span><br><span class="line">        <span class="comment"># 如预测标签为class_为1，否则为0</span></span><br><span class="line">        temp_pred = [<span class="number">1</span> <span class="keyword">if</span> p == class_ <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> p <span class="keyword">in</span> y_pred]</span><br><span class="line">        <span class="comment"># 真阳性样本数</span></span><br><span class="line">        tp = true_positive(temp_true, temp_pred)</span><br><span class="line">        <span class="comment"># 假阳性样本数</span></span><br><span class="line">        fp = false_positive(temp_true, temp_pred)</span><br><span class="line">        <span class="comment"># 计算精确度</span></span><br><span class="line">        temp_precision = tp / (tp + fp)</span><br><span class="line">        <span class="comment"># 各类精确率相加</span></span><br><span class="line">        precision += temp_precision</span><br><span class="line">    <span class="comment"># 计算平均值</span></span><br><span class="line">    precision /= num_classes</span><br><span class="line"><span class="keyword">return</span> precision</span><br></pre></td></tr></table></figure><p>你会发现这并不难。同样，我们还有微平均精确率分数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">micro_precision</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 种类数</span></span><br><span class="line">    num_classes = <span class="built_in">len</span>(np.unique(y_true))</span><br><span class="line">    <span class="comment"># 初始化真阳性样本数</span></span><br><span class="line">    tp = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 初始化假阳性样本数</span></span><br><span class="line">    fp = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历0~（种类数-1）</span></span><br><span class="line">    <span class="keyword">for</span> class_ <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">        <span class="comment"># 若真实标签为class_为1，否则为0</span></span><br><span class="line">        temp_true = [<span class="number">1</span> <span class="keyword">if</span> p == class_ <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> p <span class="keyword">in</span> y_true]</span><br><span class="line">        <span class="comment"># 若预测标签为class_为1，否则为0</span></span><br><span class="line">        temp_pred = [<span class="number">1</span> <span class="keyword">if</span> p == class_ <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> p <span class="keyword">in</span> y_pred]</span><br><span class="line">        <span class="comment"># 真阳性样本数相加</span></span><br><span class="line">        tp += true_positive(temp_true, temp_pred)</span><br><span class="line">        <span class="comment"># 假阳性样本数相加</span></span><br><span class="line">        fp += false_positive(temp_true, temp_pred)</span><br><span class="line">    <span class="comment"># 精确率</span></span><br><span class="line">precision = tp / (tp + fp)</span><br><span class="line"><span class="keyword">return</span> precision</span><br></pre></td></tr></table></figure><p>这也不难。那什么难？什么都不难。机器学习很简单。现在，让我们来看看加权精确率的实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">weighted_precision</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 种类数</span></span><br><span class="line">    num_classes = <span class="built_in">len</span>(np.unique(y_true))</span><br><span class="line">    <span class="comment"># 统计各种类样本数</span></span><br><span class="line">    class_counts = Counter(y_true)</span><br><span class="line">    <span class="comment"># 初始化精确率</span></span><br><span class="line">    precision = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历0~（种类数-1）</span></span><br><span class="line">    <span class="keyword">for</span> class_ <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">        <span class="comment"># 若真实标签为class_为1，否则为0</span></span><br><span class="line">        temp_true = [<span class="number">1</span> <span class="keyword">if</span> p == class_ <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> p <span class="keyword">in</span> y_true]</span><br><span class="line">        <span class="comment"># 若预测标签为class_为1，否则为0</span></span><br><span class="line">        temp_pred = [<span class="number">1</span> <span class="keyword">if</span> p == class_ <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> p <span class="keyword">in</span> y_pred]</span><br><span class="line">        <span class="comment"># 真阳性样本数</span></span><br><span class="line">        tp = true_positive(temp_true, temp_pred)</span><br><span class="line">        <span class="comment"># 假阳性样本数</span></span><br><span class="line">        fp = false_positive(temp_true, temp_pred)</span><br><span class="line">        <span class="comment"># 精确率</span></span><br><span class="line">        temp_precision = tp / (tp + fp)</span><br><span class="line">        <span class="comment"># 根据该种类样本数分配权重</span></span><br><span class="line">        weighted_precision = class_counts[class_] * temp_precision</span><br><span class="line">        <span class="comment"># 加权精确率求和</span></span><br><span class="line">        precision += weighted_precision</span><br><span class="line">    <span class="comment"># 计算平均精确率</span></span><br><span class="line">overall_precision = precision / <span class="built_in">len</span>(y_true)</span><br><span class="line"><span class="keyword">return</span> overall_precision</span><br></pre></td></tr></table></figure><p>将我们的实现与 scikit-learn 进行比较，以了解实现是否正确。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">In [X]: <span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">In [X]: y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">In [X]: y_pred = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>]</span><br><span class="line">In [X]: macro_precision(y_true, y_pred)</span><br><span class="line">Out[X]: <span class="number">0.3611111111111111</span></span><br><span class="line">In [X]: metrics.precision_score(y_true, y_pred, average=<span class="string">&quot;macro&quot;</span>)</span><br><span class="line">Out[X]: <span class="number">0.3611111111111111</span></span><br><span class="line">In [X]: micro_precision(y_true, y_pred)</span><br><span class="line">Out[X]: <span class="number">0.4444444444444444</span></span><br><span class="line">In [X]: metrics.precision_score(y_true, y_pred, average=<span class="string">&quot;micro&quot;</span>)</span><br><span class="line">Out[X]: <span class="number">0.4444444444444444</span></span><br><span class="line">In [X]: weighted_precision(y_true, y_pred)</span><br><span class="line">Out[X]: <span class="number">0.39814814814814814</span></span><br><span class="line">In [X]: metrics.precision_score(y_true, y_pred, average=<span class="string">&quot;weighted&quot;</span>)</span><br><span class="line">Out[X]: <span class="number">0.39814814814814814</span></span><br></pre></td></tr></table></figure><p>看来我们已经正确地实现了一切。 请注意，这里展示的实现可能不是最有效的，但却是最容易理解的。</p><p>同样，我们也可以实现<strong>多类别的召回率指标</strong>。精确率和召回率取决于真阳性、假阳性和假阴性，而 F1 则取决于精确率和召回率。</p><p>召回率的实现方法留待读者练习，这里实现的是多类 F1 的一个版本，即加权平均值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">weighted_f1</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 种类数</span></span><br><span class="line">    num_classes = <span class="built_in">len</span>(np.unique(y_true))</span><br><span class="line">    <span class="comment"># 统计各种类样本数</span></span><br><span class="line">    class_counts = Counter(y_true)</span><br><span class="line">    <span class="comment"># 初始化F1值</span></span><br><span class="line">    f1 = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历0~（种类数-1）</span></span><br><span class="line">    <span class="keyword">for</span> class_ <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">        <span class="comment"># 若真实标签为class_为1，否则为0</span></span><br><span class="line">        temp_true = [<span class="number">1</span> <span class="keyword">if</span> p == class_ <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> p <span class="keyword">in</span> y_true]</span><br><span class="line">        <span class="comment"># 若预测标签为class_为1，否则为0</span></span><br><span class="line">        temp_pred = [<span class="number">1</span> <span class="keyword">if</span> p == class_ <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> p <span class="keyword">in</span> y_pred]</span><br><span class="line">        <span class="comment"># 计算精确率</span></span><br><span class="line">        p = precision(temp_true, temp_pred)</span><br><span class="line">        <span class="comment"># 计算召回率</span></span><br><span class="line">        r = recall(temp_true, temp_pred)</span><br><span class="line">        <span class="comment"># 若精确率+召回率不为0，则使用公式计算F1值</span></span><br><span class="line">        <span class="keyword">if</span> p + r != <span class="number">0</span>:</span><br><span class="line">            temp_f1 = <span class="number">2</span> * p * r / (p + r)</span><br><span class="line">        <span class="comment"># 否则直接为0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            temp_f1 = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 根据样本数分配权重</span></span><br><span class="line">weighted_f1 = class_counts[class_] * temp_f1</span><br><span class="line">        <span class="comment"># 加权F1值相加</span></span><br><span class="line">        f1 += weighted_f1</span><br><span class="line">    <span class="comment"># 计算加权平均F1值</span></span><br><span class="line">    overall_f1 = f1 / <span class="built_in">len</span>(y_true)</span><br><span class="line"><span class="keyword">return</span> overall_f1</span><br></pre></td></tr></table></figure><p>请注意，上面有几行代码是新写的。因此，你应该仔细阅读这些代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [X]: <span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">In [X]: y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line">In [X]: y_pred = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>]</span><br><span class="line">In [X]: weighted_f1(y_true, y_pred)</span><br><span class="line">Out[X]: <span class="number">0.41269841269841273</span></span><br><span class="line">In [X]: metrics.f1_score(y_true, y_pred, average=<span class="string">&quot;weighted&quot;</span>)</span><br><span class="line">Out[X]: <span class="number">0.41269841269841273</span></span><br></pre></td></tr></table></figure><p>因此，我们已经为多类问题实现了精确率、召回率和 F1。同样，您也可以将 AUC 和对数损失转换为多类格式。这种转换格式被称为 <strong>one-vs-all</strong>。这里我不打算实现它们，因为实现方法与我们已经讨论过的很相似。</p><p>在二元或多类分类中，看一下<strong>混淆矩阵</strong>也很流行。不要困惑，这很简单。混淆矩阵只不过是一个包含 TP、FP、TN 和 FN 的表格。使用混淆矩阵，您可以快速查看有多少样本被错误分类，有多少样本被正确分类。也许有人会说，混淆矩阵应该在本章很早就讲到，但我没有这么做。如果了解了 TP、FP、TN、FN、精确率、召回率和 AUC，就很容易理解和解释混淆矩阵了。让我们看看图 7 中二元分类问题的混淆矩阵。</p><p>我们可以看到，混淆矩阵由 TP、FP、FN 和 TN 组成。我们只需要这些值来计算精确率、召回率、F1 分数和 AUC。有时，人们也喜欢把 FP 称为<strong>第一类错误</strong>，把 FN 称为<strong>第二类错误</strong>。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page57_image.png" alt=""></p><p align="center"><b>图 7：二元分类任务的混淆矩阵</b> </p><p>我们还可以将二元混淆矩阵扩展为多类混淆矩阵。它会是什么样子呢？如果我们有 N 个类别，它将是一个大小为 NxN 的矩阵。对于每个类别，我们都要计算相关类别和其他类别的样本总数。举个例子可以让我们更好地理解这一点。</p><p>假设我们有以下真实标签：</p><script type="math/tex; mode=display">[0, 1, 2, 0, 1, 2, 0, 2, 2]</script><p>我们的预测标签是：</p><script type="math/tex; mode=display">[0, 2, 1, 0, 2, 1, 0, 0, 2]</script><p>那么，我们的混淆矩阵将如图 8 所示。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page58_image.png" alt=""></p><p align="center"><b>图 8：多分类问题的混淆矩阵</b> </p><p>图 8 说明了什么？</p><p>让我们来看看 0 类。我们看到，在真实标签中，有 3 个样本属于 0 类。然而，在预测中，我们有 3 个样本属于第 0 类，1 个样本属于第 1 类。理想情况下，对于真实标签中的类别 0，预测标签 1 和 2 应该没有任何样本。让我们看看类别 2。在真实标签中，这个数字加起来是 4，而在预测标签中，这个数字加起来是 3。</p><p>一个完美的混淆矩阵只能从左到右斜向填充。</p><p><strong>混淆矩阵</strong>提供了一种简单的方法来计算我们之前讨论过的不同指标。Scikit-learn 提供了一种简单直接的方法来生成混淆矩阵。请注意，我在图 8 中显示的混淆矩阵是 scikit-learn 混淆矩阵的转置，原始版本可以通过以下代码绘制。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line"><span class="comment"># 真实样本标签</span></span><br><span class="line">y_true = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line"><span class="comment"># 预测样本标签</span></span><br><span class="line">y_pred = [<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算混淆矩阵</span></span><br><span class="line">cm = metrics.confusion_matrix(y_true, y_pred)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建画布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line"><span class="comment"># 创建方格</span></span><br><span class="line">cmap = sns.cubehelix_palette(<span class="number">50</span>, hue=<span class="number">0.05</span>, rot=<span class="number">0</span>, light=<span class="number">0.9</span>, dark=<span class="number">0</span>,</span><br><span class="line">as_cmap=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 规定字体大小</span></span><br><span class="line">sns.<span class="built_in">set</span>(font_scale=<span class="number">2.5</span>)</span><br><span class="line"><span class="comment"># 绘制热图</span></span><br><span class="line">sns.heatmap(cm, annot=<span class="literal">True</span>, cmap=cmap, cbar=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># y轴标签，字体大小为20</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Actual Labels&#x27;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line"><span class="comment"># x轴标签，字体大小为20</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Predicted Labels&#x27;</span>, fontsize=<span class="number">20</span>)</span><br></pre></td></tr></table></figure><p>因此，到目前为止，我们已经解决了二元分类和多类分类的度量问题。接下来，我们将讨论另一种类型的分类问题，即多标签分类。在多标签分类中，每个样本都可能与一个或多个类别相关联。这类问题的一个简单例子就是要求你预测给定图像中的不同物体。</p><p>图 9 显示了一个著名数据集的图像示例。请注意，该数据集的目标有所不同，但我们暂且不去讨论它。我们假设其目的只是预测图像中是否存在某个物体。在图 9 中，我们有椅子、花盆、窗户，但没有其他物体，如电脑、床、电视等。因此，一幅图像可能有多个相关目标。这类问题就是多标签分类问题。</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/AAAMLP_page59_image.png" alt=""></p><p align="center"><b>图 9：图像中的不同物体</b> </p><p>这类分类问题的衡量标准有些不同。一些合适的 最常见的指标有：</p><ul><li>k 精确率（P@k）</li><li>k 平均精确率（AP@k）</li><li>k 均值平均精确率（MAP@k）</li><li>对数损失（Log loss）</li></ul><p>让我们从<strong>k 精确率或者 P@k</strong>我们不能将这一精确率与前面讨论的精确率混淆。如果您有一个给定样本的原始类别列表和同一个样本的预测类别列表，那么精确率的定义就是预测列表中仅考虑前 k 个预测结果的命中数除以 k。</p><p>如果您对此感到困惑，使用 python 代码后就会明白。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">pk</span>(<span class="params">y_true, y_pred, k</span>):</span><br><span class="line">    <span class="comment"># 如果k为0</span></span><br><span class="line">    <span class="keyword">if</span> k == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 返回0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="comment"># 取预测标签前k个</span></span><br><span class="line">    y_pred = y_pred[:k]</span><br><span class="line">    <span class="comment"># 将预测标签转换为集合</span></span><br><span class="line">    pred_set = <span class="built_in">set</span>(y_pred)</span><br><span class="line">    <span class="comment"># 将真实标签转换为集合</span></span><br><span class="line">    true_set = <span class="built_in">set</span>(y_true)</span><br><span class="line">    <span class="comment"># 预测标签集合与真实标签集合交集</span></span><br><span class="line">    common_values = pred_set.intersection(true_set)</span><br><span class="line">    <span class="comment"># 计算精确率</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(common_values) / <span class="built_in">len</span>(y_pred[:k])</span><br></pre></td></tr></table></figure><p>有了代码，一切都变得更容易理解了。</p><p>现在，我们有了<strong>k 平均精确率或 AP@k</strong>。AP@k 是通过 P@k 计算得出的。例如，如果要计算 AP@3，我们要先计算 P@1、P@2 和 P@3，然后将总和除以 3。</p><p>让我们来看看它的实现。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">apk</span>(<span class="params">y_true, y_pred, k</span>):</span><br><span class="line">    <span class="comment"># 初始化P@k列表</span></span><br><span class="line">    pk_values = []</span><br><span class="line">    <span class="comment"># 遍历1~k</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, k + <span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 将P@k加入列表</span></span><br><span class="line">        pk_values.append(pk(y_true, y_pred, i))</span><br><span class="line">    <span class="comment"># 若长度为0</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(pk_values) == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 返回0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="comment"># 否则计算AP@K</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(pk_values) / <span class="built_in">len</span>(pk_values)</span><br></pre></td></tr></table></figure><p>这两个函数可以用来计算两个给定列表的 k 平均精确率 (AP@k)；让我们看看如何计算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">In [X]: y_true = [</span><br><span class="line">   ...:     [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">   ...:     [<span class="number">0</span>, <span class="number">2</span>],</span><br><span class="line">   ...:     [<span class="number">1</span>],</span><br><span class="line">   ...:     [<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">   ...:     [<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">   ...:     []</span><br><span class="line">   ...: ]</span><br><span class="line">In [X]: y_pred = [</span><br><span class="line">   ...:     [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">   ...:     [<span class="number">1</span>],</span><br><span class="line">   ...:     [<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">   ...:     [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>],</span><br><span class="line">   ...:     [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">   ...:     [<span class="number">0</span>]</span><br><span class="line">   ...: ]</span><br><span class="line">In [X]: <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y_true)):</span><br><span class="line">   ...:    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">4</span>):</span><br><span class="line">   ...:         <span class="built_in">print</span>(</span><br><span class="line">   ...:            <span class="string">f&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">   ...:             y_true=<span class="subst">&#123;y_true[i]&#125;</span>,</span></span><br><span class="line"><span class="string">   ...:             y_pred=<span class="subst">&#123;y_pred[i]&#125;</span>,</span></span><br><span class="line"><span class="string">   ...:             AP@<span class="subst">&#123;j&#125;</span>=<span class="subst">&#123;apk(y_true[i], y_pred[i], k=j)&#125;</span></span></span><br><span class="line"><span class="string">   ...:             &quot;&quot;&quot;</span></span><br><span class="line">   ...:         )</span><br><span class="line">   ...:</span><br><span class="line">        y_true=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        y_pred=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        AP@<span class="number">1</span>=<span class="number">0.0</span></span><br><span class="line">        y_true=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        y_pred=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        AP@<span class="number">2</span>=<span class="number">0.25</span></span><br><span class="line">        y_true=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        y_pred=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        AP@<span class="number">3</span>=<span class="number">0.38888888888888884</span></span><br></pre></td></tr></table></figure><p>请注意，我省略了输出结果中的许多数值，但你会明白其中的意思。这就是我们如何计算 AP@k 的方法，即每个样本的 AP@k。在机器学习中，我们对所有样本都感兴趣，这就是为什么我们有<strong>均值平均精确率 k 或 MAP@k</strong>。MAP@k 只是 AP@k 的平均值，可以通过以下 python 代码轻松计算。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mapk</span>(<span class="params">y_true, y_pred, k</span>):</span><br><span class="line">    <span class="comment"># 初始化AP@k列表</span></span><br><span class="line">    apk_values = []</span><br><span class="line">    <span class="comment"># 遍历0~（真实标签数-1）</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(y_true)):</span><br><span class="line">        <span class="comment"># 将AP@K加入列表</span></span><br><span class="line">        apk_values.append(</span><br><span class="line">            apk(y_true[i], y_pred[i], k=k)</span><br><span class="line">        )</span><br><span class="line">    <span class="comment"># 计算平均AP@k</span></span><br><span class="line"><span class="keyword">return</span> <span class="built_in">sum</span>(apk_values) / <span class="built_in">len</span>(apk_values)</span><br></pre></td></tr></table></figure><p>现在，我们可以针对相同的列表计算 k=1、2、3 和 4 时的 MAP@k。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">In [X]: y_true = [</span><br><span class="line">   ...:     [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">   ...:     [<span class="number">0</span>, <span class="number">2</span>],</span><br><span class="line">   ...:     [<span class="number">1</span>],</span><br><span class="line">   ...:     [<span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">   ...:     [<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">   ...:     []</span><br><span class="line">   ...: ]</span><br><span class="line">In [X]: y_pred = [</span><br><span class="line">   ...:     [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">   ...:     [<span class="number">1</span>],</span><br><span class="line">   ...:     [<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">   ...:     [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">0</span>],</span><br><span class="line">   ...:     [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">   ...:     [<span class="number">0</span>]</span><br><span class="line">   ...: ]</span><br><span class="line">In [X]: mapk(y_true, y_pred, k=<span class="number">1</span>)</span><br><span class="line">Out[X]: <span class="number">0.3333333333333333</span></span><br><span class="line">In [X]: mapk(y_true, y_pred, k=<span class="number">2</span>)</span><br><span class="line">Out[X]: <span class="number">0.375</span></span><br><span class="line">In [X]: mapk(y_true, y_pred, k=<span class="number">3</span>)</span><br><span class="line">Out[X]: <span class="number">0.3611111111111111</span></span><br><span class="line">In [X]: mapk(y_true, y_pred, k=<span class="number">4</span>)</span><br><span class="line">Out[X]: <span class="number">0.34722222222222215</span></span><br></pre></td></tr></table></figure><p>P@k、AP@k 和 MAP@k 的范围都是从 0 到 1，其中 1 为最佳。</p><p>请注意，有时您可能会在互联网上看到 P@k 和 AP@k 的不同实现方式。 例如，让我们来看看其中一种实现方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">apk</span>(<span class="params">actual, predicted, k=<span class="number">10</span></span>):</span><br><span class="line">    <span class="comment"># 若预测标签长度大于k</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(predicted)&gt;k:</span><br><span class="line">        <span class="comment"># 取前k个标签</span></span><br><span class="line">predicted = predicted[:k]</span><br><span class="line"></span><br><span class="line">    score = <span class="number">0.0</span></span><br><span class="line">    num_hits = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i,p <span class="keyword">in</span> <span class="built_in">enumerate</span>(predicted):</span><br><span class="line"><span class="keyword">if</span> p <span class="keyword">in</span> actual <span class="keyword">and</span> p <span class="keyword">not</span> <span class="keyword">in</span> predicted[:i]:</span><br><span class="line">num_hits += <span class="number">1.0</span></span><br><span class="line">score += num_hits / (i+<span class="number">1.0</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> actual:</span><br><span class="line"><span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line"><span class="keyword">return</span> score / <span class="built_in">min</span>(<span class="built_in">len</span>(actual), k)</span><br></pre></td></tr></table></figure><p>这种实现方式是 AP@k 的另一个版本，其中顺序很重要，我们要权衡预测结果。这种实现方式的结果与我的介绍略有不同。</p><p>现在，我们来看看<strong>多标签分类的对数损失</strong>。这很容易。您可以将目标转换为二元分类，然后对每一列使用对数损失。最后，你可以求出每列对数损失的平均值。这也被称为平均列对数损失。当然，还有其他方法可以实现这一点，你应该在遇到时加以探索。</p><p>我们现在可以说已经掌握了所有二元分类、多类分类和多标签分类指标，现在我们可以转向回归指标。</p><p>回归中最常见的指标是<strong>误差（Error）</strong>。误差很简单，也很容易理解。</p><script type="math/tex; mode=display">Error = True\ Value - Predicted\ Value</script><p><strong>绝对误差（Absolute error）</strong>只是上述误差的绝对值。</p><script type="math/tex; mode=display">Absolute\ Error = Abs(True\ Value - Predicted\ Value)</script><p>接下来我们讨论<strong>平均绝对误差（MAE）</strong>。它只是所有绝对误差的平均值。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mean_absolute_error</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment">#初始化误差</span></span><br><span class="line">    error = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历y_true, y_pred</span></span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="comment"># 累加绝对误差</span></span><br><span class="line">        error += np.<span class="built_in">abs</span>(yt - yp)</span><br><span class="line">    <span class="comment"># 返回平均绝对误差</span></span><br><span class="line">    <span class="keyword">return</span> error / <span class="built_in">len</span>(y_true)</span><br></pre></td></tr></table></figure><p>同样，我们还有平方误差和<strong>均方误差 （MSE）</strong>。</p><script type="math/tex; mode=display">Squared\ Error = (True Value - Predicted\ Value)^2</script><p>均方误差（MSE）的计算方式如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mean_squared_error</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 初始化误差</span></span><br><span class="line">    error = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历y_true, y_pred</span></span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="comment"># 累加误差平方和</span></span><br><span class="line">        error += (yt - yp) ** <span class="number">2</span></span><br><span class="line">    <span class="comment"># 计算均方误差</span></span><br><span class="line">    <span class="keyword">return</span> error / <span class="built_in">len</span>(y_true)</span><br></pre></td></tr></table></figure><p>MSE 和 <strong>RMSE（均方根误差）</strong>是评估回归模型最常用的指标。</p><script type="math/tex; mode=display">RMSE = SQRT(MSE)</script><p>同一类误差的另一种类型是<strong>平方对数误差</strong>。有人称其为 <strong>SLE</strong>，当我们取所有样本中这一误差的平均值时，它被称为 MSLE（平均平方对数误差），实现方法如下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mean_squared_log_error</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 初始化误差</span></span><br><span class="line">    error = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历y_true, y_pred</span></span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="comment"># 计算平方对数误差</span></span><br><span class="line">        error += (np.log(<span class="number">1</span> + yt) - np.log(<span class="number">1</span> + yp)) ** <span class="number">2</span></span><br><span class="line">    <span class="comment"># 计算平均平方对数误差</span></span><br><span class="line">    <span class="keyword">return</span> error / <span class="built_in">len</span>(y_true)</span><br></pre></td></tr></table></figure><p><strong>均方根对数误差</strong>只是其平方根。它也被称为 <strong>RMSLE</strong>。</p><p>然后是百分比误差：</p><script type="math/tex; mode=display">Percentage\ Error = (( True\ Value – Predicted\ Value ) / True\ Value ) \times 100</script><p>同样可以转换为所有样本的平均百分比误差。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mean_percentage_error</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 初始化误差</span></span><br><span class="line">    error = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历y_true, y_pred</span></span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="comment"># 计算百分比误差</span></span><br><span class="line">        error += (yt - yp) / yt</span><br><span class="line">    <span class="comment"># 返回平均百分比误差</span></span><br><span class="line">    <span class="keyword">return</span> error / <span class="built_in">len</span>(y_true)</span><br></pre></td></tr></table></figure><p>绝对误差的绝对值（也是更常见的版本）被称为<strong>平均绝对百分比误差或 MAPE</strong>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mean_abs_percentage_error</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 初始化误差</span></span><br><span class="line">    error = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历y_true, y_pred</span></span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        <span class="comment"># 计算绝对百分比误差</span></span><br><span class="line">        error += np.<span class="built_in">abs</span>(yt - yp) / yt</span><br><span class="line">    <span class="comment">#返回平均绝对百分比误差</span></span><br><span class="line">    <span class="keyword">return</span> error / <span class="built_in">len</span>(y_true)</span><br></pre></td></tr></table></figure><p>回归的最大优点是，只有几个最常用的指标，几乎可以应用于所有回归问题。与分类指标相比，回归指标更容易理解。</p><p>让我们来谈谈另一个回归指标 $R^2$（R 方），也称为<strong>判定系数</strong>。</p><p>简单地说，R 方表示模型与数据的拟合程度。R 方接近 1.0 表示模型与数据的拟合程度相当好，而接近 0 则表示模型不是那么好。当模型只是做出荒谬的预测时，R 方也可能是负值。</p><p>R 方的计算公式如下所示，但 Python 的实现总是能让一切更加清晰。</p><script type="math/tex; mode=display">R^2 = \frac{\sum^{N}_{i=1}(y_{t_i}-y_{p_i})^2}{\sum^{N}_{i=1}(y_{t_i} - y_{t_{mean}})}</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">r2</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 计算平均真实值</span></span><br><span class="line">    mean_true_value = np.mean(y_true)</span><br><span class="line">    <span class="comment"># 初始化平方误差</span></span><br><span class="line">    numerator = <span class="number">0</span></span><br><span class="line">    denominator = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历y_true, y_pred</span></span><br><span class="line">    <span class="keyword">for</span> yt, yp <span class="keyword">in</span> <span class="built_in">zip</span>(y_true, y_pred):</span><br><span class="line">        numerator += (yt - yp) ** <span class="number">2</span></span><br><span class="line">        denominator += (yt - mean_true_value) ** <span class="number">2</span></span><br><span class="line">    ratio = numerator / denominator</span><br><span class="line">    <span class="comment"># 计算R方</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> – ratio</span><br></pre></td></tr></table></figure><p>还有更多的评价指标，这个清单永远也列不完。我可以写一本书，只介绍不同的评价指标。也许我会的。现在，这些评估指标几乎可以满足你想尝试解决的所有问题。请注意，我已经以最直接的方式实现了这些指标，这意味着它们不够高效。你可以通过正确使用 numpy 以非常高效的方式实现其中大部分指标。例如，看看平均绝对误差的实现，不需要任何循环。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">mae_np</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line"><span class="keyword">return</span> np.mean(np.<span class="built_in">abs</span>(y_true - y_pred))</span><br></pre></td></tr></table></figure><p>我本可以用这种方法实现所有指标，但为了学习，最好还是看看底层实现。一旦你学会了纯 python 的底层实现，并且不使用大量 numpy，你就可以很容易地将其转换为 numpy，并使其变得更快。</p><p>然后是一些高级度量。</p><p>其中一个应用相当广泛的指标是<strong>二次加权卡帕</strong>，也称为 <strong>QWK</strong>。它也被称为科恩卡帕。<strong>QWK</strong> 衡量两个 “评分 “之间的 “一致性”。评分可以是 0 到 N 之间的任何实数，预测也在同一范围内。一致性可以定义为这些评级之间的接近程度。因此，它适用于有 N 个不同类别的分类问题。如果一致度高，分数就更接近 1.0。Cohen’s kappa 在 scikit-learn 中有很好的实现，关于该指标的详细讨论超出了本书的范围。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">In [X]: <span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line">In [X]: y_true = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">In [X]: y_pred = [<span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">In [X]: metrics.cohen_kappa_score(y_true, y_pred, weights=<span class="string">&quot;quadratic&quot;</span>)</span><br><span class="line">Out[X]: <span class="number">0.33333333333333337</span></span><br><span class="line">In [X]: metrics.accuracy_score(y_true, y_pred)</span><br><span class="line">Out[X]: <span class="number">0.4444444444444444</span></span><br></pre></td></tr></table></figure><p>您可以看到，尽管准确度很高，但 QWK 却很低。QWK 大于 0.85 即为非常好！</p><p>一个重要的指标是<strong>马修相关系数（MCC）</strong>。1 代表完美预测，-1 代表不完美预测，0 代表随机预测。MCC 的计算公式非常简单。</p><script type="math/tex; mode=display">MCC = \frac{TP \times TN - FP \times FN}{\sqrt{(TP + FP) \times (FN + TN) \times (FP + TN) \times (TP + FN)}}</script><p>我们看到，MCC 考虑了 TP、FP、TN 和 FN，因此可用于处理类偏斜的问题。您可以使用我们已经实现的方法在 python 中快速实现它。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">mcc</span>(<span class="params">y_true, y_pred</span>):</span><br><span class="line">    <span class="comment"># 真阳性样本数</span></span><br><span class="line">    tp = true_positive(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 真阴性样本数</span></span><br><span class="line">    tn = true_negative(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 假阳性样本数</span></span><br><span class="line">    fp = false_positive(y_true, y_pred)</span><br><span class="line">    <span class="comment"># 假阴性样本数</span></span><br><span class="line">    fn = false_negative(y_true, y_pred)</span><br><span class="line">    numerator = (tp * tn) - (fp * fn)</span><br><span class="line">    denominator = (</span><br><span class="line">        (tp + fp) *</span><br><span class="line">        (fn + tn) *</span><br><span class="line">        (fp + tn) *</span><br><span class="line">        (tp + fn)</span><br><span class="line">    )</span><br><span class="line">denominator = denominator ** <span class="number">0.5</span></span><br><span class="line"><span class="keyword">return</span> numerator/denominator</span><br></pre></td></tr></table></figure><p>这些指标可以帮助你入门，几乎适用于所有机器学习问题。</p><p>需要注意的一点是，在评估非监督方法（例如某种聚类）时，最好创建或手动标记测试集，并将其与建模部分的所有内容分开。完成聚类后，就可以使用任何一种监督学习指标来评估测试集的性能了。</p><p>一旦我们了解了特定问题应该使用什么指标，我们就可以开始更深入地研究我们的模型，以求改进。</p>]]></content>
      
      
      <categories>
          
          <category> AAAMLP </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>python打包成.exe</title>
      <link href="/%E6%9D%82%E5%AD%A6/python%E6%89%93%E5%8C%85%E6%88%90.exe/"/>
      <url>/%E6%9D%82%E5%AD%A6/python%E6%89%93%E5%8C%85%E6%88%90.exe/</url>
      
        <content type="html"><![CDATA[<h1>在 Python 开发中将脚本打包成可执行文件（.exe）</h1><p>在 Python 开发中，将 Python 脚本打包成可执行文件（.exe）是一种常见需求。这样做可以使程序在没有安装 Python 解释器的环境下运行，同时也方便了程序的发布和分发。本文将介绍几种常见的方法来将 Python 代码打包成可执行文件。</p><h2 id="一、使用-pyinstaller-打包">一、使用 pyinstaller 打包</h2><p><code>pyinstaller</code> 是一个流行的 Python 打包工具，它能够将 Python 脚本打包成各种平台的可执行文件，包括 Windows、Linux 和 macOS。使用 <code>pyinstaller</code> 可以非常简单地将 Python 代码打包成独立的可执行文件。</p><h3 id="安装-pyinstaller">安装 <code>pyinstaller</code></h3><p>首先，您需要安装 <code>pyinstaller</code>。可以通过以下命令进行安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install pyinstaller</span><br></pre></td></tr></table></figure><h3 id="使用-pyinstaller-打包">使用 <code>pyinstaller</code> 打包</h3><p>接下来，您可以使用 <code>pyinstaller</code> 来打包您的 Python 脚本。以下是一些常用的打包命令：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打包单个文件</span></span><br><span class="line">pyinstaller your_script.py</span><br><span class="line"><span class="comment"># 打包多个 py 文件</span></span><br><span class="line">pyinstaller [主文件] -p [其他文件<span class="number">1</span>] -p [其他文件<span class="number">2</span>]</span><br><span class="line"><span class="comment"># 打包时去除 cmd 框</span></span><br><span class="line">pyinstaller -F XXX.py --noconsole</span><br><span class="line"><span class="comment"># 打包加入 exe 图标</span></span><br><span class="line">pyinstaller -F -i picturename.ico -w XXX.py</span><br><span class="line"><span class="comment"># 打包去除控制台</span></span><br><span class="line">pyinstaller -w xxx.py</span><br><span class="line"><span class="comment"># 打包方便查看报错，可看到控制台</span></span><br><span class="line">pyinstaller -c xxx.py</span><br></pre></td></tr></table></figure><p>如果遇到错误 <code>AttributeError: module 'enum' has no attribute 'IntFlag'</code>，请检查是否安装了 <code>enum34</code> 包，并卸载它以解决问题。<br>执行以上命令后，<code>pyinstaller</code> 将在当前目录下生成一个 <code>dist</code> 文件夹，其中包含了打包好的可执行文件。</p><h3 id="处理-gradio-库依赖">处理 <code>gradio</code> 库依赖</h3><p>如果您在程序中使用了 <code>gradio</code> 库，您可能需要在打包时特别注意。如果在打包后双击程序时出现闪退，您可以在命令行中运行程序以查看具体的报错原因。<br>如果遇到错误 <code>FileNotFoundError: [Errno 2] No such file or directory</code>，这通常是因为 <code>pyinstaller</code> 没有正确识别 <code>gradio</code> 相关的依赖项。您可以通过以下命令来修正这个问题：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyinstaller -F python_file_name --collect-data=gradio_client --collect-data=gradio</span><br></pre></td></tr></table></figure><p>如果出现 <code>FileNotFoundError: [Errno 2] No such file or directory: gradio\blocks_events.pyc</code>，则需要修改 <code>spec</code> 文件来指定对 <code>gradio</code> 库下的代码进行编译。具体操作如下：</p><ol><li>生成 <code>spec</code> 文件：<code>pyi-makespec --collect-data=gradio_client --collect-data=gradio python_file_name</code></li><li>打开与要打包的 <code>py</code> 代码同名的 <code>spec</code> 文件，在 <code>A = Analysis&#123;&#125;</code> 添加对 <code>gradio</code> 的编译：<code>module_collection_mode=&#123; 'gradio': 'py',&#125;</code></li><li>删除目录下的 <code>build</code> 文件夹，再次执行 <code>pyinstaller python_file_name.spec</code><br>然后，您可以进入 <code>dist</code> 目录，找到生成的 <code>exe</code> 文件。</li></ol><h3 id="使用-spec-文件生成单个-exe-文件">使用 <code>spec</code> 文件生成单个 <code>exe</code> 文件</h3><p>您可以使用以下 <code>spec</code> 文件来生成单个 <code>exe</code> 文件：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"># -*- mode: python ; coding: utf-8 -*-</span><br><span class="line">from PyInstaller.utils.hooks import collect_data_files</span><br><span class="line"></span><br><span class="line">datas = []</span><br><span class="line">datas += collect_data_files(&#x27;gradio_client&#x27;)</span><br><span class="line">datas += collect_data_files(&#x27;gradio&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a = Analysis(</span><br><span class="line">    [&#x27;08.onnxgradio.py&#x27;],</span><br><span class="line">    pathex=[],</span><br><span class="line">    binaries=[],</span><br><span class="line">    datas=datas,</span><br><span class="line">    hiddenimports=[],</span><br><span class="line">    hookspath=[],</span><br><span class="line">    hooksconfig=&#123;&#125;,</span><br><span class="line">    runtime_hooks=[],</span><br><span class="line">    excludes=[],</span><br><span class="line">    noarchive=False,</span><br><span class="line">module_collection_mode=&#123; &#x27;gradio&#x27;: &#x27;py&#x27;,&#125;</span><br><span class="line">)</span><br><span class="line">pyz = PYZ(a.pure)</span><br><span class="line"></span><br><span class="line">exe = EXE(</span><br><span class="line">    pyz,</span><br><span class="line">    a.scripts,</span><br><span class="line">    a.binaries,</span><br><span class="line">    a.datas,</span><br><span class="line">    [],</span><br><span class="line">    name=&#x27;08.onnxgradio&#x27;,</span><br><span class="line">    debug=False,</span><br><span class="line">    bootloader_ignore_signals=False,</span><br><span class="line">    strip=False,</span><br><span class="line">    upx=True,</span><br><span class="line">    upx_exclude=[],</span><br><span class="line">    runtime_tmpdir=None,</span><br><span class="line">    console=True,</span><br><span class="line">    disable_windowed_traceback=False,</span><br><span class="line">    argv_emulation=False,</span><br><span class="line">    target_arch=None,</span><br><span class="line">    codesign_identity=None,</span><br><span class="line">    entitlements_file=None,</span><br><span class="line">)</span><br><span class="line">coll = COLLECT(</span><br><span class="line">    exe,</span><br><span class="line">    a.binaries,</span><br><span class="line">    a.datas,</span><br><span class="line">    strip=False,</span><br><span class="line">    upx=True,</span><br><span class="line">    upx_exclude=[],</span><br><span class="line">    name=&#x27;08.onnxgradio&#x27;,</span><br><span class="line">)</span><br></pre></td></tr></table></figure><h2 id="二、cx-Freeze">二、cx_Freeze</h2><p><code>cx_Freeze</code> 是另一个常用的 Python 打包工具，可以将 <code>Python</code> 脚本打包成可执行文件，并且支持跨平台。使用 <code>cx_Freeze</code> 也可以将 Python 代码打包成独立的可执行文件。</p><p>安装 <code>cx_Freeze</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install cx-Freeze</span><br></pre></td></tr></table></figure><p>使用 <code>cx_Freeze 打包</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cxfreeze your_script.py --target-dir dist</span><br></pre></td></tr></table></figure><p>执行以上命令后，<code>cx_Freeze</code> 将会在指定的目录下生成可执行文件。</p>]]></content>
      
      
      <categories>
          
          <category> 杂学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数学物理方程第一章</title>
      <link href="/%E6%AD%A3%E5%AD%A6/%E6%95%B0%E5%AD%A6%E7%89%A9%E7%90%86%E6%96%B9%E7%A8%8B/%E6%95%B0%E5%AD%A6%E7%89%A9%E7%90%86%E6%96%B9%E7%A8%8B%E7%AC%AC%E4%B8%80%E7%AB%A0/"/>
      <url>/%E6%AD%A3%E5%AD%A6/%E6%95%B0%E5%AD%A6%E7%89%A9%E7%90%86%E6%96%B9%E7%A8%8B/%E6%95%B0%E5%AD%A6%E7%89%A9%E7%90%86%E6%96%B9%E7%A8%8B%E7%AC%AC%E4%B8%80%E7%AB%A0/</url>
      
        <content type="html"><![CDATA[<h2 id="书名-数学物理方程">书名-数学物理方程</h2><h2 id="新知识概览">新知识概览</h2><h1>一些典型方程和定解条件的推导</h1><h3 id="基本方程的建立">基本方程的建立</h3><p>简要介绍本课的新知识，包括概念、定义和基本原理。</p><h3 id="初值条件与边界条件">初值条件与边界条件</h3><p>问题所具有的特定条件也用数学形式表达出来，这是因为任何一个具体的物理现象都是处在特定条件之下的.</p><h3 id="定解问题的提法">定解问题的提法</h3><p>由于每一个物理过程都处在特定的条件之下，所以我们的任务是要求出偏微分方程的适合某些特定条件的解.初值条件和边界条件都称为定解条件.把某个偏微分方程和相应的定解条件结合在一起，就构成了一个定解问题。</p><h2 id="学习笔记">学习笔记</h2><h3 id="基本方程的建立-2">基本方程的建立</h3><h4 id="例-1-弦的振动">例 1 弦的振动</h4><p>设有一根均匀柔软的 细弦，平 衡时沿 直线拉紧，而且除 受不 随时间 而 变的张力作用及弦本身的重力外，不受外力影响.下面研究弦作微小横向振动的规律.所谓“横向&quot;是指全部运动出现在一个平面上，而 且弦上的点沿垂直于 x 轴的方向运动(图 1-1).所谓“微小”是指振动的幅度及弦在任意位置处切线的倾角都很小，以至它们的高于一次方的项都可略而不计.</p><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/sxwlfc1.1.png" alt="图1-1"><br>用牛顿运动定律，作用于弧段上任一方向上的力的总和等于这段弧的 质量 乘该方向 上的加速度.在 x 轴方向，弧段 MM’受力的总和为<code>-Tcos α+T'cos α'</code>,由于弦只作横向振动，所以<br>$$T’\cos\alpha’-T\cos\alpha=0.\quad(1.1)$$<br>按照上述弦振动微小的假设，可知在振动过程中弦上 M 点与 M’点处切线的倾角都很小，<code>α≈0,α'=0</code>,从而由<br>$$\cos\alpha=1-\frac{\alpha^{2}}{2!}+\frac{\alpha^{4}}{4!}-\cdots $$<br>可知，当我们略去$\alpha$与$\alpha^\prime$的所有高于一次方的各项时，就有$\cos \alpha \approx 1$, $\cos \alpha ^{\prime }\approx 1$,<br>代人<code>(1.1)</code>式，便可近似得到<br>$$T=T^\prime.$$<br>在$u$ 方向，弧段$\widehat MM^\prime$受力的总和为-$T\sin\alpha+T^{\prime}\sin\alpha^{\prime}-\rho g$ds,其中-$\rho g$ds 是弧段$\widehat{MM}^{\prime}$的重力.又因当$\alpha\approx0,\alpha^\prime\approx0$时<br>$$\sin\alpha=\frac{\tan\alpha}{\sqrt{1+\tan^{2}\alpha}}\approx\tan\alpha=\frac{\partial u(x,t)}{\partial x},$$<br>$$\sin\alpha^{\prime}\approx\tan\alpha^{\prime}=\frac{\partial u\left(x+\mathrm{d}x,t\right)}{\partial x},$$<br>$$\mathrm{d}s=\sqrt{1+\left[\frac{\partial u\left(x,t\right)}{\partial x}\right]^{2}}\mathrm{d}x\approx\mathrm{d}x,$$<br>且小弧段在时刻$\iota$沿$u$方向运动的加速度近似为$\frac{\partial^2u(x,t)}{\partial t^2}$,小弧段的质量为$\rho$ds ,所以<br>$$-T\sin\alpha+T’\sin\alpha’-\rho g\mathrm{d}s\approx\rho\mathrm{d}s\frac{\partial^{2}u(x,t)}{\partial t^{^2}}$$<br>或<br>$$T\Big[\frac{\partial u\left(x+\mathrm{d}x,t\right)}{\partial x}-\frac{\partial u\left(x,t\right)}{\partial x}\Big]-\rho g\mathrm{d}x\approx\rho\frac{\partial^{2}u\left(x,t\right)}{\partial t^{2}}\mathrm{d}x,(1.2)$$<br>上式左边方括号内的部分是由于$x$产生 d$x$ 的变化而引起的$\frac\partial u(x,t){\partial x}$的改变量，可用微分近似代替，即<br>$$\frac{\partial u\left(x+\mathrm{d}x,t\right)}{\partial x}-\frac{\partial u\left(x,t\right)}{\partial u}\approx\frac{\partial}{\partial x}\biggl[\frac{\partial u\left(x,t\right)}{\partial x}\biggr]\mathrm{d}x$$<br>$$=\frac{\partial^{2}u\left(x,t\right)}{\partial x^{2}}\mathrm{d}x,$$<br>于是<br>$$\left[T\frac{\partial^{2}u\left(x,t\right)}{\partial x^{2}}-\rho g\right]\mathrm{d}x\approx\rho\frac{\partial^{2}u\left(x,t\right)}{\partial t^{2}}\mathrm{d}x$$<br>或<br>$$\frac{T}{\rho}\frac{\partial^{2}u\left(x,t\right)}{\partial x^{2}}\approx\frac{\partial^{2}u\left(x,t\right)}{\partial t^{2}}+g.$$<br>一般说来，张力较大时弦振动速度变化很快，即$\frac{\partial^2u}{\partial t^2}$要比 $g$ 大得多，所以又可以<br>把$g$略去.经过这样逐步略去一些次要的量，抓住主要的量，在$u(x,t)$关于${x,t}$都是二次连续可微的前提下，最后得出$u(x,t)$应近似地满足方程<br>$$\frac{\partial^{2}u}{\partial t^{2}}=a^{2}\frac{\partial^{2}u}{\partial x^{2}},(1.3)$$</p><p>这里的$a^{2}=\frac{T}{\rho}.(1.3)$式称为一维波动方程.<br>如果在振动过程中，弦上另外还受到一个与弦的振动方向平行的外力，且假定在时刻$\iota$弦上$x$点处的外力密度为$F(x,t)$,显然，这时(1.1)及(1.2)分别为<br>$$T^{\prime}\cos\alpha^{\prime}-T\cos\alpha=0,$$<br>$$F\mathrm{d}s-T\mathrm{sin}\alpha+T’\mathrm{sin}\alpha’-\rho g\mathrm{d}s\approx\rho\mathrm{d}s\frac{\partial^{2}u}{\partial t^{2}}.$$<br>利用上面的推导方法并略去弦本身的质量，可得弦的强迫振动方程为<br>$$\frac{\partial^{2}u}{\partial t^{2}}=a^{2}\frac{\partial^{2}u}{\partial x^{2}}+f(x,\iota),(1.3)^{\prime}$$<br>其中$f(x,t)=\frac1aF(x,t)$ ,表示 $t$ 时刻单位质量的弦在 $x$ 点处所受的外力密度.<br>方程( 1.3)与$(1.3)^{\prime}$的差别在于$(1.3)^{\prime}$的右端多了一个与未知函数$u$无关的项 $f(x,t)$,这个项称为自由项.包括非零自由项的方程称为非齐次方程，自由项恒等于零的方程称为齐次方程.(1.3)为齐次一维波动方程，$(1.3)^{\prime}$为非齐次一维波动方程.</p><h3 id="初值条件与边界条件-2">初值条件与边界条件</h3><p>在将物理问题转化为数学表达式时，除了需要表达物理规律本身，还需要将问题的特定条件用数学形式表达出来。这些特定条件包括初始状态和边界约束，分别称为初值条件和边界条件。例如在弦振动问题中，虽然我们已经得到了描述弦振动的普遍方程，但如果没有考虑弦的初始状态和两端点所受的约束，我们就无法准确地描述一个特定情况下的弦振动。因此，为了精确描述和研究具体的物理现象，我们需要将这些特定条件纳入数学模型中。<br>下面具体说明初值条件和边界条件的表达形式.先谈初值条件，对于弦振动问题来说，初值条件就是弦在开始时刻的位移及速度，若以$\varphi(x),\psi(x)$分别表示初位移和初速度，则初值条件可以表达为<br>$$\begin{cases}u\bigg|<em>{t=0}=\varphi(x),\\\frac{\partial u}{\partial t}\bigg|</em>{t=0}=\psi(x).\end{cases},(1.22)$$</p><h3 id="定解问题的提法-2">定解问题的提法</h3><p>在工程技术中，经常会遇到需要解决偏微分方程的问题。一个函数如果满足某个偏微分方程，并且具有所需的连续偏导数，使得代入方程后成为恒等式，那么这个函数就是该方程的解。<br>由于物理过程总是在特定条件下发生，我们需要找到满足特定条件的偏微分方程的解，这些特定条件包括<strong>初值条件</strong>和<strong>边界条件</strong>，统称为<strong>定解条件</strong>。<br>定解问题可以分为三类：</p><ul><li><strong>初值问题（或称柯西问题）</strong>：只有初值条件。</li><li><strong>边值问题</strong>：只有边界条件。</li><li><strong>混合问题</strong>：既有初值条件又有边界条件。<br>定解问题的合理性可以从三个方面检验：</li><li><strong>存在性:</strong> 即看所归结出来的定解问题是否有解；</li><li><strong>唯一性:</strong> 即看是否只有一个解；</li><li><strong>稳定性:</strong> 即看当定解条件有微小变动时，解是否相应地只有微小的变动，如果确实如此，此解便称为稳定的<br>如果定解问题存在唯一且稳定的解，则称为<strong>适定的</strong>。然而，讨论定解问题的适定性通常非常困难，因此本书将重点放在讨论定解问题的解法上，而不过多涉及适定性的讨论，因为书中所讨论的定解问题都是经典的，它们的适定性已经得到了证明。</li></ul><h2 id="练习题与答案">练习题与答案</h2><h3 id="无">无</h3><h2 id="参考文献">参考文献</h2><ul><li>工程数学 数学物理方程与特征函数</li></ul>]]></content>
      
      
      <categories>
          
          <category> 正学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数学物理方程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>九种常见激活函数</title>
      <link href="/uncategorized/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"/>
      <url>/uncategorized/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>神经网络中的激活函数是神经网络中至关重要的一环，它们决定了神经网络的非线性特性，能够让神经网络学习非常复杂的函数。激活函数的种类也非常丰富，从最早的 sigmoid、tanh，到后来的 ReLU、LeakyReLU、ELU 等，再到最近的 GELU、SE-ReLU、SiLU 等，每种激活函数都有其独特的优点和适用场景。</p><p>在本篇文章中，我们将对神经网络中常见的激活函数进行总结和介绍，同时也会介绍一些新兴的激活函数，帮助读者了解它们的特点和使用方法，以便在实际应用中能够选择合适的激活函数来提升神经网络的性能。</p><h3 id="常见的激活函数">常见的激活函数</h3><p>以下是一些常见的激活函数：</p><ul><li><strong>Sigmoid</strong></li><li><strong>Tanh</strong></li><li><strong>ReLU</strong></li><li><strong>LeakyReLU</strong></li><li><strong>ELU</strong></li></ul><h3 id="新兴的激活函数">新兴的激活函数</h3><p>以下是一些新兴的激活函数：</p><ul><li><strong>GELU</strong></li><li><strong>SE-ReLU</strong></li><li><strong>SiLU</strong></li></ul><h2 id="概述">概述</h2><p>神经网络中的激活函数是非常重要的组成部分，它的作用是将神经元的输入信号转换为输出信号，从而实现神经网络的非线性映射。激活函数的意义在于它能够引入非线性特性，使得神经网络可以拟合非常复杂的函数，从而提高了神经网络的表达能力和预测性能。</p><p>具体来说，激活函数的作用有以下几个方面：</p><ol><li><strong>引入非线性特性</strong>：激活函数能够将神经元的输入信号转换为输出信号，从而引入非线性特性，使得神经网络可以拟合非常复杂的函数。</li><li><strong>压缩输出范围</strong>：激活函数能够将神经元的输出范围压缩到一定的范围内，这有助于防止神经元输出的值过大或过小，从而提高了神经网络的稳定性和泛化性能。</li><li><strong>增加网络深度</strong>：激活函数能够增加神经网络的深度，从而提高了神经网络的表达能力和预测性能。</li><li><strong>改善梯度消失问题</strong>：激活函数能够改善神经网络中的梯度消失问题，从而提高了神经网络的训练效率和收敛速度。</li></ol><h2 id="特性">特性</h2><h3 id="sigmoid-函数">sigmoid 函数</h3><p>sigmoid 函数是神经网络中最早也是最常用的激活函数之一，它的特点是将输入值映射到 0 到 1 之间的连续范围内，输出值具有良好的可解释性，但是它在梯度消失和输出饱和等问题上表现不佳。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.</span> / (<span class="number">1.</span> + np.exp(-x))</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/sigmoid.jpg" alt="Sigmoid"></p><h3 id="ReLU-函数">ReLU 函数</h3><p>ReLU 函数是当前最常用的激活函数之一，它的特点是简单、快速，并且在许多情况下表现出色。ReLU 函数将负数输入映射到 0，将正数输入保留不变，因此在训练过程中可以避免梯度消失的问题。但是 ReLU 函数在输入为负数时输出为 0，这可能导致神经元死亡，因此后续的改进版本 LeakyReLU 得到了广泛的应用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">ReLU</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.maximum(<span class="number">0</span>, x)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/ReLU.jpg" alt="ReLU"></p><h3 id="LeakyReLU-函数">LeakyReLU 函数</h3><p>LeakyReLU 函数是 ReLU 函数的改进版本，它在输入为负数时输出一个小的负数，从而避免了 ReLU 函数可能导致神经元死亡的问题。LeakyReLU 函数的优点是简单、快速，并且在许多情况下表现出色，但是其超参数需要手动调整，因此在实际应用中需要进行一定的调试。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">LeakyReLU</span>(<span class="params">x, alpha=<span class="number">0.1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> np.maximum(alpha*x, x)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/LeakyReLU.jpg" alt="LeakyReLU"></p><h3 id="Tanh-函数">Tanh 函数</h3><p>Tanh 函数是一种具有 S 形状的激活函数，其特点是将输入值映射到-1 到 1 之间的连续范围内，输出值也具有良好的可解释性。Tanh 函数在某些情况下可以表现出色，但是它也存在梯度消失和输出饱和等问题，因此在深度神经网络中使用并不广泛。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Tanh</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.tanh(x)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/tanh.jpg" alt="Tanh"></p><h3 id="Softmax-函数">Softmax 函数</h3><p>Softmax 函数是一种常用于多分类问题的激活函数，它将输入值映射到 0 到 1 之间的概率分布，可以将神经网络的输出转换为各个类别的概率值。Softmax 函数的优点是简单、易于理解，并且在多分类问题中表现出色，但是它也存在梯度消失和输出饱和等问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">Softmax</span>(<span class="params">x</span>):</span><br><span class="line">    exp_x = np.exp(x)</span><br><span class="line">    <span class="keyword">return</span> exp_x / np.<span class="built_in">sum</span>(exp_x, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/softmax.jpg" alt="SoftMax"></p><h3 id="GELU-函数">GELU 函数</h3><p>GELU 函数是一种近年来提出的激活函数，它的特点是在 ReLU 函数的基础</p><p>上引入了高斯误差线性单元，从而在某些情况下能够表现出色。GELU 函数具有平滑的非线性特性，可以避免 ReLU 函数可能导致的神经元死亡问题。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">GELU</span>(<span class="params">x</span>):</span><br><span class="line">    cdf = <span class="number">0.5</span> * (<span class="number">1.0</span> + np.tanh((np.sqrt(<span class="number">2</span> / np.pi) * (x + <span class="number">0.044715</span> * np.power(x, <span class="number">3</span>)))))</span><br><span class="line">    <span class="keyword">return</span> x * cdf</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/GeLU.jpg" alt="GeLU"></p><h3 id="SE-ReLU-函数">SE_ReLU 函数</h3><p>SE_ReLU 函数是一种近年来提出的激活函数，它的特点是在 ReLU 函数的基础上引入了 Sigmoid 函数和 Exponential 函数，从而能够增加神经元的表达能力。SE_ReLU 函数具有非常好的平滑性和可解释性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">SE_ReLU</span>(<span class="params">x, alpha=<span class="number">0.1</span>, beta=<span class="number">10</span></span>):</span><br><span class="line">    <span class="keyword">return</span> np.where(x &gt; <span class="number">0</span>, x + alpha * x * np.exp(-beta * x), x)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/SE_ReLU.jpg" alt="SE_ReLU"></p><h3 id="SiLU-函数">SiLU 函数</h3><p>SiLU 函数是一种近年来提出的激活函数，它的特点是在 sigmoid 函数的基础上引入了自身的输入，从而能够表现出更好的非线性特性。SiLU 函数具有非常好的平滑性和可解释性。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">SE_ReLU</span>(<span class="params">x, alpha=<span class="number">0.1</span>, beta=<span class="number">10</span></span>):</span><br><span class="line">    <span class="keyword">return</span> np.where(x &gt; <span class="number">0</span>, x + alpha * x * np.exp(-beta * x), x)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/SiLU.jpg" alt="SiLU"></p><h3 id="DynamicShiftMax-DynamicReLU-A-DynamicReLU-B-函数">DynamicShiftMax &amp; DynamicReLU_A &amp; DynamicReLU_B 函数</h3><p>DynamicShiftMax 函数是一种近年来提出的激活函数，它的特点是在 ReLU 函数的基础上引入了动态偏移量，从而能够增加神经元的表达能力。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">DynamicShiftMax</span>(<span class="params">x, alpha=<span class="number">0.1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> np.maximum(x, x + alpha * np.<span class="built_in">max</span>(x, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">DynamicReLU_A</span>(<span class="params">x, alpha=<span class="number">0.1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> np.maximum(x, x + alpha * np.mean(x, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">DynamicReLU_B</span>(<span class="params">x, alpha=<span class="number">0.1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> np.maximum(x, x + alpha * np.std(x, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>))</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/DSM%26DRLA%26DRLB.jpg" alt="DSM%26DRLA%26DRLB"></p><h2 id="性能测试">性能测试</h2><p>我们采用控制变量法进行激活函数的推理速度测试，x 为输入，范围为-1 到 1 之间的十万个数据，运行次数为 100 计算激活函数的计算耗时。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    x = np.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">100000</span>)</span><br><span class="line">    t1 = time.time()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">        y = sigmoid(x)</span><br><span class="line">    t2 = time.time()</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">float</span>(t2 - t1))</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/littlepenguin66/webImage/FET.jpg" alt="FunctionExecutionTime"></p><p>完整代码如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sigmoid</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.</span> / (<span class="number">1.</span> + np.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ReLU</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.maximum(<span class="number">0</span>, x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">LeakyReLU</span>(<span class="params">x, alpha=<span class="number">0.1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> np.maximum(alpha * x, x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Tanh</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> np.tanh(x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Softmax</span>(<span class="params">x</span>):</span><br><span class="line">    exp_x = np.exp(x)</span><br><span class="line">    <span class="keyword">return</span> exp_x / np.<span class="built_in">sum</span>(exp_x, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">GELU</span>(<span class="params">x</span>):</span><br><span class="line">    cdf = <span class="number">0.5</span> * (<span class="number">1.0</span> + np.tanh((np.sqrt(<span class="number">2</span> / np.pi) * (x + <span class="number">0.044715</span> * np.power(x, <span class="number">3</span>)))))</span><br><span class="line">    <span class="keyword">return</span> x * cdf</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">SE_ReLU</span>(<span class="params">x, alpha=<span class="number">0.1</span>, beta=<span class="number">10</span></span>):</span><br><span class="line">    <span class="keyword">return</span> np.where(x &gt; <span class="number">0</span>, x + alpha * x * np.exp(-beta * x), x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">SE_ReLU</span>(<span class="params">x, alpha=<span class="number">0.1</span>, beta=<span class="number">10</span></span>):</span><br><span class="line">    <span class="keyword">return</span> np.where(x &gt; <span class="number">0</span>, x + alpha * x * np.exp(-beta * x), x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">DynamicShiftMax</span>(<span class="params">x, alpha=<span class="number">0.1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> np.maximum(x, x + alpha * np.<span class="built_in">max</span>(x, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">DynamicReLU_A</span>(<span class="params">x, alpha=<span class="number">0.1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> np.maximum(x, x + alpha * np.mean(x, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">DynamicReLU_B</span>(<span class="params">x, alpha=<span class="number">0.1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> np.maximum(x, x + alpha * np.std(x, axis=<span class="number">0</span>, keepdims=<span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line">name = [sigmoid, ReLU, LeakyReLU, Tanh, Softmax, GELU, SE_ReLU, DynamicShiftMax, DynamicReLU_A, DynamicReLU_B]</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    x = np.linspace(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1000000</span>)</span><br><span class="line">    times = []  <span class="comment"># 创建一个空列表来存储函数名称和时间</span></span><br><span class="line">    <span class="keyword">for</span> n <span class="keyword">in</span> name:</span><br><span class="line">        t1 = time.perf_counter()  <span class="comment"># 使用perf_counter</span></span><br><span class="line">        y = n(x)</span><br><span class="line">        t2 = time.perf_counter()  <span class="comment"># 使用perf_counter</span></span><br><span class="line">        times.append((n.__name__, <span class="built_in">float</span>(t2 - t1)))  <span class="comment"># 将函数名称和时间作为元组添加到列表中</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> n, t <span class="keyword">in</span> times:  <span class="comment"># 遍历列表并打印每个函数名称和时间</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;n&#125;</span>: <span class="subst">&#123;t&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 用plot绘制times列表中的数据</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">plt.bar(*<span class="built_in">zip</span>(*times)) <span class="comment"># 使用zip(*times)将元组列表转换为两个元组列表</span></span><br><span class="line">plt.ylabel(<span class="string">&#x27;Time (s)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Activation Functions&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 机器学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>anzhiyu添加新页面基于已有模板</title>
      <link href="/%E6%9D%82%E5%AD%A6/%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9/anzhiyu%E6%B7%BB%E5%8A%A0%E6%96%B0%E9%A1%B5%E9%9D%A2%E5%9F%BA%E4%BA%8E%E5%B7%B2%E6%9C%89%E6%A8%A1%E6%9D%BF/"/>
      <url>/%E6%9D%82%E5%AD%A6/%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9/anzhiyu%E6%B7%BB%E5%8A%A0%E6%96%B0%E9%A1%B5%E9%9D%A2%E5%9F%BA%E4%BA%8E%E5%B7%B2%E6%9C%89%E6%A8%A1%E6%9D%BF/</url>
      
        <content type="html"><![CDATA[<h2 id="前言">前言</h2><p><code>anzhiyu</code>主题仅支持添加现有模板，例如<code>album</code>、<code>essay</code>等。如果您使用以下命令创建新页面：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new page pageName</span><br></pre></td></tr></table></figure><p>由于<code>./themes/anzhiyu/layout/page.pug</code>中的以下代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">block content</span><br><span class="line">  #page</span><br><span class="line">    if top_img === false &amp;&amp; !page.top_single</span><br><span class="line">      h1.page-title= page.title</span><br><span class="line">    case page.type</span><br><span class="line">      when &#x27;tags&#x27;</span><br><span class="line">        include includes/page/tags.pug</span><br><span class="line">      when &#x27;link&#x27;</span><br><span class="line">        include includes/page/flink.pug</span><br><span class="line">      when &#x27;categories&#x27;</span><br><span class="line">        include includes/page/categories.pug</span><br><span class="line">      when &#x27;essay&#x27;</span><br><span class="line">        include includes/page/essay.pug</span><br><span class="line">      when &#x27;room&#x27;</span><br><span class="line">        include includes/page/room.pug</span><br><span class="line">      when &#x27;about&#x27;</span><br><span class="line">        include includes/page/about.pug</span><br><span class="line">      when &#x27;album&#x27;</span><br><span class="line">        include includes/page/album.pug</span><br><span class="line">      when &#x27;fcircle&#x27;</span><br><span class="line">        include includes/page/fcircle.pug</span><br><span class="line">      when &#x27;album_detail&#x27;</span><br><span class="line">        include includes/page/album_detail.pug</span><br><span class="line">      when &#x27;music&#x27;</span><br><span class="line">        include includes/page/music.pug</span><br><span class="line">      when &#x27;equipment&#x27;</span><br><span class="line">        include includes/page/equipment.pug</span><br><span class="line">      default</span><br><span class="line">        include includes/page/default-page.pug</span><br></pre></td></tr></table></figure><p>新页面将使用<code>default-page</code>的 JavaScript 和 CSS，这可能会导致外观不尽如人意（除非您有能力自行编写）。因此，我建议您基于现有模板进行修改。在这里，我们将使用模板库中的<code>equipment</code>页面作为示例进行自定义修改。</p><h4 id="具体方法如下：">具体方法如下：</h4><ol><li><p>找到以下文件：</p><ul><li><code>themes\anzhiyu\layout\page.pug</code></li><li><code>themes\anzhiyu\layout\includes\page\equipment.pug</code></li><li><code>themes\anzhiyu\source\css\_page\equipment.styl</code></li></ul></li><li><p>在<code>page.pug</code>中添加以下代码：</p></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">#page</span><br><span class="line">  if top_img === false &amp;&amp; !page.top_single</span><br><span class="line">    h1.page-title= page.title</span><br><span class="line">  case page.type</span><br><span class="line">    when &#x27;tags&#x27;</span><br><span class="line">      include includes/page/tags.pug</span><br><span class="line">    when &#x27;link&#x27;</span><br><span class="line">      include includes/page/flink.pug</span><br><span class="line">    when &#x27;categories&#x27;</span><br><span class="line">      include includes/page/categories.pug</span><br><span class="line">    when &#x27;essay&#x27;</span><br><span class="line">      include includes/page/essay.pug</span><br><span class="line">    when &#x27;room&#x27;</span><br><span class="line">      include includes/page/room.pug</span><br><span class="line">    when &#x27;about&#x27;</span><br><span class="line">      include includes/page/about.pug</span><br><span class="line">    when &#x27;album&#x27;</span><br><span class="line">      include includes/page/album.pug</span><br><span class="line">    when &#x27;fcircle&#x27;</span><br><span class="line">      include includes/page/fcircle.pug</span><br><span class="line">    when &#x27;album_detail&#x27;</span><br><span class="line">      include includes/page/album_detail.pug</span><br><span class="line">    when &#x27;music&#x27;</span><br><span class="line">      include includes/page/music.pug</span><br><span class="line">    when &#x27;equipment&#x27;</span><br><span class="line">      include includes/page/equipment.pug</span><br><span class="line">    when &#x27;pageName&#x27;  // 新加的代码</span><br><span class="line">      include includes/page/pageName.pug  // 新加的代码</span><br><span class="line">    default</span><br><span class="line">      include includes/page/default-page.pug</span><br></pre></td></tr></table></figure><ol start="3"><li><p>接着，对<code>equipment.pug</code>进行操作：</p><ul><li>新建一个文件<code>pageName.pug</code>。</li><li>复制<code>equipment.pug</code>中的所有代码。</li><li>将所有的<code>equipment</code>关键字替换为<code>pageName</code></li></ul></li><li><p>对<code>equipment.styl</code>重复上述步骤。</p></li></ol><p>完成以上步骤后，您就可以开始编辑新的<code>pageName.yml</code>文件了。</p><ol start="5"><li>直接把<code>equipment.yml</code>复制一份到新文件<code>pageName.yml</code>，并且把所有的<code>equipment</code>字样全部替换为<code>pageName</code>，就可以根据<code>equipment</code>的编辑模式对<code>pageName</code>页面进行编辑了。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 杂学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>页面配置</title>
      <link href="/%E6%9D%82%E5%AD%A6/%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9/%E9%A1%B5%E9%9D%A2%E9%85%8D%E7%BD%AE/"/>
      <url>/%E6%9D%82%E5%AD%A6/%E7%BD%91%E9%A1%B5%E5%86%85%E5%AE%B9/%E9%A1%B5%E9%9D%A2%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[<h3 id="🧱-Front-matter-的基本认识">🧱 Front-matter 的基本认识</h3><p>Front-matter 是 markdown 文件最上方以 — 分隔的区域，用于指定个别档案的变数。其中又分为两种 markdown 里</p><ul><li><strong>Page Front-matter</strong> 用于页面配置</li><li><strong>Post Front-matter</strong> 用于文章页配置</li></ul><h4 id="Page-Front-matter">Page Front-matter</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">title:</span> <span class="string">【必需】页面标题</span></span><br><span class="line"><span class="attr">date:</span> <span class="string">【必需】页面创建日期</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">【必需】标签、分类、关于、音乐馆、友情链接、相册、相册详情、朋友圈、即刻页面需要配置</span></span><br><span class="line"><span class="attr">updated:</span> <span class="string">【可选】页面更新日期</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">【可选】页面描述</span></span><br><span class="line"><span class="attr">keywords:</span> <span class="string">【可选】页面关键字</span></span><br><span class="line"><span class="attr">comments:</span> <span class="string">【可选】显示页面评论模块(默认</span> <span class="literal">true</span><span class="string">)</span></span><br><span class="line"><span class="attr">top_img:</span> <span class="string">【可选】页面顶部图片</span></span><br><span class="line"><span class="attr">mathjax:</span> <span class="string">【可选】显示</span> <span class="string">mathjax(当设置</span> <span class="string">mathjax</span> <span class="string">的</span> <span class="attr">per_page:</span> <span class="literal">false</span> <span class="string">时，才需要配置，默认</span> <span class="literal">false</span><span class="string">)</span></span><br><span class="line"><span class="attr">katex:</span> <span class="string">【可选】显示</span> <span class="string">katex(当设置</span> <span class="string">katex</span> <span class="string">的</span> <span class="attr">per_page:</span> <span class="literal">false</span> <span class="string">时，才需要配置，默认</span> <span class="literal">false</span><span class="string">)</span></span><br><span class="line"><span class="attr">aside:</span> <span class="string">【可选】显示侧边栏</span> <span class="string">(默认</span> <span class="literal">true</span><span class="string">)</span></span><br><span class="line"><span class="attr">aplayer:</span> <span class="string">【可选】在需要的页面加载</span> <span class="string">aplayer</span> <span class="string">的</span> <span class="string">js</span> <span class="string">和</span> <span class="string">css,请参考文章下面的音乐</span> <span class="string">配置</span></span><br><span class="line"><span class="attr">highlight_shrink:</span> <span class="string">【可选】配置代码框是否展开(true/false)(默认为设置中</span> <span class="string">highlight_shrink</span> <span class="string">的配置)</span></span><br><span class="line"><span class="attr">top_single_background:</span> <span class="string">【可选】部分页面的顶部模块背景图片</span></span><br></pre></td></tr></table></figure><h4 id="Post-Front-matter">Post Front-matter</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">title:</span> <span class="string">【必需】文章标题</span></span><br><span class="line"><span class="attr">date:</span> <span class="string">【必需】文章创建日期</span></span><br><span class="line"><span class="attr">updated:</span> <span class="string">【可选】文章更新日期</span></span><br><span class="line"><span class="attr">tags:</span> <span class="string">【可选】文章标签</span></span><br><span class="line"><span class="attr">categories:</span> <span class="string">【可选】文章分类</span></span><br><span class="line"><span class="attr">keywords:</span> <span class="string">【可选】文章关键字</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">【可选】文章描述</span></span><br><span class="line"><span class="attr">top_img:</span> <span class="string">【可选】文章顶部图片</span></span><br><span class="line"><span class="attr">cover:</span> <span class="string">【可选】文章缩略图(如果没有设置</span> <span class="string">top_img,文章页顶部将显示缩略图，可设为</span> <span class="literal">false</span><span class="string">/图片地址/留空)</span></span><br><span class="line"><span class="attr">comments:</span> <span class="string">【可选】显示文章评论模块(默认</span> <span class="literal">true</span><span class="string">)</span></span><br><span class="line"><span class="attr">toc:</span> <span class="string">【可选】显示文章</span> <span class="string">TOC(默认为设置中</span> <span class="string">toc</span> <span class="string">的</span> <span class="string">enable</span> <span class="string">配置)</span></span><br><span class="line"><span class="attr">toc_number:</span> <span class="string">【可选】显示</span> <span class="string">toc_number(默认为设置中</span> <span class="string">toc</span> <span class="string">的</span> <span class="string">number</span> <span class="string">配置)</span></span><br><span class="line"><span class="attr">toc_style_simple:</span> <span class="string">【可选】显示</span> <span class="string">toc</span> <span class="string">简洁模式</span></span><br><span class="line"><span class="attr">copyright:</span> <span class="string">【可选】显示文章版权模块(默认为设置中</span> <span class="string">post_copyright</span> <span class="string">的</span> <span class="string">enable</span> <span class="string">配置)</span></span><br><span class="line"><span class="attr">copyright_author:</span> <span class="string">【可选】文章版权模块的文章作者</span></span><br><span class="line"><span class="attr">copyright_author_href:</span> <span class="string">【可选】文章版权模块的文章作者链接</span></span><br><span class="line"><span class="attr">copyright_url:</span> <span class="string">【可选】文章版权模块的文章链接链接</span></span><br><span class="line"><span class="attr">copyright_info:</span> <span class="string">【可选】文章版权模块的版权声明文字</span></span><br><span class="line"><span class="attr">mathjax:</span> <span class="string">【可选】显示</span> <span class="string">mathjax(当设置</span> <span class="string">mathjax</span> <span class="string">的</span> <span class="attr">per_page:</span> <span class="literal">false</span> <span class="string">时，才需要配置，默认</span> <span class="literal">false</span><span class="string">)</span></span><br><span class="line"><span class="attr">katex:</span> <span class="string">【可选】显示</span> <span class="string">katex(当设置</span> <span class="string">katex</span> <span class="string">的</span> <span class="attr">per_page:</span> <span class="literal">false</span> <span class="string">时，才需要配置，默认</span> <span class="literal">false</span><span class="string">)</span></span><br><span class="line"><span class="attr">aplayer:</span> <span class="string">【可选】在需要的页面加载</span> <span class="string">aplayer</span> <span class="string">的</span> <span class="string">js</span> <span class="string">和</span> <span class="string">css,请参考文章下面的音乐</span> <span class="string">配置</span></span><br><span class="line"><span class="attr">highlight_shrink:</span> <span class="string">【可选】配置代码框是否展开(true/false)(默认为设置中</span> <span class="string">highlight_shrink</span> <span class="string">的配置)</span></span><br><span class="line"><span class="attr">aside:</span> <span class="string">【可选】显示侧边栏</span> <span class="string">(默认</span> <span class="literal">true</span><span class="string">)</span></span><br><span class="line"><span class="attr">swiper_index:</span> <span class="string">【可选】首页轮播图配置</span> <span class="string">index</span> <span class="string">索引，数字越小越靠前</span></span><br><span class="line"><span class="attr">top_group_index:</span> <span class="string">【可选】首页右侧卡片组配置,</span> <span class="string">数字越小越靠前</span></span><br><span class="line"><span class="attr">ai:</span> <span class="string">【可选】文章ai摘要</span></span><br><span class="line"><span class="attr">main_color:</span> <span class="string">【可选】文章主色，必须是16进制颜色且有6位，不可缩减，例如#ffffff</span> <span class="string">不可写成#fff</span></span><br></pre></td></tr></table></figure><p><strong>使用方法</strong>：</p><ol><li>在 Markdown 文件的最上方添加 Front-matter 区域，以<code>---</code>分隔。</li><li>根据需要配置 Page Front-matter 或 Post Front-matter 中的参数。</li><li>可选参数可以根据个人需求添加，不必全部包含。</li><li>特定页面的 Front-matter 配置（如 swiper_index 和 top_group_index）可以实现轮播图和推荐卡片的显示。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 杂学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 前端 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
